{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Tock - open conversational platform \u00b6 Tock ( The Open Conversation Kit ) is a complete and open platform to build conversational agents - also known as bots . Contrary to most conversational AI solutions, Tock does not depend on 3rd-party APIs, although it is possible to integrate with them. Users choose which components to embed and decide to keep (or share) ownership of conversational data and models. Tock has been used in production for several years by OUI.sncf to propose various assistants over its own channels (Web, mobile), social networks, as well as smart speakers. The platform source code is available on GitHub under the Apache License, version 2.0 . Tock is promoted and backed by the TOSIT (The Open Source I Trust) association. Features \u00b6 Standalone bots or integrated with Web sites, mobile apps, social networks, smart speakers. Full-featured NLU (Natural Language Understanding) platform, compatible with algorithms such as OpenNLP , Stanford CoreNLP , Duckling , can be deployed alone (for use cases like the Internet Of Things for instance) Tock Studio user interfaces: Models management, bot training Conversational no-code story builder Internationalization ( i18n ) support for multilingual bots Conversations, performance et model errors monitoring Interactive trends / users flow analytics ( Bot Flow ) Frameworks available to develop complex stories and integrate with 3rd-party services: Kotlin DSL plus any-language API Numerous connectors to Messenger , WhatsApp , Google Assistant / Home , Twitter , Alexa , Business Chat / iMessage , Teams , Slack ... (see connectors ) Cloud or on-premise setups, with or without Docker , \"embedded\" bots without Internet Technologies \u00b6 Tock runs on JVM platforms. The reference language is Kotlin , but other programming languages can be leveraged through the available APIs. Tock relies on Vert.x and MongoDB . Various NLU libraries and algorithms can be used, such as Apache OpenNLP or Stanford CoreNLP , but Tock does not depend on them directly. Graphical interfaces (Tock Studio) are made with Angular in Typescript . Getting started... \u00b6 Table of contents Guides and running demo/sandbox platform User , developer and administrator/ops manuals Resources (slides, video) and code samples","title":"Overview"},{"location":"#welcome-to-tock-open-conversational-platform","text":"Tock ( The Open Conversation Kit ) is a complete and open platform to build conversational agents - also known as bots . Contrary to most conversational AI solutions, Tock does not depend on 3rd-party APIs, although it is possible to integrate with them. Users choose which components to embed and decide to keep (or share) ownership of conversational data and models. Tock has been used in production for several years by OUI.sncf to propose various assistants over its own channels (Web, mobile), social networks, as well as smart speakers. The platform source code is available on GitHub under the Apache License, version 2.0 . Tock is promoted and backed by the TOSIT (The Open Source I Trust) association.","title":"Welcome to Tock - open conversational platform"},{"location":"#features","text":"Standalone bots or integrated with Web sites, mobile apps, social networks, smart speakers. Full-featured NLU (Natural Language Understanding) platform, compatible with algorithms such as OpenNLP , Stanford CoreNLP , Duckling , can be deployed alone (for use cases like the Internet Of Things for instance) Tock Studio user interfaces: Models management, bot training Conversational no-code story builder Internationalization ( i18n ) support for multilingual bots Conversations, performance et model errors monitoring Interactive trends / users flow analytics ( Bot Flow ) Frameworks available to develop complex stories and integrate with 3rd-party services: Kotlin DSL plus any-language API Numerous connectors to Messenger , WhatsApp , Google Assistant / Home , Twitter , Alexa , Business Chat / iMessage , Teams , Slack ... (see connectors ) Cloud or on-premise setups, with or without Docker , \"embedded\" bots without Internet","title":"Features"},{"location":"#technologies","text":"Tock runs on JVM platforms. The reference language is Kotlin , but other programming languages can be leveraged through the available APIs. Tock relies on Vert.x and MongoDB . Various NLU libraries and algorithms can be used, such as Apache OpenNLP or Stanford CoreNLP , but Tock does not depend on them directly. Graphical interfaces (Tock Studio) are made with Angular in Typescript .","title":"Technologies"},{"location":"#getting-started","text":"Table of contents Guides and running demo/sandbox platform User , developer and administrator/ops manuals Resources (slides, video) and code samples","title":"Getting started..."},{"location":"api/","text":"You can test a model via the Tock NLP API. Please consult the documentation /api . If you want to test the API, run the docker images and open the url http://localhost/doc/index.html Also, Administration API (in order to manage the models) is documented: /api/admin If you want to test the Admin API, run the docker images and open the url http://localhost/doc/admin.html","title":"Api"},{"location":"build-nlp-model/","text":"Build a New NLU (Natural Language Understanding) Model \u00b6 Overview \u00b6 Seven tabs are available: Try it : add (or test) a new sentence Inbox : not yet qualified sentences Archive : the set of archived sentences, i. e. marked as not yet recognized by the model. Search : an advanced search interface that lets you search for sentences, whether or not they are qualified. Intents : the list of the model's intentions Entities : the list of model entities Logs : the last queries requested via the NLP API The user is redirected by default to Inbox . Add and Qualify Sentences \u00b6 Add a New Sentence \u00b6 Click on the Try It menu and enter the new sentence. The add a new user intent by selecting \"Create a New Intent\" in the \"Intent\" selection list. Declaring Entities \u00b6 If necessary, you can specify the entities of this new intent, by selecting the text of these entities, and then clicking on the \"Add New Entity\" button that has just appeared. It's up to you to choose an existing entity type, or create a new one, and then give that entity a role. Built-in Entities \u00b6 In the window \"Add Entity\", you can see that there are already pre-existing entities (prefixed by duckling ). These are the entities recognized by the eponymous library. These entities will be recognized and valued automatically if you specify them in at least one sentence of the intent. Validate a Sentence \u00b6 If you think that the sentence is qualified correctly, you just have to click on \"Validate\" to confirm that the sentence is ok. If this is not the case, it's up to you to correct the meaning before validating it. You are building your first model! Explore the Model \u00b6 The Search Tab \u00b6 The Search tab allows you to browse all the sentences of the model. The most used criterion is the full text search input (regular expressions are allowed). You can then consult the sentences that are part of your model, and also change the qualifications of these sentences over time. States of a Sentence \u00b6 Each sentence has a state: Inbox : The sentence has not been qualified yet and is not included in the model Validated : The sentence has been validated but is not yet included in the NLP model (this can take some time for large models) Included in model : The sentence has been validated and is included in the model Advanced Features \u00b6 By clicking on the \"Applications\"menu, you get the list of existing applications. Then click of the edit button of the application you want to configure. Nlp Engine Selection \u00b6 You can select the NLP library used by this application with the \"NLP engine\" radio button: Use Built-in Entity Models \u00b6 This option allows you to reuse built-in entity models (ie duckling) in your new intent. For example, if you create an intent with a duckling:datetime entity, the dates will automatically be recognized for that intent in all new sentences assigned to that intent (Internally, a merge is performed between the info given by the built-in entity models and the info of your own model). This option is enabled by default, it can be useful to disable it for very large models, for which the NER detection will perform better in almost all cases. Use sub-entities \u00b6 If you enable this option, you will be able to qualify multiple levels of entities: The number of levels is not limited, but it is advisable not to specify more than 3 or 4. Use predefined values \u00b6 An entity can have predefined values : you just have to click on \"Entities\" tab, and select an entity. A small icon next to the delete icon shows the types of entities you can edit as shown in the picture below:","title":"Build a New NLU (Natural Language Understanding) Model"},{"location":"build-nlp-model/#build-a-new-nlu-natural-language-understanding-model","text":"","title":"Build a New NLU (Natural Language Understanding) Model"},{"location":"build-nlp-model/#overview","text":"Seven tabs are available: Try it : add (or test) a new sentence Inbox : not yet qualified sentences Archive : the set of archived sentences, i. e. marked as not yet recognized by the model. Search : an advanced search interface that lets you search for sentences, whether or not they are qualified. Intents : the list of the model's intentions Entities : the list of model entities Logs : the last queries requested via the NLP API The user is redirected by default to Inbox .","title":"Overview"},{"location":"build-nlp-model/#add-and-qualify-sentences","text":"","title":"Add and Qualify Sentences"},{"location":"build-nlp-model/#add-a-new-sentence","text":"Click on the Try It menu and enter the new sentence. The add a new user intent by selecting \"Create a New Intent\" in the \"Intent\" selection list.","title":"Add a New Sentence"},{"location":"build-nlp-model/#declaring-entities","text":"If necessary, you can specify the entities of this new intent, by selecting the text of these entities, and then clicking on the \"Add New Entity\" button that has just appeared. It's up to you to choose an existing entity type, or create a new one, and then give that entity a role.","title":"Declaring Entities"},{"location":"build-nlp-model/#built-in-entities","text":"In the window \"Add Entity\", you can see that there are already pre-existing entities (prefixed by duckling ). These are the entities recognized by the eponymous library. These entities will be recognized and valued automatically if you specify them in at least one sentence of the intent.","title":"Built-in Entities"},{"location":"build-nlp-model/#validate-a-sentence","text":"If you think that the sentence is qualified correctly, you just have to click on \"Validate\" to confirm that the sentence is ok. If this is not the case, it's up to you to correct the meaning before validating it. You are building your first model!","title":"Validate a Sentence"},{"location":"build-nlp-model/#explore-the-model","text":"","title":"Explore the Model"},{"location":"build-nlp-model/#the-search-tab","text":"The Search tab allows you to browse all the sentences of the model. The most used criterion is the full text search input (regular expressions are allowed). You can then consult the sentences that are part of your model, and also change the qualifications of these sentences over time.","title":"The Search Tab"},{"location":"build-nlp-model/#states-of-a-sentence","text":"Each sentence has a state: Inbox : The sentence has not been qualified yet and is not included in the model Validated : The sentence has been validated but is not yet included in the NLP model (this can take some time for large models) Included in model : The sentence has been validated and is included in the model","title":"States of a Sentence"},{"location":"build-nlp-model/#advanced-features","text":"By clicking on the \"Applications\"menu, you get the list of existing applications. Then click of the edit button of the application you want to configure.","title":"Advanced Features"},{"location":"build-nlp-model/#nlp-engine-selection","text":"You can select the NLP library used by this application with the \"NLP engine\" radio button:","title":"Nlp Engine Selection"},{"location":"build-nlp-model/#use-built-in-entity-models","text":"This option allows you to reuse built-in entity models (ie duckling) in your new intent. For example, if you create an intent with a duckling:datetime entity, the dates will automatically be recognized for that intent in all new sentences assigned to that intent (Internally, a merge is performed between the info given by the built-in entity models and the info of your own model). This option is enabled by default, it can be useful to disable it for very large models, for which the NER detection will perform better in almost all cases.","title":"Use Built-in Entity Models"},{"location":"build-nlp-model/#use-sub-entities","text":"If you enable this option, you will be able to qualify multiple levels of entities: The number of levels is not limited, but it is advisable not to specify more than 3 or 4.","title":"Use sub-entities"},{"location":"build-nlp-model/#use-predefined-values","text":"An entity can have predefined values : you just have to click on \"Entities\" tab, and select an entity. A small icon next to the delete icon shows the types of entities you can edit as shown in the picture below:","title":"Use predefined values"},{"location":"code-a-bot/","text":"Tock's Conversationnal Language \u00b6 To develop a bot or an assistant with Tock, you can use its conversational DSL (Domain Specific Language) developed in Kotlin . Add the bot-toolkit Dependency \u00b6 The bot-toolkit dependency is required: With Maven: <dependency> <groupId> ai.tock </groupId> <artifactId> bot-toolkit </artifactId> <version> 19.3.3 </version> </dependency> With Gradle: compile 'ai.tock:bot-toolkit:19.3.3' A Bot is a Set of Stories \u00b6 This is how the open data bot is defined: val openBot = bot ( \"bot_open_data\" , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) This bot has an unique identifier (required - \"bot_open_data\") and a list of \"Story\" . A Story is a functional subset that has a main intention and, optionally, one or more so-called \"secondary\" intentions. Here the bot defines 4 Stories , greetings, departures, arrivals and search. Greetings is also set ( hello = greetings ) as the default story used for a new dialog. A Simple Story \u00b6 How do you define a story? Here is a first simplified version of the story greetings : val greetings = story ( \"greetings\" ) { send ( \"Welcome to the Tock Open Data Bot! :)\" ) end ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } Note that in the body of the function, this has a BotBus type. From which you can interact with the user, and which also allows you to access to all available contextual elements. When the intention greetings will be detected by the NLP model, the function above will be called by the Tock framework. The bot sends successively a first response sentence ( bus.send() ), then a second one indicating that it is the last sentence of his answer using a bus.end() . Here is the full version of greetings : val greetings = story ( \"greetings\" ) { //cleanup state resetDialogState () send ( \"Welcome to the Tock Open Data Bot! :)\" ) send ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) withMessenger { buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) } withGoogleAssistant { gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) } end () } Two notions have been added: resetDialogState() which cleanup the state (forgetting any previous context). the withMessenger{} and withGoogleAssistant{} methods that define specific responses for each connector - Here it's a text with buttons for Messenger, and a text with suggestions for Google Assistant. Start and Connect the Bot \u00b6 To start the bot, simply add the following call to your main function: registerAndInstallBot ( openBot ) where the openBot variable is the bot you originally defined. When the bot is started, you also need to specify which connectors are used in the web administration interface: Configuration -> Bot Configurations -> Create a new configuration The documentation for each connector is in the README file of the corresponding sub-projects. Five are available by default: Messenger Google Assistant Slack RocketChat Twitter WhatsApp Teams Alexa - for Alexa, the NLP model is necessarily managed on Amazon side. So only the conversational framework of Tock can be used with this connector. Advanced options \u00b6 Of course, the StoryHandler of greetings does not depend on the context: the answer is always the same. Secondary Intentions \u00b6 Here is the beginning of the definition of the search story : val search = storyDef < SearchDef >( \"search\" , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } The story search defines a secondary starter intent ( indicate_origin ) and a simple secondary intent ( indicate_location ). A secondary starter intent is similar in every respect to the main intent: as soon as the intent is detected, if the current story does not contain indicate_origin as secondary intent, the story search is called. For a classic secondary intent, on the other hand, the story will be executed only if the current story of the context is already the search story. Different stories can therefore share the same secondary intents. Handle Entities \u00b6 To retrieve entity values, it is good practice to define Kotlin extensions . For example here is the code used to retrieve the destination entity: val destinationEntity = openBot . entity ( \"location\" , \"destination\" ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) An entity of type \"location\" and role \"destination\" is created. There is a corresponding entity in the NLP model. A variable destination is defined, which will simplify the handling of this entity in the conversational code. This variable contains the current value of the destination in the user context. Here's a full version of the search story that uses destination : val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } If there is no value in the current context for the destination, the bot asks to specify the destination and stays there. Same behaviour for the origin or date of departure. If the 3 required values are specified, then the real answer developed in the SearchDef class is used. Here is the full version of this first part of the code: val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) && location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } In the case where the detected intention is indicate_location , we do not know if the locality represents the origin or the destination. A simple rule is then used: If there is already in the context an origin and no destination, the new locality is actually the destination. Otherwise, it is the origin. HandlerDef \u00b6 In the search story above, you may have noted the generic SearchDef typing. Here is the code of this class: @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef < SearchConnector >( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( \"From {0} to {1}\" , o , d ) send ( \"Departure on {0}\" , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( \"Sorry, no routes found :(\" ) } else { send ( \"Here is the first proposal:\" ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef extends HandlerDef which is an alias of a Tock framework class. It is usually here that the code of complex stories is defined. The code contains an additional abstraction: SearchConnector . SearchConnector is the class that defines the behavior specific to each connector, and the annotations @GAHandler (GASearchConnector::class) and @MessengerHandler (MessengerSearchConnector::class) indicate the corresponding implementations for the different supported connectors (respectively Google Assistant and Messenger). What would happen there is no connector for Google Assistant for example, and if a call from Google Assistant is answered? The connector?.sendFirstJourney(journeys.first()) method call would not send the final response, since connector would be null . ConnectorDef \u00b6 Here is a simplified version of SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef < SearchDef >( context ) { fun Section . title (): CharSequence = i18n ( \"{0} - {1}\" , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List < Section >): ConnectorMessage } And its Messenger implementation: class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List < Section >): ConnectorMessage = flexibleListTemplate ( sections . map { section -> with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } The code specific to each connector is thus decoupled correctly. The code common to each connector is present in SearchConnector and the behavior specific to each connector is specified in the dedicated classes. StoryStep \u00b6 Sometimes you need to remember the stage at which the user is in the current story. For this, Tock provides the concept of StoryStep . There are two types of StoryStep. SimpleStoryStep \u00b6 enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps < MyStep >( \"intent\" ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } To modify the current step, two methods are available: Manually change the step val story = storyWithSteps < MyStep >( \"intent\" ) { //(...) step = MyStep . a // the step will be persisted as long as we stay in this story } Use buttons or quick replies More details on this topic here . StorySteps with complex behavior \u00b6 In more complex cases, we want to be able to define a behavior for each step. enum class MySteps : StoryStep < MyHandlerDef > { //no specific behaviour display , select { // \"select\" step will be automatically selected if the select sub-intention is detected override val intent : IntentAware ? = SecondaryIntent . select override fun answer (): MyHandlerDef .() -> Any ? = { end ( \"I don't know yet how to select something\" ) } }, disruption { override fun answer (): ScoreboardDef .() -> Any ? = { end ( \"some perturbation\" ) } }; } More configuration options are available. Check out the description of StoryStep . Postback buttons & quick replies \u00b6 Messenger provides this type of button, as most connectors with GUI. With Tock, you can easily define the action performed after clicking on these buttons. In the following example, the button will redirect to the \"search\" intent: buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , search ) ) It is also possible to define a * StoryStep * and dedicated parameters: //to define parameters, just extend the ParameterKey interface enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , intent = search , //if no step is specified, the current step is used step = MyStep . a , parameters = //this parameter is stored as a string (hooks are used) nextResultDate [ nextDate ] + //this parameter is stored in json (parentheses are used) nextResultOrigin ( origin ) ) ) To retrieve the parameters of the button that was clicked: val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin ) Define your own connector \u00b6 It is possible to develop its own connector. 1) Implement the interface Connector Here is an example of implementation: val testConnectorType = ConnectorType ( \"test\" ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router -> //main API router . post ( \"$path/message\" ). blockingHandler { context -> //ConnectorRequest is my business object passed by the front app val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //business object mapped to Tock event val event = readUserMessage ( message ) //we pass the Tock event to the framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //we record the action callback . actions . add ( event ) //if it's the last action to send, send the answer if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { \"unsupported event: $event\" } } } } // to retrieve all actions before sending class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList < Action > = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //we transform the list of Tock responses into a business response val response = mapper . writeValueAsString ( actions . map {...}) //then we send the answer context . response (). end ( response ) } } 2) Implement the interface ConnectorProvider Here is an example of implementation: object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Make this connector available via a Service Loader By placing a file META-INF/services/fr.vsct.tock.bot.connector.ConnectorProvider in the classpath, containing the class name : mypackage . TestConnectorProviderService 4) Add all classes and files created in the admin classpath and bot classpath The new connector must then be available in the \"Bot Configurations\" administration interface.","title":"Tock's Conversationnal Language"},{"location":"code-a-bot/#tocks-conversationnal-language","text":"To develop a bot or an assistant with Tock, you can use its conversational DSL (Domain Specific Language) developed in Kotlin .","title":"Tock's Conversationnal Language"},{"location":"code-a-bot/#add-the-bot-toolkit-dependency","text":"The bot-toolkit dependency is required: With Maven: <dependency> <groupId> ai.tock </groupId> <artifactId> bot-toolkit </artifactId> <version> 19.3.3 </version> </dependency> With Gradle: compile 'ai.tock:bot-toolkit:19.3.3'","title":"Add the bot-toolkit Dependency"},{"location":"code-a-bot/#a-bot-is-a-set-of-stories","text":"This is how the open data bot is defined: val openBot = bot ( \"bot_open_data\" , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) This bot has an unique identifier (required - \"bot_open_data\") and a list of \"Story\" . A Story is a functional subset that has a main intention and, optionally, one or more so-called \"secondary\" intentions. Here the bot defines 4 Stories , greetings, departures, arrivals and search. Greetings is also set ( hello = greetings ) as the default story used for a new dialog.","title":"A Bot is a Set of Stories"},{"location":"code-a-bot/#a-simple-story","text":"How do you define a story? Here is a first simplified version of the story greetings : val greetings = story ( \"greetings\" ) { send ( \"Welcome to the Tock Open Data Bot! :)\" ) end ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } Note that in the body of the function, this has a BotBus type. From which you can interact with the user, and which also allows you to access to all available contextual elements. When the intention greetings will be detected by the NLP model, the function above will be called by the Tock framework. The bot sends successively a first response sentence ( bus.send() ), then a second one indicating that it is the last sentence of his answer using a bus.end() . Here is the full version of greetings : val greetings = story ( \"greetings\" ) { //cleanup state resetDialogState () send ( \"Welcome to the Tock Open Data Bot! :)\" ) send ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) withMessenger { buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) } withGoogleAssistant { gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) } end () } Two notions have been added: resetDialogState() which cleanup the state (forgetting any previous context). the withMessenger{} and withGoogleAssistant{} methods that define specific responses for each connector - Here it's a text with buttons for Messenger, and a text with suggestions for Google Assistant.","title":"A Simple Story"},{"location":"code-a-bot/#start-and-connect-the-bot","text":"To start the bot, simply add the following call to your main function: registerAndInstallBot ( openBot ) where the openBot variable is the bot you originally defined. When the bot is started, you also need to specify which connectors are used in the web administration interface: Configuration -> Bot Configurations -> Create a new configuration The documentation for each connector is in the README file of the corresponding sub-projects. Five are available by default: Messenger Google Assistant Slack RocketChat Twitter WhatsApp Teams Alexa - for Alexa, the NLP model is necessarily managed on Amazon side. So only the conversational framework of Tock can be used with this connector.","title":"Start and Connect the Bot"},{"location":"code-a-bot/#advanced-options","text":"Of course, the StoryHandler of greetings does not depend on the context: the answer is always the same.","title":"Advanced options"},{"location":"code-a-bot/#secondary-intentions","text":"Here is the beginning of the definition of the search story : val search = storyDef < SearchDef >( \"search\" , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } The story search defines a secondary starter intent ( indicate_origin ) and a simple secondary intent ( indicate_location ). A secondary starter intent is similar in every respect to the main intent: as soon as the intent is detected, if the current story does not contain indicate_origin as secondary intent, the story search is called. For a classic secondary intent, on the other hand, the story will be executed only if the current story of the context is already the search story. Different stories can therefore share the same secondary intents.","title":"Secondary Intentions"},{"location":"code-a-bot/#handle-entities","text":"To retrieve entity values, it is good practice to define Kotlin extensions . For example here is the code used to retrieve the destination entity: val destinationEntity = openBot . entity ( \"location\" , \"destination\" ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) An entity of type \"location\" and role \"destination\" is created. There is a corresponding entity in the NLP model. A variable destination is defined, which will simplify the handling of this entity in the conversational code. This variable contains the current value of the destination in the user context. Here's a full version of the search story that uses destination : val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } If there is no value in the current context for the destination, the bot asks to specify the destination and stays there. Same behaviour for the origin or date of departure. If the 3 required values are specified, then the real answer developed in the SearchDef class is used. Here is the full version of this first part of the code: val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) && location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } In the case where the detected intention is indicate_location , we do not know if the locality represents the origin or the destination. A simple rule is then used: If there is already in the context an origin and no destination, the new locality is actually the destination. Otherwise, it is the origin.","title":"Handle Entities"},{"location":"code-a-bot/#handlerdef","text":"In the search story above, you may have noted the generic SearchDef typing. Here is the code of this class: @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef < SearchConnector >( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( \"From {0} to {1}\" , o , d ) send ( \"Departure on {0}\" , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( \"Sorry, no routes found :(\" ) } else { send ( \"Here is the first proposal:\" ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef extends HandlerDef which is an alias of a Tock framework class. It is usually here that the code of complex stories is defined. The code contains an additional abstraction: SearchConnector . SearchConnector is the class that defines the behavior specific to each connector, and the annotations @GAHandler (GASearchConnector::class) and @MessengerHandler (MessengerSearchConnector::class) indicate the corresponding implementations for the different supported connectors (respectively Google Assistant and Messenger). What would happen there is no connector for Google Assistant for example, and if a call from Google Assistant is answered? The connector?.sendFirstJourney(journeys.first()) method call would not send the final response, since connector would be null .","title":"HandlerDef"},{"location":"code-a-bot/#connectordef","text":"Here is a simplified version of SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef < SearchDef >( context ) { fun Section . title (): CharSequence = i18n ( \"{0} - {1}\" , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List < Section >): ConnectorMessage } And its Messenger implementation: class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List < Section >): ConnectorMessage = flexibleListTemplate ( sections . map { section -> with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } The code specific to each connector is thus decoupled correctly. The code common to each connector is present in SearchConnector and the behavior specific to each connector is specified in the dedicated classes.","title":"ConnectorDef"},{"location":"code-a-bot/#storystep","text":"Sometimes you need to remember the stage at which the user is in the current story. For this, Tock provides the concept of StoryStep . There are two types of StoryStep.","title":"StoryStep"},{"location":"code-a-bot/#simplestorystep","text":"enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps < MyStep >( \"intent\" ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } To modify the current step, two methods are available: Manually change the step val story = storyWithSteps < MyStep >( \"intent\" ) { //(...) step = MyStep . a // the step will be persisted as long as we stay in this story } Use buttons or quick replies More details on this topic here .","title":"SimpleStoryStep"},{"location":"code-a-bot/#storysteps-with-complex-behavior","text":"In more complex cases, we want to be able to define a behavior for each step. enum class MySteps : StoryStep < MyHandlerDef > { //no specific behaviour display , select { // \"select\" step will be automatically selected if the select sub-intention is detected override val intent : IntentAware ? = SecondaryIntent . select override fun answer (): MyHandlerDef .() -> Any ? = { end ( \"I don't know yet how to select something\" ) } }, disruption { override fun answer (): ScoreboardDef .() -> Any ? = { end ( \"some perturbation\" ) } }; } More configuration options are available. Check out the description of StoryStep .","title":"StorySteps with complex behavior"},{"location":"code-a-bot/#postback-buttons-quick-replies","text":"Messenger provides this type of button, as most connectors with GUI. With Tock, you can easily define the action performed after clicking on these buttons. In the following example, the button will redirect to the \"search\" intent: buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , search ) ) It is also possible to define a * StoryStep * and dedicated parameters: //to define parameters, just extend the ParameterKey interface enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , intent = search , //if no step is specified, the current step is used step = MyStep . a , parameters = //this parameter is stored as a string (hooks are used) nextResultDate [ nextDate ] + //this parameter is stored in json (parentheses are used) nextResultOrigin ( origin ) ) ) To retrieve the parameters of the button that was clicked: val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin )","title":"Postback buttons &amp; quick replies"},{"location":"code-a-bot/#define-your-own-connector","text":"It is possible to develop its own connector. 1) Implement the interface Connector Here is an example of implementation: val testConnectorType = ConnectorType ( \"test\" ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router -> //main API router . post ( \"$path/message\" ). blockingHandler { context -> //ConnectorRequest is my business object passed by the front app val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //business object mapped to Tock event val event = readUserMessage ( message ) //we pass the Tock event to the framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //we record the action callback . actions . add ( event ) //if it's the last action to send, send the answer if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { \"unsupported event: $event\" } } } } // to retrieve all actions before sending class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList < Action > = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //we transform the list of Tock responses into a business response val response = mapper . writeValueAsString ( actions . map {...}) //then we send the answer context . response (). end ( response ) } } 2) Implement the interface ConnectorProvider Here is an example of implementation: object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Make this connector available via a Service Loader By placing a file META-INF/services/fr.vsct.tock.bot.connector.ConnectorProvider in the classpath, containing the class name : mypackage . TestConnectorProviderService 4) Add all classes and files created in the admin classpath and bot classpath The new connector must then be available in the \"Bot Configurations\" administration interface.","title":"Define your own connector"},{"location":"contact/","text":"Contact us \u00b6 Developers, users, or simply curious, don't hesitate to get in touch with Tock creators and other community members, to share about the platform. Contact us on Gitter (the IM service for GitHub) : https://gitter.im/tockchat/Lobby GitHub issues can be used to report bugs, propose enhancements or features : https://github.com/theopenconversationkit/tock/issues","title":"Contact us"},{"location":"contact/#contact-us","text":"Developers, users, or simply curious, don't hesitate to get in touch with Tock creators and other community members, to share about the platform. Contact us on Gitter (the IM service for GitHub) : https://gitter.im/tockchat/Lobby GitHub issues can be used to report bugs, propose enhancements or features : https://github.com/theopenconversationkit/tock/issues","title":"Contact us"},{"location":"contribute/","text":"Contribute to the Tock project \u00b6 Build the project \u00b6 The project uses Maven . mvn package A CI build is available on Travis . Start the project in the IDE \u00b6 In addition to docker images , the project provides IntelliJ configurations: The bot administration server: BotAdmin The NLP administration server only: Admin The NLP service: NlpService The Duckling service: Duckling Build engine for NLP models: BuildWorker To manage script compilation at runtime: KotlinCompilerServer And for the open data bot: OpenDataBot In order to launch the administration front interfaces, please consult the README files: For bot and NLP administration interface For NLP administration only Code conventions \u00b6 Conventions are described in Kotlin Code Conventions","title":"Contribute to the Tock project"},{"location":"contribute/#contribute-to-the-tock-project","text":"","title":"Contribute to the Tock project"},{"location":"contribute/#build-the-project","text":"The project uses Maven . mvn package A CI build is available on Travis .","title":"Build the project"},{"location":"contribute/#start-the-project-in-the-ide","text":"In addition to docker images , the project provides IntelliJ configurations: The bot administration server: BotAdmin The NLP administration server only: Admin The NLP service: NlpService The Duckling service: Duckling Build engine for NLP models: BuildWorker To manage script compilation at runtime: KotlinCompilerServer And for the open data bot: OpenDataBot In order to launch the administration front interfaces, please consult the README files: For bot and NLP administration interface For NLP administration only","title":"Start the project in the IDE"},{"location":"contribute/#code-conventions","text":"Conventions are described in Kotlin Code Conventions","title":"Code conventions"},{"location":"evaluate-the-model/","text":"Evaluate the relevance of a NLP model \u00b6 Tabs \u00b6 Five tabs are used to control the relevance of the model: Stats : Monitores model perfomance in production: self-evaluation of the model about its relevance in terms of recognition of intent and entities number of calls and errors average execution time Test Trend : evolution of the relevance of partial model tests Intent Errors : the list of intent errors found with partial model tests Entity Errors : the list of entity errors found with partial model tests Model Builds : the cimplete list of model builds Partial Model Tests \u00b6 Partial model tests is a way to detect qualifications errors. Temporarily models are built from a random part of the whole sentence set of the model (90% for example) and then tested against the remaining sentences. The process is repeated a number of times and the most frequent errors are pushed to an admin user. Partial model tests are useful only with large models. Intent errors \u00b6 Click on the Intent Errors tab: Since the picture above is built from a very simple model, no real error has been detected. We can nevertheless note that in some cases the model is systematically wrong with a high probability. Entity errors \u00b6 These errors can be viewed via the Entity Errors tab.","title":"Evaluate the relevance of a NLP model"},{"location":"evaluate-the-model/#evaluate-the-relevance-of-a-nlp-model","text":"","title":"Evaluate the relevance of a NLP model"},{"location":"evaluate-the-model/#tabs","text":"Five tabs are used to control the relevance of the model: Stats : Monitores model perfomance in production: self-evaluation of the model about its relevance in terms of recognition of intent and entities number of calls and errors average execution time Test Trend : evolution of the relevance of partial model tests Intent Errors : the list of intent errors found with partial model tests Entity Errors : the list of entity errors found with partial model tests Model Builds : the cimplete list of model builds","title":"Tabs"},{"location":"evaluate-the-model/#partial-model-tests","text":"Partial model tests is a way to detect qualifications errors. Temporarily models are built from a random part of the whole sentence set of the model (90% for example) and then tested against the remaining sentences. The process is repeated a number of times and the most frequent errors are pushed to an admin user. Partial model tests are useful only with large models.","title":"Partial Model Tests"},{"location":"evaluate-the-model/#intent-errors","text":"Click on the Intent Errors tab: Since the picture above is built from a very simple model, no real error has been detected. We can nevertheless note that in some cases the model is systematically wrong with a high probability.","title":"Intent errors"},{"location":"evaluate-the-model/#entity-errors","text":"These errors can be viewed via the Entity Errors tab.","title":"Entity errors"},{"location":"getting-started/","text":"Getting Started \u00b6 A Sample Bot \u00b6 A sample bot using Tock is available: https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit. Docker Images \u00b6 Docker images are available in the Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker . Start the NLP stack \u00b6 #get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80: http://localhost The default login is admin@app.com and the password is password . Sample bot based on Open Data APIs \u00b6 A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images . Administration Interface Menu \u00b6 The Configuration menu allows you to create new models and configure them. The NLP and NLP QA menus are dedicated to building NLP models. The Build , Test and Monitoring menus are used for building bots or assistants.","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#a-sample-bot","text":"A sample bot using Tock is available: https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit.","title":"A Sample Bot"},{"location":"getting-started/#docker-images","text":"Docker images are available in the Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker .","title":"Docker Images"},{"location":"getting-started/#start-the-nlp-stack","text":"#get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80: http://localhost The default login is admin@app.com and the password is password .","title":"Start the NLP stack"},{"location":"getting-started/#sample-bot-based-on-open-data-apis","text":"A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images .","title":"Sample bot based on Open Data APIs"},{"location":"getting-started/#administration-interface-menu","text":"The Configuration menu allows you to create new models and configure them. The NLP and NLP QA menus are dedicated to building NLP models. The Build , Test and Monitoring menus are used for building bots or assistants.","title":"Administration Interface Menu"},{"location":"i18n/","text":"Translate bot responses \u00b6 Activation \u00b6 The Tock framework provides an internationalization framework. It is disabled by default. To activate it, add this code when starting the bot: Translator . enabled = true or set the system property -Dtock_i18n_enabled=true . How to develop for more than one locale \u00b6 Let's Code \u00b6 The code does not change once the internationalization is activated. For example: send ( \"Arrival at {0}\" , time ) is a valid code whether the module is activated or not. On the other hand, at runtime, the behavior differs significantly. If internationalization is enabled, the following operations will be performed: A key will be generated from the text passed in parameter, according to the namespace (the organization of the creator of the bot) and the story in which this wording is requested. In the case above, it will look like app_arrivals_arrival_Arrival at {0} where app is the namespace and arrivals the main intention of the story. The framework checks if this key is already present. If this is the case, it uses the label present in the database for the requested locale to find the most appropriate translation (the connector or the type of interface can also be taken into account) Otherwise, a key is created with the default label (\"Arrival at {0}\" in our example) used for the current locale It is then possible to consult and modify this label in the administration interface: Supported format \u00b6 The supported format is the standard i18n java format used by MessageFormat and ChoiceFormat : send ( \"There {0,choice,0#are no files|1#is one file|1<are {0,number,integer} files}.\" , 2 ) In addition, Tock provides a by extension for dates that allows you to specify a dedicated format for the parameters: send ( \"Departure at {0}\" , departureDateTime by timeFormat ) User Locale \u00b6 When possible, the user locale is imported from the user account of the connector. For example, if the Messenger account is configured in French, French will be automatically used as the user locale by Tock. If there is no account locale, the defaultLocale value is taken into account. You can modify this default value with a system property: -Dtock_default_locale=fr Finally it is possible to modify the locale of the user in the bot itself: userPreferences . locale = Locale . FRENCH Points of attention \u00b6 Tock's internationalization module is effective, but some practices, yet intuitive in Kotlin, are to be banished. For example, this code works perfectly well with the disabled i18n module. send ( \"There are $nb files\" ) //DANGER!! but is problematic if i18n is enabled. A new label will be inserted for each different value of the nb variable! If it is necessary to send \"not to translate\" answers, use BotBus.sendRaw , BotBus.endRaw , or String.raw methods. send ( \"There are $nb files\" . raw ) //CORRECT send ( \"There are {0} files\" , nb ) //BETTER The risk of collision between two labels is low since the main intention of the story is part of the key. However, if you want to avoid any risk, you can use the i18nKey method: send ( i18nKey ( \"my_unique_key\" , \"There are {0} files\" , nb )) Test internationalization \u00b6 An example of an i18n test is available in the open data bot source code . You need to use a custom test extension to indicate the label translations . And the test looks like: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Recherche\" , search , locale = Locale . FRENCH ) { destination = lille origin = paris run () firstAnswer . assertText ( \"Quand souhaitez-vous partir?\" ) } } Administration interface \u00b6 The different variants \u00b6 Each label has a default value for each language of the bot. It is also possible to indicate specific answers: by connector type (Messenger, Google Assistant, Slack, etc.) by type of interface (Text or voice) - this is useful for example in the case of Google Assistant to support the voice only use cases. Finally, you can specify alternatives . In this case, the bot uses one of the possible alternatives at random, each time it sends a response to the user. Import and export of data \u00b6 Labels import/export (json or csv format) is available. When importing, only labels indicated as validated are taken into account.","title":"Translate bot responses"},{"location":"i18n/#translate-bot-responses","text":"","title":"Translate bot responses"},{"location":"i18n/#activation","text":"The Tock framework provides an internationalization framework. It is disabled by default. To activate it, add this code when starting the bot: Translator . enabled = true or set the system property -Dtock_i18n_enabled=true .","title":"Activation"},{"location":"i18n/#how-to-develop-for-more-than-one-locale","text":"","title":"How to develop for more than one locale"},{"location":"i18n/#lets-code","text":"The code does not change once the internationalization is activated. For example: send ( \"Arrival at {0}\" , time ) is a valid code whether the module is activated or not. On the other hand, at runtime, the behavior differs significantly. If internationalization is enabled, the following operations will be performed: A key will be generated from the text passed in parameter, according to the namespace (the organization of the creator of the bot) and the story in which this wording is requested. In the case above, it will look like app_arrivals_arrival_Arrival at {0} where app is the namespace and arrivals the main intention of the story. The framework checks if this key is already present. If this is the case, it uses the label present in the database for the requested locale to find the most appropriate translation (the connector or the type of interface can also be taken into account) Otherwise, a key is created with the default label (\"Arrival at {0}\" in our example) used for the current locale It is then possible to consult and modify this label in the administration interface:","title":"Let's Code"},{"location":"i18n/#supported-format","text":"The supported format is the standard i18n java format used by MessageFormat and ChoiceFormat : send ( \"There {0,choice,0#are no files|1#is one file|1<are {0,number,integer} files}.\" , 2 ) In addition, Tock provides a by extension for dates that allows you to specify a dedicated format for the parameters: send ( \"Departure at {0}\" , departureDateTime by timeFormat )","title":"Supported format"},{"location":"i18n/#user-locale","text":"When possible, the user locale is imported from the user account of the connector. For example, if the Messenger account is configured in French, French will be automatically used as the user locale by Tock. If there is no account locale, the defaultLocale value is taken into account. You can modify this default value with a system property: -Dtock_default_locale=fr Finally it is possible to modify the locale of the user in the bot itself: userPreferences . locale = Locale . FRENCH","title":"User Locale"},{"location":"i18n/#points-of-attention","text":"Tock's internationalization module is effective, but some practices, yet intuitive in Kotlin, are to be banished. For example, this code works perfectly well with the disabled i18n module. send ( \"There are $nb files\" ) //DANGER!! but is problematic if i18n is enabled. A new label will be inserted for each different value of the nb variable! If it is necessary to send \"not to translate\" answers, use BotBus.sendRaw , BotBus.endRaw , or String.raw methods. send ( \"There are $nb files\" . raw ) //CORRECT send ( \"There are {0} files\" , nb ) //BETTER The risk of collision between two labels is low since the main intention of the story is part of the key. However, if you want to avoid any risk, you can use the i18nKey method: send ( i18nKey ( \"my_unique_key\" , \"There are {0} files\" , nb ))","title":"Points of attention"},{"location":"i18n/#test-internationalization","text":"An example of an i18n test is available in the open data bot source code . You need to use a custom test extension to indicate the label translations . And the test looks like: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Recherche\" , search , locale = Locale . FRENCH ) { destination = lille origin = paris run () firstAnswer . assertText ( \"Quand souhaitez-vous partir?\" ) } }","title":"Test internationalization"},{"location":"i18n/#administration-interface","text":"","title":"Administration interface"},{"location":"i18n/#the-different-variants","text":"Each label has a default value for each language of the bot. It is also possible to indicate specific answers: by connector type (Messenger, Google Assistant, Slack, etc.) by type of interface (Text or voice) - this is useful for example in the case of Google Assistant to support the voice only use cases. Finally, you can specify alternatives . In this case, the bot uses one of the possible alternatives at random, each time it sends a response to the user.","title":"The different variants"},{"location":"i18n/#import-and-export-of-data","text":"Labels import/export (json or csv format) is available. When importing, only labels indicated as validated are taken into account.","title":"Import and export of data"},{"location":"kdoc/","text":"A KDoc documentation is provided .","title":"Kdoc"},{"location":"test-the-bot/","text":"Use the Test Framework \u00b6 Tock provides extensions in order to help writing better unit tests. To use them, you need to add the bot-test dependency to your project. With Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> bot-test </artifactId> <version> 19.3.3 </version> <scope> test </scope> </dependency> With Gradle : testCompile 'ai.tock:bot-test:19.3.3' This framework is documented in KDoc format here . Write a Simple Test \u00b6 In the next samples, JUnit5 is used as test engine. A dedicated extension for Tock is available . @RegisterExtension @JvmField val ext = TockJUnit5Extension () To test the greetings story of the Open Data bot, just use the ext.send() method: @Test fun `greetings story displays welcome message` () { ext . send { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } } As the default connector is Messenger, it is possible to test the message specific to Messenger in the same way: @Test fun `greetings story displays welcome message with Messenger dedicated message` () { ext . send { lastAnswer . assertMessage ( buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) ) } } To test the message specific to Google Assistant (or any other connector), you need to indicate the connector to be tested: @Test fun `greetings story displays welcome message with GA dedicated message WHEN context contains GA connector` () { ext . send ( connectorType = gaConnectorType ) { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) lastAnswer . assertMessage ( gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) ) } } Test a specific Story \u00b6 In the previous examples, it was useless to specify the story to test ( greetings being the default story). Suppose you want to test the search story, then you need to indicate the story to test as follows: @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search ) { firstAnswer . assertText ( \"For which destination?\" ) } } Test a Conversation \u00b6 You can simulate a whole conversation. For example, here the user indicates the destination, then the origin: @Test fun `search story asks for origin WHEN there is a destination BUT no origin in context` () { ext . send ( \"I would like to find a train\" , search ) { firstAnswer . assertText ( \"For which destination?\" ) } ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( \"For which origin?\" ) } ext . send ( \"Paris\" , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( \"When?\" ) } } The first text parameter of the send method is merely indicative, to help understanding the tests. The others parameters defines how the NLP engine has analysed the text. For example : private val lille = PlaceValue ( SncfPlace ( \"stop_area\" , 90 , \"Lille Europe\" , \"Lille Europe (Lille)\" , \"stop_area:OCE:SA:87223263\" , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) indicate that the phrase \"Lille\" is categorized as an indicate_location intent with a value lille for the entity location . Finally it is possible to modify all the values of the mocked bus at initialization. In the following example, the use of the secondary intent indicate_location is simulated to indicate the origin: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Search\" , search ) { destination = lille origin = paris run () firstAnswer . assertText ( \"When?\" ) } } The destination and origin variables are updated, then a call to the bus is simulated with the function run() .","title":"Use the Test Framework"},{"location":"test-the-bot/#use-the-test-framework","text":"Tock provides extensions in order to help writing better unit tests. To use them, you need to add the bot-test dependency to your project. With Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> bot-test </artifactId> <version> 19.3.3 </version> <scope> test </scope> </dependency> With Gradle : testCompile 'ai.tock:bot-test:19.3.3' This framework is documented in KDoc format here .","title":"Use the Test Framework"},{"location":"test-the-bot/#write-a-simple-test","text":"In the next samples, JUnit5 is used as test engine. A dedicated extension for Tock is available . @RegisterExtension @JvmField val ext = TockJUnit5Extension () To test the greetings story of the Open Data bot, just use the ext.send() method: @Test fun `greetings story displays welcome message` () { ext . send { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } } As the default connector is Messenger, it is possible to test the message specific to Messenger in the same way: @Test fun `greetings story displays welcome message with Messenger dedicated message` () { ext . send { lastAnswer . assertMessage ( buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) ) } } To test the message specific to Google Assistant (or any other connector), you need to indicate the connector to be tested: @Test fun `greetings story displays welcome message with GA dedicated message WHEN context contains GA connector` () { ext . send ( connectorType = gaConnectorType ) { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) lastAnswer . assertMessage ( gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) ) } }","title":"Write a Simple Test"},{"location":"test-the-bot/#test-a-specific-story","text":"In the previous examples, it was useless to specify the story to test ( greetings being the default story). Suppose you want to test the search story, then you need to indicate the story to test as follows: @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search ) { firstAnswer . assertText ( \"For which destination?\" ) } }","title":"Test a specific Story"},{"location":"test-the-bot/#test-a-conversation","text":"You can simulate a whole conversation. For example, here the user indicates the destination, then the origin: @Test fun `search story asks for origin WHEN there is a destination BUT no origin in context` () { ext . send ( \"I would like to find a train\" , search ) { firstAnswer . assertText ( \"For which destination?\" ) } ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( \"For which origin?\" ) } ext . send ( \"Paris\" , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( \"When?\" ) } } The first text parameter of the send method is merely indicative, to help understanding the tests. The others parameters defines how the NLP engine has analysed the text. For example : private val lille = PlaceValue ( SncfPlace ( \"stop_area\" , 90 , \"Lille Europe\" , \"Lille Europe (Lille)\" , \"stop_area:OCE:SA:87223263\" , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) indicate that the phrase \"Lille\" is categorized as an indicate_location intent with a value lille for the entity location . Finally it is possible to modify all the values of the mocked bus at initialization. In the following example, the use of the secondary intent indicate_location is simulated to indicate the origin: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Search\" , search ) { destination = lille origin = paris run () firstAnswer . assertText ( \"When?\" ) } } The destination and origin variables are updated, then a call to the bus is simulated with the function run() .","title":"Test a Conversation"},{"location":"the-open-data-bot/","text":"Getting Started with the Conversational Framework \u00b6 The Open Data Bot \u00b6 A good starting point is the source code of the Open Data Bot Follow the instructions of the README file of the project, to start the bot in the IDE (do not configure Messenger or Google Assistant at this point), then connect to the administration interface. The bot is already testable. The Test Tab \u00b6 Go to this tab, and test the bot: This is a test mode, so the interface is minimal. The real goal is to have your users interact with the bot via channels like Messenger, Google Assistant ... or your sites or applications. The Monitoring Tab \u00b6 It is then possible to consult the discussion that you just had with the bot via the Monitoring tab: In this sample, this dialog has the Messenger flag, as it was tested for this channel. The Build Tab \u00b6 Add a new answer \u00b6 With the category Add new Answer , it is possible to add directly a new answer: Then test the new intention and its answer: Modify the Answers and Internationalization \u00b6 Finally it is possible to modify each answer of the bot, by type of interface (chat / voice), by type of connector and by language with the i18n tab. The ability to add alternative answers (a response from the list will be chosen each time at random) is also provided (with the \"plus\" button).","title":"Getting Started with the Conversational Framework"},{"location":"the-open-data-bot/#getting-started-with-the-conversational-framework","text":"","title":"Getting Started with the Conversational Framework"},{"location":"the-open-data-bot/#the-open-data-bot","text":"A good starting point is the source code of the Open Data Bot Follow the instructions of the README file of the project, to start the bot in the IDE (do not configure Messenger or Google Assistant at this point), then connect to the administration interface. The bot is already testable.","title":"The Open Data Bot"},{"location":"the-open-data-bot/#the-test-tab","text":"Go to this tab, and test the bot: This is a test mode, so the interface is minimal. The real goal is to have your users interact with the bot via channels like Messenger, Google Assistant ... or your sites or applications.","title":"The Test Tab"},{"location":"the-open-data-bot/#the-monitoring-tab","text":"It is then possible to consult the discussion that you just had with the bot via the Monitoring tab: In this sample, this dialog has the Messenger flag, as it was tested for this channel.","title":"The Monitoring Tab"},{"location":"the-open-data-bot/#the-build-tab","text":"","title":"The Build Tab"},{"location":"the-open-data-bot/#add-a-new-answer","text":"With the category Add new Answer , it is possible to add directly a new answer: Then test the new intention and its answer:","title":"Add a new answer"},{"location":"the-open-data-bot/#modify-the-answers-and-internationalization","text":"Finally it is possible to modify each answer of the bot, by type of interface (chat / voice), by type of connector and by language with the i18n tab. The ability to add alternative answers (a response from the list will be chosen each time at random) is also provided (with the \"plus\" button).","title":"Modify the Answers and Internationalization"},{"location":"toc/","text":"Tock documentation \u00b6 Overview Table of contents Try Tock : Create your first bot with Tock Studio Configure your bot for Slack Configure your bot for Messenger Program stories using the Bot API mode Deploy a standalone Tock platform with Docker Use Tock : Conversational concepts for Tock Tock Studio interfaces : General interface The Configuration menu The NLU menu The NLU QA menu The Build menu The Test menu The Monitoring menu Build your conversational model Create a multichannel bot (connectors) Create a multilingual bot (internationalization) Develop with Tock : Available modes Tock Bot API Tock Integrated Bot Unit Tests Connectors Internationalization ( i18n ) Tock APIs Code samples Run & administrate Tock : Functional and technical architecture Installation Security High Availability Monitoring Cloud About Tock : Why Tock Showcase Resources & press kit Contact us Community Contribute Jobs","title":"Table of contents"},{"location":"toc/#tock-documentation","text":"Overview Table of contents Try Tock : Create your first bot with Tock Studio Configure your bot for Slack Configure your bot for Messenger Program stories using the Bot API mode Deploy a standalone Tock platform with Docker Use Tock : Conversational concepts for Tock Tock Studio interfaces : General interface The Configuration menu The NLU menu The NLU QA menu The Build menu The Test menu The Monitoring menu Build your conversational model Create a multichannel bot (connectors) Create a multilingual bot (internationalization) Develop with Tock : Available modes Tock Bot API Tock Integrated Bot Unit Tests Connectors Internationalization ( i18n ) Tock APIs Code samples Run & administrate Tock : Functional and technical architecture Installation Security High Availability Monitoring Cloud About Tock : Why Tock Showcase Resources & press kit Contact us Community Contribute Jobs","title":"Tock documentation"},{"location":"about/community/","text":"Community \u00b6 Tock has been designed to remain an open platform shared with the community. To know more, see why Tock . Next events / Meetup \u00b6 This lists the next planed events related to Tock, as well as groups identified to share with the community: November: We should present Tock at the following Paris NLP (season 4 meetup #2) An open Hackathon event will take place in Paris the 21-22 of November around conversational AI with Tock (+ info very soon) December: A talk about open conversational AI platforms has been submitted to the Paris Open Source Summit CFP (to be confirmed) TOSIT association \u00b6 Tock has been selected as a reference solution supported by the TOSIT (The Open Source I Trust) , an association dedicated to support Open Source and Free Software. Founded by Carrefour, EDF, Enedis, Orange, P\u00f4le Emploi and SNCF, TOSIT now gathers other important members, such as the (French) Minist\u00e8re des Arm\u00e9es, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale or MAIF for instance. Tock refers to Chatbots Work Group at TOSIT. To know more about TOSIT, please visit http://tosit.fr/ GitHub & Gitter \u00b6 The Tock platform and tools are available on https://github.com/theopenconversationkit/tock under the Apache 2 license . Sources License Versions Issues Contributors Gitter Demo To know more about repository structure, coding conventions, etc. refer to the contribute to Tock section. Help \u00b6 Feel free to contact us .","title":"Community"},{"location":"about/community/#community","text":"Tock has been designed to remain an open platform shared with the community. To know more, see why Tock .","title":"Community"},{"location":"about/community/#next-events-meetup","text":"This lists the next planed events related to Tock, as well as groups identified to share with the community: November: We should present Tock at the following Paris NLP (season 4 meetup #2) An open Hackathon event will take place in Paris the 21-22 of November around conversational AI with Tock (+ info very soon) December: A talk about open conversational AI platforms has been submitted to the Paris Open Source Summit CFP (to be confirmed)","title":"Next events / Meetup"},{"location":"about/community/#tosit-association","text":"Tock has been selected as a reference solution supported by the TOSIT (The Open Source I Trust) , an association dedicated to support Open Source and Free Software. Founded by Carrefour, EDF, Enedis, Orange, P\u00f4le Emploi and SNCF, TOSIT now gathers other important members, such as the (French) Minist\u00e8re des Arm\u00e9es, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale or MAIF for instance. Tock refers to Chatbots Work Group at TOSIT. To know more about TOSIT, please visit http://tosit.fr/","title":"TOSIT association"},{"location":"about/community/#github-gitter","text":"The Tock platform and tools are available on https://github.com/theopenconversationkit/tock under the Apache 2 license . Sources License Versions Issues Contributors Gitter Demo To know more about repository structure, coding conventions, etc. refer to the contribute to Tock section.","title":"GitHub &amp; Gitter"},{"location":"about/community/#help","text":"Feel free to contact us .","title":"Help"},{"location":"about/contact/","text":"Contact us \u00b6 Developers, users and curious people are more than welcome to share about Tock with both its creators and the community. Don't hesitate to join us on Gitter (the instant messaging service for GitHub): https://gitter.im/tockchat/Lobby GitHub issues can be used to keep track of bugs, enhancements or feature requests: https://github.com/theopenconversationkit/tock/issues","title":"Contact us"},{"location":"about/contact/#contact-us","text":"Developers, users and curious people are more than welcome to share about Tock with both its creators and the community. Don't hesitate to join us on Gitter (the instant messaging service for GitHub): https://gitter.im/tockchat/Lobby GitHub issues can be used to keep track of bugs, enhancements or feature requests: https://github.com/theopenconversationkit/tock/issues","title":"Contact us"},{"location":"about/contribute/","text":"Contribute to Tock \u00b6 The Tock project is open to contribution and any feedback is welcome! This page details the source structure and coding conventions for the platform. Main technologies \u00b6 The applicative platform is the JVM . The reference language is Kotlin , but other programming languages can be used through the provided API. Tock leverages Vert.x and MongoDB . For the moment, most Tock applications are written in blocking IO mode. In the future, fibers should be preferred. Graphical interfaces (namely Tock Studio ) are powered by Angular in Typescript . Source structure \u00b6 Repositories \u00b6 tock : main source repository, including the framework and platform components under the Apache 2 license . tock-corenlp : optional module, leveraging a dependency to Stanford CoreNLP (instead of Apache OpenNLP ), under GPL license . tock-docker : Docker and Docker Compose images/descriptors, for platform hands-on and fast deployment of various configuations. tock-bot-samples : code samples, in particular the WebHook and WebSocket modes examples from Tock programing guides . tock-bot-open-data : a bot example, based on the SNCF Open Data API , also implementing basic internationalization ( i18n ) mecanisms with two distinct languages. The tock repository \u00b6 TODO : detail modules and repo structure Le tock-docker repository \u00b6 TODO : detail modules and repo structure, how Maven and Docker builds work, etc. Build Tock from sources \u00b6 Tock (core) \u00b6 Tock is built with Maven , including the Web modules leveraging NPM et Angular : $ mvn package Continuous integration build jobs are available on Travis . Docker images \u00b6 Tock Docker images can be rebuilt from sources, included in repository tock-docker . One can use Maven to trigger the Docker build: $ mvn docker:build Docker containers can then be instantiated from images, or Docker Compose stacks from the various descriptors at the root of the repository. Run in IDE \u00b6 To run Tock using Docker Compose outside the IDE, rather see Deploy Tock with Docker . Tock components (NLU, Studio, bot...) can run in an IDE, such as IntelliJ , Eclipse or Visual Studio Code for instance. Beside the Docker images , IntelliJ configurations are provided with Tock sources: The Tock Studio interfaces/server: BotAdmin The alternative standalone NLU interfaces/server: Admin The NLU service: NlpService The Duckling entity-recognition service: Duckling The NLU model-builder service: BuildWorker The script compilation service: KotlinCompilerServer The OpenDataBot example also has a run configuration available: OpenDataBot To start the Tock Studio interfaces, please refer to the commands described in the following pages: Full Tock Studio server commands Standalone NLU server commands Conventions \u00b6 Kotlin Code Conventions are used to develop Tock. Contact us \u00b6 To contribute to the project or to known more about the implementation, feel free to contact us . Ideas and feedback is more than welcome.","title":"Contribute"},{"location":"about/contribute/#contribute-to-tock","text":"The Tock project is open to contribution and any feedback is welcome! This page details the source structure and coding conventions for the platform.","title":"Contribute to Tock"},{"location":"about/contribute/#main-technologies","text":"The applicative platform is the JVM . The reference language is Kotlin , but other programming languages can be used through the provided API. Tock leverages Vert.x and MongoDB . For the moment, most Tock applications are written in blocking IO mode. In the future, fibers should be preferred. Graphical interfaces (namely Tock Studio ) are powered by Angular in Typescript .","title":"Main technologies"},{"location":"about/contribute/#source-structure","text":"","title":"Source structure"},{"location":"about/contribute/#repositories","text":"tock : main source repository, including the framework and platform components under the Apache 2 license . tock-corenlp : optional module, leveraging a dependency to Stanford CoreNLP (instead of Apache OpenNLP ), under GPL license . tock-docker : Docker and Docker Compose images/descriptors, for platform hands-on and fast deployment of various configuations. tock-bot-samples : code samples, in particular the WebHook and WebSocket modes examples from Tock programing guides . tock-bot-open-data : a bot example, based on the SNCF Open Data API , also implementing basic internationalization ( i18n ) mecanisms with two distinct languages.","title":"Repositories"},{"location":"about/contribute/#the-tock-repository","text":"TODO : detail modules and repo structure","title":"The tock repository"},{"location":"about/contribute/#le-tock-docker-repository","text":"TODO : detail modules and repo structure, how Maven and Docker builds work, etc.","title":"Le tock-docker repository"},{"location":"about/contribute/#build-tock-from-sources","text":"","title":"Build Tock from sources"},{"location":"about/contribute/#tock-core","text":"Tock is built with Maven , including the Web modules leveraging NPM et Angular : $ mvn package Continuous integration build jobs are available on Travis .","title":"Tock (core)"},{"location":"about/contribute/#docker-images","text":"Tock Docker images can be rebuilt from sources, included in repository tock-docker . One can use Maven to trigger the Docker build: $ mvn docker:build Docker containers can then be instantiated from images, or Docker Compose stacks from the various descriptors at the root of the repository.","title":"Docker images"},{"location":"about/contribute/#run-in-ide","text":"To run Tock using Docker Compose outside the IDE, rather see Deploy Tock with Docker . Tock components (NLU, Studio, bot...) can run in an IDE, such as IntelliJ , Eclipse or Visual Studio Code for instance. Beside the Docker images , IntelliJ configurations are provided with Tock sources: The Tock Studio interfaces/server: BotAdmin The alternative standalone NLU interfaces/server: Admin The NLU service: NlpService The Duckling entity-recognition service: Duckling The NLU model-builder service: BuildWorker The script compilation service: KotlinCompilerServer The OpenDataBot example also has a run configuration available: OpenDataBot To start the Tock Studio interfaces, please refer to the commands described in the following pages: Full Tock Studio server commands Standalone NLU server commands","title":"Run in IDE"},{"location":"about/contribute/#conventions","text":"Kotlin Code Conventions are used to develop Tock.","title":"Conventions"},{"location":"about/contribute/#contact-us","text":"To contribute to the project or to known more about the implementation, feel free to contact us . Ideas and feedback is more than welcome.","title":"Contact us"},{"location":"about/jobs/","text":"Tock jobs \u00b6 Interested in working with Tock and contribute to the platform? This page lists companies and organizations, proposing job offers in the field of conversational AI with Tock: e-voyageurs Technologies (Tock creators) recruit various profiles to build conversational assistants with Tock. To known more, check offers on Gitter or https://jobs.oui.sncf/ . Do you leverage Tock and offer conversational jobs? Don't hesitate to tell us and expand the list.","title":"Jobs"},{"location":"about/jobs/#tock-jobs","text":"Interested in working with Tock and contribute to the platform? This page lists companies and organizations, proposing job offers in the field of conversational AI with Tock: e-voyageurs Technologies (Tock creators) recruit various profiles to build conversational assistants with Tock. To known more, check offers on Gitter or https://jobs.oui.sncf/ . Do you leverage Tock and offer conversational jobs? Don't hesitate to tell us and expand the list.","title":"Tock jobs"},{"location":"about/resources/","text":"Tock resources \u00b6 This page lists various presentations of Tock, giving an overview of the solution in addition to the main documentation and demo instance. Conferences / video (in French) \u00b6 Code a bot for Messenger and Google Assistant in 30 minutes @ Devoxx France 2018 (live coding \"tools in action\" 30 min) Meetup / Slides (in French) \u00b6 Tock - The Open Conversation Kit @ Meetup Open Transport (2019) Tock - The Open Conversation Kit @ CRiP OpenSource & Co-d\u00e9veloppement (2017) Don't hesitate to share with us more slides, documents and links about Tock. Press kit \u00b6 Tock logos are provided under the Apache 2 license . Tock logo - default colors / transparent ( download ) : Tock logo - blue / transparent ( download ) : Tock logo - black / transparent ( download ) : Tock logo - white / transparent ( download ) :","title":"Resources"},{"location":"about/resources/#tock-resources","text":"This page lists various presentations of Tock, giving an overview of the solution in addition to the main documentation and demo instance.","title":"Tock resources"},{"location":"about/resources/#conferences-video-in-french","text":"Code a bot for Messenger and Google Assistant in 30 minutes @ Devoxx France 2018 (live coding \"tools in action\" 30 min)","title":"Conferences / video (in French)"},{"location":"about/resources/#meetup-slides-in-french","text":"Tock - The Open Conversation Kit @ Meetup Open Transport (2019) Tock - The Open Conversation Kit @ CRiP OpenSource & Co-d\u00e9veloppement (2017) Don't hesitate to share with us more slides, documents and links about Tock.","title":"Meetup / Slides (in French)"},{"location":"about/resources/#press-kit","text":"Tock logos are provided under the Apache 2 license . Tock logo - default colors / transparent ( download ) : Tock logo - blue / transparent ( download ) : Tock logo - black / transparent ( download ) : Tock logo - white / transparent ( download ) :","title":"Press kit"},{"location":"about/showcase/","text":"User showcase \u00b6 Since its creation for OUI.sncf in 2016, Tock has been used by more and more teams to build conversational bots dedicated to various use cases : business to customer and business to business e-commerce, transactions, payment assistance, care, help desks FAQ and decision trees This page presents various assistants and products built and powered by Tock. OUIbot , the OUI.sncf bot \u00b6 OUIbot is the conversational assistant from OUI.sncf. Available since 2016 on Facebook Messenger, OUIbot was built along with the first versions of Tock. With OUIbot, booking a train ticket has never been easier! It assists you in the preparation of your trips, allows you to make a complete reservation quickly and easily, from research to purchase (payment included), and accompanies you during your trip. Thanks to the numerous connectors, OUIbot is now available on multiple conversational channels, such as the company Website www.oui.sncf , social networks, voice assistants, smart display and even SmartBrics with JCDecaux devices. In 2019, OUIbot answers approximately 10.000 users a day. It has been awarded Best Robot Experience for the second year in a row. Name: OUIbot Date of birth: in production since 2016 Field: e-commerce/travel, transactions (booking, payment), alerts & push notifications, push messages to an agent Channels: text & voice, on the company Website, Messenger, WhatsApp, Business Chat (Messages), Google Assistant, Google Home, Alexa, JCDecaux SmartBrics L'Assistant SNCF \u00b6 L' Assistant SNCF is the mobile application for SNCF passengers on Android and iOS, covering both trains and other modes of transport. With L' Assistant (the SNCF Assistant), you can plan your itinerary, stay informed in real time, buy your transport tickets directly or book a taxi ride. More features are yet to come. Accessible via the \"microphone\" in the mobile application, le SNCF Assistant's conversational bot is built with Tock plus the speech-to-text Android and iOS functions. Name: L' Assistant SNCF Date of birth: in production, featuring Tock voice function since 2019 Field: travel & transport (multi-modal route research, etc.) Channels: voice, on the SNCF mobile application for Android and iOS Tilien , the Transilien chatbot \u00b6 Tilien is the Transilien chatbot on Messenger. Designed as a personal and friendly travel companion, it informs you about upcoming departures, the service status, current and future works, itineraries and much more (route plans, timetables, etc.) on the entire Ile-De-France rail network: Metro, RER, Transilien, Tram. Powered by Tock, the chatbot is waiting for you on Facebook Messenger. Name: Tilien Date of birth: in production, since 2018 with Tock Field: transport & assistance (route research, route plans, traffic conditions, etc.) Channels: text, on Messenger Mon Assistant TGV INOUI \u00b6 Mon Assistant advises customers and travellers of the TGV INOUI brand before, during and after their journey. The chatbot can tell you all about the service status, train departure platforms, customer seats, onboard services (bar, electrical outlets, etc.). It also allows you to talk with a SNCF agents while remaining in the same conversation. Located on the TGV INOUI Facebook page, the assistant based on Tock is also accessible from the E-Ticket reminder SMS or directly from the application. Name: Mon Assistant TGV INOUI Date of birth: in production since 2019 Field: assistance & passenger information (dock information, current travel information, on-board services), relay to an agent Channels: text, on Messenger (Facebook TGV INOUI page) L' Agent virtuel SNCF \u00b6 L' Agent virtuel SNCF (SNCF Virtual Assistant) presents passenger information and any disruptions on all trains (TGV, Intercites, TER, Eurostar, etc.) in a conversational manner. Query the bot by train number, passenger file, next departures, etc. to get the latest information and traffic status. Accessible via the SNCF Facebook page, the Agent virtuel is based on Tock. Name: Agent virtuel SNCF Date of birth: in production since 2019 Field: travel & transport (traffic situation, works, next departures), relay to an agent Channels: text, on Messenger ( SNCF Facebook page) Eve , the e-voyageurs internal assistant \u00b6 Eve is the internal assistant of e-voyageurs SNCF employees. The chatbot answers common questions, refers to the right interlocutors and collaborative tools of the company, automates common requests to IT Support, General Services, Legal Department, etc. DevOps teams can also ask it for production status, next planned operations, or even to manage certain operations directly for greater simplicity and reactivity. Eve is always listening to the employees, both within the offices and on-the-go using Teams applications with Tock. Name: Eve Date of birth: in production since 2019 Field: internal & B2B support (FAQ, IT Support, HR, Legal), DevOps automation (monitoring, deployments, production management, etc.) Channels: text & voice, internally within the offices and on-the-go via Teams What about you? \u00b6 As a generic platform, Tock enables numerous use cases and integration of internal as well as external channels. Please feel free to contact us in case of doubts or questions about Tock features or possibilities for a new project of your own. And don't hesitate to share your achievements with the community! \ud83d\ude42","title":"Showcase"},{"location":"about/showcase/#user-showcase","text":"Since its creation for OUI.sncf in 2016, Tock has been used by more and more teams to build conversational bots dedicated to various use cases : business to customer and business to business e-commerce, transactions, payment assistance, care, help desks FAQ and decision trees This page presents various assistants and products built and powered by Tock.","title":"User showcase"},{"location":"about/showcase/#ouibot-the-ouisncf-bot","text":"OUIbot is the conversational assistant from OUI.sncf. Available since 2016 on Facebook Messenger, OUIbot was built along with the first versions of Tock. With OUIbot, booking a train ticket has never been easier! It assists you in the preparation of your trips, allows you to make a complete reservation quickly and easily, from research to purchase (payment included), and accompanies you during your trip. Thanks to the numerous connectors, OUIbot is now available on multiple conversational channels, such as the company Website www.oui.sncf , social networks, voice assistants, smart display and even SmartBrics with JCDecaux devices. In 2019, OUIbot answers approximately 10.000 users a day. It has been awarded Best Robot Experience for the second year in a row. Name: OUIbot Date of birth: in production since 2016 Field: e-commerce/travel, transactions (booking, payment), alerts & push notifications, push messages to an agent Channels: text & voice, on the company Website, Messenger, WhatsApp, Business Chat (Messages), Google Assistant, Google Home, Alexa, JCDecaux SmartBrics","title":"OUIbot, the OUI.sncf bot"},{"location":"about/showcase/#lassistant-sncf","text":"L' Assistant SNCF is the mobile application for SNCF passengers on Android and iOS, covering both trains and other modes of transport. With L' Assistant (the SNCF Assistant), you can plan your itinerary, stay informed in real time, buy your transport tickets directly or book a taxi ride. More features are yet to come. Accessible via the \"microphone\" in the mobile application, le SNCF Assistant's conversational bot is built with Tock plus the speech-to-text Android and iOS functions. Name: L' Assistant SNCF Date of birth: in production, featuring Tock voice function since 2019 Field: travel & transport (multi-modal route research, etc.) Channels: voice, on the SNCF mobile application for Android and iOS","title":"L'Assistant SNCF"},{"location":"about/showcase/#tilien-the-transilien-chatbot","text":"Tilien is the Transilien chatbot on Messenger. Designed as a personal and friendly travel companion, it informs you about upcoming departures, the service status, current and future works, itineraries and much more (route plans, timetables, etc.) on the entire Ile-De-France rail network: Metro, RER, Transilien, Tram. Powered by Tock, the chatbot is waiting for you on Facebook Messenger. Name: Tilien Date of birth: in production, since 2018 with Tock Field: transport & assistance (route research, route plans, traffic conditions, etc.) Channels: text, on Messenger","title":"Tilien, the Transilien chatbot"},{"location":"about/showcase/#mon-assistant-tgv-inoui","text":"Mon Assistant advises customers and travellers of the TGV INOUI brand before, during and after their journey. The chatbot can tell you all about the service status, train departure platforms, customer seats, onboard services (bar, electrical outlets, etc.). It also allows you to talk with a SNCF agents while remaining in the same conversation. Located on the TGV INOUI Facebook page, the assistant based on Tock is also accessible from the E-Ticket reminder SMS or directly from the application. Name: Mon Assistant TGV INOUI Date of birth: in production since 2019 Field: assistance & passenger information (dock information, current travel information, on-board services), relay to an agent Channels: text, on Messenger (Facebook TGV INOUI page)","title":"Mon Assistant TGV INOUI"},{"location":"about/showcase/#l-agent-virtuel-sncf","text":"L' Agent virtuel SNCF (SNCF Virtual Assistant) presents passenger information and any disruptions on all trains (TGV, Intercites, TER, Eurostar, etc.) in a conversational manner. Query the bot by train number, passenger file, next departures, etc. to get the latest information and traffic status. Accessible via the SNCF Facebook page, the Agent virtuel is based on Tock. Name: Agent virtuel SNCF Date of birth: in production since 2019 Field: travel & transport (traffic situation, works, next departures), relay to an agent Channels: text, on Messenger ( SNCF Facebook page)","title":"L' Agent virtuel SNCF"},{"location":"about/showcase/#eve-the-e-voyageurs-internal-assistant","text":"Eve is the internal assistant of e-voyageurs SNCF employees. The chatbot answers common questions, refers to the right interlocutors and collaborative tools of the company, automates common requests to IT Support, General Services, Legal Department, etc. DevOps teams can also ask it for production status, next planned operations, or even to manage certain operations directly for greater simplicity and reactivity. Eve is always listening to the employees, both within the offices and on-the-go using Teams applications with Tock. Name: Eve Date of birth: in production since 2019 Field: internal & B2B support (FAQ, IT Support, HR, Legal), DevOps automation (monitoring, deployments, production management, etc.) Channels: text & voice, internally within the offices and on-the-go via Teams","title":"Eve, the e-voyageurs internal assistant"},{"location":"about/showcase/#what-about-you","text":"As a generic platform, Tock enables numerous use cases and integration of internal as well as external channels. Please feel free to contact us in case of doubts or questions about Tock features or possibilities for a new project of your own. And don't hesitate to share your achievements with the community! \ud83d\ude42","title":"What about you?"},{"location":"about/why/","text":"Why Tock? \u00b6 Created in 2016 by the OUI.sncf Innovation team to implement voice-command on its mobile applications , the framework has then been used to create the Messenger chatbot , before being extended to support numerous channels and other bots with more use cases. At first the platform showed results, similar to other available solutions on the market, while keeping the code in control (relying on opensource libraries and academic solutions) and preventing \"black box\" effects (eg. debugging conversational models) for more reactive agility. Since then, the team behind OUIbot as well as other teams, dedicated to various conversational assistants at SNCF (see the showcase ) use Tock every day in production and add new features and connectors to the platform on a regular basis. We are convinced there is a need for open AI and conversational platforms , enabling various technical and business cases while keeping the code in control and the ownership of models and data . More and more partners and third-parties, small and big companies in France and worldwide, share this vision and requirement for their own projects. The complete Tock solution is shared with the community in order to federate and mutualize efforts from assistant builders. In 2019, Tock was selected both as a reference solution for the groupe SNCF, and the TOSIT (The Open Source I Trust) association.","title":"Why Tock"},{"location":"about/why/#why-tock","text":"Created in 2016 by the OUI.sncf Innovation team to implement voice-command on its mobile applications , the framework has then been used to create the Messenger chatbot , before being extended to support numerous channels and other bots with more use cases. At first the platform showed results, similar to other available solutions on the market, while keeping the code in control (relying on opensource libraries and academic solutions) and preventing \"black box\" effects (eg. debugging conversational models) for more reactive agility. Since then, the team behind OUIbot as well as other teams, dedicated to various conversational assistants at SNCF (see the showcase ) use Tock every day in production and add new features and connectors to the platform on a regular basis. We are convinced there is a need for open AI and conversational platforms , enabling various technical and business cases while keeping the code in control and the ownership of models and data . More and more partners and third-parties, small and big companies in France and worldwide, share this vision and requirement for their own projects. The complete Tock solution is shared with the community in order to federate and mutualize efforts from assistant builders. In 2019, Tock was selected both as a reference solution for the groupe SNCF, and the TOSIT (The Open Source I Trust) association.","title":"Why Tock?"},{"location":"admin/architecture/","text":"Architecture de Tock \u00b6 Ce chapitre pr\u00e9sente l'architecture g\u00e9n\u00e9rale d'une plateforme Tock : composants et d\u00e9pendances, flux, configuration de proxies, etc. Architecture fonctionnelle \u00b6 Deux composants majeurs sont disponibles : le moteur NLU : Natural Language Understanding (voir Tock Studio ) le framework conversationnel int\u00e9gr\u00e9 aux services NLU et \u00e0 diff\u00e9rents connecteurs comme Messenger, Google Assistant ou Slack (voir manuel d\u00e9veloppeur et connecteurs ). La plateforme NLU est ind\u00e9pendante de la partie conversationnelle. Il est possible d'utiliser le NLU sans devoir ma\u00eetriser la complexit\u00e9 induite par la gestion des conversations. Dans certain cas d'usage importants, comme l' Internet des objets , l'utilisation d'un mod\u00e8le NLU seule est pertinente. Architecture technique \u00b6 Tock est compos\u00e9 de plusieurs composants applicatifs ( conteneurs lorsqu'on utilise Docker) et d'une base de donn\u00e9e MongoDB . Les descripteurs Docker et Docker Compose fournis (ie. les Dockerfile et docker-compose.yml ) d\u00e9crivent l'architecture de Tock. Un exemple complet se trouve dans le fichier docker-compose-bot-open-data.yml disponible dans le d\u00e9p\u00f4t tock-docker . Base de donn\u00e9es MongoDB \u00b6 La base Mongo doit \u00eatre configur\u00e9e en replica set , c'est \u00e0 dire avec au minimum 3 instances d\u00e9ploy\u00e9es. C'est obligatoire car Tock utilise la fonctionnalit\u00e9 des Change Streams qui a comme pr\u00e9-requis l'installation en replica set. Il s'agit \u00e9galement d'une bonne pratique afin d'assurer une haute disponibilit\u00e9 de la base de donn\u00e9es. Composants applicatifs \u00b6 Voici une description rapide des diff\u00e9rents composants applicatifs (et images Docker fournies avec Tock) : Interfaces et outils Tock Studio : tock/bot_admin : Tock Studio Partie NLU : tock/build_worker : reconstruit les mod\u00e8les automatiquement d\u00e8s que n\u00e9cessaire tock/duckling : analyse les dates et types primitifs en utilisant Duckling tock/nlp_api : analyse les phrases \u00e0 partir des mod\u00e8les construits dans Tock Studio Partie conversationnelle : tock/bot_api : API pour d\u00e9velopper des bots (mode Tock Bot API ) tock/kotlin_compiler (facultatif) : compilateur de scripts pour les saisir directement dans l'interface Build de Tock Studio Un dernier composant, le bot lui-m\u00eame, doit \u00eatre ajout\u00e9 et rendu accessible aux partenaires et canaux externes auxquels on souhaite s'int\u00e9grer. Bien entendu l'impl\u00e9mentation du bot n'est pas fournie avec Tock (chacun impl\u00e9mente ses fonctionnalit\u00e9s propres pour son besoin) mais un exemple est disponible dans docker-compose-bot-open-data.yml . Modes de d\u00e9ploiement \u00b6 Le mode plateforme NLU seul (sans partie conversationnelle) : Le mode Tock Bot API (recommand\u00e9 pour la plupart des cas), permettant de d\u00e9velopper en Kotlin ou un autre langage \u00e0 travers l'API conversationnelle de Tock : Le mode Tock Bot int\u00e9gr\u00e9 (historique) permettant de d\u00e9velopper en Kotlin uniquement en utilisant toutes les possibilit\u00e9s de Tock mais en acc\u00e9dant \u00e0 la base MongoDB directement depuis le bot : Voir aussi... \u00b6 Installation S\u00e9curit\u00e9 Supervision Cloud Haute disponibilit\u00e9","title":"Architecture"},{"location":"admin/architecture/#architecture-de-tock","text":"Ce chapitre pr\u00e9sente l'architecture g\u00e9n\u00e9rale d'une plateforme Tock : composants et d\u00e9pendances, flux, configuration de proxies, etc.","title":"Architecture de Tock"},{"location":"admin/architecture/#architecture-fonctionnelle","text":"Deux composants majeurs sont disponibles : le moteur NLU : Natural Language Understanding (voir Tock Studio ) le framework conversationnel int\u00e9gr\u00e9 aux services NLU et \u00e0 diff\u00e9rents connecteurs comme Messenger, Google Assistant ou Slack (voir manuel d\u00e9veloppeur et connecteurs ). La plateforme NLU est ind\u00e9pendante de la partie conversationnelle. Il est possible d'utiliser le NLU sans devoir ma\u00eetriser la complexit\u00e9 induite par la gestion des conversations. Dans certain cas d'usage importants, comme l' Internet des objets , l'utilisation d'un mod\u00e8le NLU seule est pertinente.","title":"Architecture fonctionnelle"},{"location":"admin/architecture/#architecture-technique","text":"Tock est compos\u00e9 de plusieurs composants applicatifs ( conteneurs lorsqu'on utilise Docker) et d'une base de donn\u00e9e MongoDB . Les descripteurs Docker et Docker Compose fournis (ie. les Dockerfile et docker-compose.yml ) d\u00e9crivent l'architecture de Tock. Un exemple complet se trouve dans le fichier docker-compose-bot-open-data.yml disponible dans le d\u00e9p\u00f4t tock-docker .","title":"Architecture technique"},{"location":"admin/architecture/#base-de-donnees-mongodb","text":"La base Mongo doit \u00eatre configur\u00e9e en replica set , c'est \u00e0 dire avec au minimum 3 instances d\u00e9ploy\u00e9es. C'est obligatoire car Tock utilise la fonctionnalit\u00e9 des Change Streams qui a comme pr\u00e9-requis l'installation en replica set. Il s'agit \u00e9galement d'une bonne pratique afin d'assurer une haute disponibilit\u00e9 de la base de donn\u00e9es.","title":"Base de donn\u00e9es MongoDB"},{"location":"admin/architecture/#composants-applicatifs","text":"Voici une description rapide des diff\u00e9rents composants applicatifs (et images Docker fournies avec Tock) : Interfaces et outils Tock Studio : tock/bot_admin : Tock Studio Partie NLU : tock/build_worker : reconstruit les mod\u00e8les automatiquement d\u00e8s que n\u00e9cessaire tock/duckling : analyse les dates et types primitifs en utilisant Duckling tock/nlp_api : analyse les phrases \u00e0 partir des mod\u00e8les construits dans Tock Studio Partie conversationnelle : tock/bot_api : API pour d\u00e9velopper des bots (mode Tock Bot API ) tock/kotlin_compiler (facultatif) : compilateur de scripts pour les saisir directement dans l'interface Build de Tock Studio Un dernier composant, le bot lui-m\u00eame, doit \u00eatre ajout\u00e9 et rendu accessible aux partenaires et canaux externes auxquels on souhaite s'int\u00e9grer. Bien entendu l'impl\u00e9mentation du bot n'est pas fournie avec Tock (chacun impl\u00e9mente ses fonctionnalit\u00e9s propres pour son besoin) mais un exemple est disponible dans docker-compose-bot-open-data.yml .","title":"Composants applicatifs"},{"location":"admin/architecture/#modes-de-deploiement","text":"Le mode plateforme NLU seul (sans partie conversationnelle) : Le mode Tock Bot API (recommand\u00e9 pour la plupart des cas), permettant de d\u00e9velopper en Kotlin ou un autre langage \u00e0 travers l'API conversationnelle de Tock : Le mode Tock Bot int\u00e9gr\u00e9 (historique) permettant de d\u00e9velopper en Kotlin uniquement en utilisant toutes les possibilit\u00e9s de Tock mais en acc\u00e9dant \u00e0 la base MongoDB directement depuis le bot :","title":"Modes de d\u00e9ploiement"},{"location":"admin/architecture/#voir-aussi","text":"Installation S\u00e9curit\u00e9 Supervision Cloud Haute disponibilit\u00e9","title":"Voir aussi..."},{"location":"admin/availability/","text":"Haute disponibilit\u00e9 \u00b6 Cette page est destin\u00e9e \u00e0 fournir des conseils et des retours d'ex\u00e9prience sur les configurations haute disponibilit\u00e9 (ou HA - High Availability ) de bots et plateformes Tock. A venir : plus de d\u00e9tails sur les mani\u00e8res d'obtenir une haute disponibilit\u00e9 sur les diff\u00e9rents composants Tock, et des retours sur notre utilisation en production depuis plusieurs ann\u00e9es (cf vitrine / utilisateurs ). Redondance et r\u00e9silience \u00b6 Une seule instance de tock/build_worker doit exister. Il est recommand\u00e9 d'utiliser une seule instance de tock/bot_admin et tock/kotlin_compiler . Pour les autres composants, en particulier le composant bot (non fourni) mais \u00e9galement tock/nlp_api et tock/duckling , il est recommand\u00e9 de d\u00e9ployer plusieurs instances pour assurer une meilleure disponibilit\u00e9 voire de meilleures performances. Performance \u00b6 Comme indiqu\u00e9 dans la section installation , le premier param\u00e8tre \u00e0 surveiller est la m\u00e9moire disponible. A forte charge - nous avons exp\u00e9riment\u00e9 plus de 80 req/s sur nos propres bots - le facteur limitant devient la base de donn\u00e9es MongoDB, qu'il faut alors redimensionner en cons\u00e9quence quand le besoin s'en fait sentir.","title":"Availability"},{"location":"admin/availability/#haute-disponibilite","text":"Cette page est destin\u00e9e \u00e0 fournir des conseils et des retours d'ex\u00e9prience sur les configurations haute disponibilit\u00e9 (ou HA - High Availability ) de bots et plateformes Tock. A venir : plus de d\u00e9tails sur les mani\u00e8res d'obtenir une haute disponibilit\u00e9 sur les diff\u00e9rents composants Tock, et des retours sur notre utilisation en production depuis plusieurs ann\u00e9es (cf vitrine / utilisateurs ).","title":"Haute disponibilit\u00e9"},{"location":"admin/availability/#redondance-et-resilience","text":"Une seule instance de tock/build_worker doit exister. Il est recommand\u00e9 d'utiliser une seule instance de tock/bot_admin et tock/kotlin_compiler . Pour les autres composants, en particulier le composant bot (non fourni) mais \u00e9galement tock/nlp_api et tock/duckling , il est recommand\u00e9 de d\u00e9ployer plusieurs instances pour assurer une meilleure disponibilit\u00e9 voire de meilleures performances.","title":"Redondance et r\u00e9silience"},{"location":"admin/availability/#performance","text":"Comme indiqu\u00e9 dans la section installation , le premier param\u00e8tre \u00e0 surveiller est la m\u00e9moire disponible. A forte charge - nous avons exp\u00e9riment\u00e9 plus de 80 req/s sur nos propres bots - le facteur limitant devient la base de donn\u00e9es MongoDB, qu'il faut alors redimensionner en cons\u00e9quence quand le besoin s'en fait sentir.","title":"Performance"},{"location":"admin/cloud/","text":"Cloud \u00b6 Cette page pr\u00e9sente les aspects li\u00e9s \u00e0 l'utilisation de services Cloud (priv\u00e9s ou publiques) pour d\u00e9ployer et h\u00e9berger plateformes et bots Tock. En effet, nous avons l'exp\u00e9rience d'utilisations de Tock en production sur des h\u00e9bergements classiques on-premise et bare metal , mais aussi sur des Clouds priv\u00e9s comme OpenStack ou Clouds publiques comme AWS . A venir : des d\u00e9tails, exemples et retours d'exp\u00e9rience sur l\"utilisation de Tock sur des h\u00e9bergements de type Cloud . Nous esp\u00e9rons m\u00eame pouvoir partager avec la communaut\u00e9 du code : infra as code , dashboards, etc.","title":"Cloud"},{"location":"admin/cloud/#cloud","text":"Cette page pr\u00e9sente les aspects li\u00e9s \u00e0 l'utilisation de services Cloud (priv\u00e9s ou publiques) pour d\u00e9ployer et h\u00e9berger plateformes et bots Tock. En effet, nous avons l'exp\u00e9rience d'utilisations de Tock en production sur des h\u00e9bergements classiques on-premise et bare metal , mais aussi sur des Clouds priv\u00e9s comme OpenStack ou Clouds publiques comme AWS . A venir : des d\u00e9tails, exemples et retours d'exp\u00e9rience sur l\"utilisation de Tock sur des h\u00e9bergements de type Cloud . Nous esp\u00e9rons m\u00eame pouvoir partager avec la communaut\u00e9 du code : infra as code , dashboards, etc.","title":"Cloud"},{"location":"admin/installation/","text":"Installation Tock \u00b6 La page architecture pr\u00e9sente l'architecture fonctionnelle et technique Tock, le r\u00f4le des diff\u00e9rents composants ainsi que les diff\u00e9rents modes de d\u00e9ploiement. Ce chapitre pr\u00e9sente les diff\u00e9rentes options d'installation de Tock. En particulier, il s'agit d'\u00e9voquer le cas d'une installation en production ainsi que partager quelques retours d'exp\u00e9rience sur les performances, la r\u00e9silience, la capacit\u00e9 de Tock \u00e0 monter en charge, les d\u00e9ploiementsde type Cloud , la supervision, etc. Si vous cherchez seulement \u00e0 tester Tock avec des donn\u00e9es non sensibles, vous pouvez pr\u00e9f\u00e9rer utiliser la plateforme de d\u00e9monstration Tock . Installation avec Docker \u00b6 Les informations ci-dessous concernent l'installation avec Docker . En analysant les descripteurs Docker et Docker Compose fournis (les Dockerfile et docker-compose.yml ) on peut facilement concevoir une installation sans Docker. Tock est compos\u00e9 par d\u00e9faut de plusieurs conteneurs/images dockers et d'une base de donn\u00e9e MongoDB . Le guide d\u00e9ployer Tock avec Docker dans la section D\u00e9couvrir Tock donne un exemple de d\u00e9ploiement d'une plateforme compl\u00e8te en quelques minutes avec une empreinte minimale en utilisant Docker et Docker Compose. Cependant, cette m\u00e9thode n'est pas envisageable pour un d\u00e9ploiement p\u00e9renne comme une plateforme de production. Si vous souhaitez utiliser Docker Compose en production, merci de lire cet article et de revoir la configuration, qui est uniquement donn\u00e9e dans le projet tock-docker \u00e0 titre d'exemple. En particulier, la configuration des instances MongoDB doit \u00eatre revue attentivement. Base de donn\u00e9es MongoDB \u00b6 La base Mongo devant \u00eatre configur\u00e9e en replica set , c'est \u00e0 dire avec au minimum 3 instances d\u00e9ploy\u00e9es. Un tutoriel d'installation en replica set est disponible sur le site de MongoDB. Composants applicatifs \u00b6 Selon les composants applicatifs de Tock, obligatoires ou facultatifs, certains doivent \u00eatre mono-instance et d'autres peuvent \u00eatre d\u00e9ploy\u00e9s en plusieurs instances (voir la section haute disponibilit\u00e9 pour en savoir plus). Pour plus de commodit\u00e9, les composants ci-dessous sont nomm\u00e9 comme les images Docker fournies avec Tock, bien que l'utilisation de Docker ne soit pas obligatoire pour installer Tock. Exposition r\u00e9seau \u00b6 Par d\u00e9faut, les composants ou conteneurs de la plateforme Tock ne doivent pas \u00eatre expos\u00e9s \u00e0 l'ext\u00e9rieur du VPN ou VPC . Seul le bot lui-m\u00eame doit \u00eatre accessible des partenaires et canaux externes auxquels on veut s'int\u00e9grer, pour le fonctionnement des WebHooks . Composant / Image Exposition r\u00e9seau Description tock/bot_admin VPN / VPC uniquement Interfaces et outils Tock Studio tock/build_worker VPN / VPC uniquement Reconstruit les mod\u00e8les automatiquement d\u00e8s que n\u00e9cessaire tock/duckling VPN / VPC uniquement Analyse les dates et types primitifs en utilisant Duckling tock/nlp_api VPN / VPC uniquement Analyse les phrases \u00e0 partir des mod\u00e8les construits dans Tock Studio tock/bot_api VPN / VPC uniquement API pour d\u00e9velopper des bots (mode Tock Bot API ) tock/kotlin_compiler VPN / VPC uniquement (Facultatif) Compilateur de scripts pour les saisir directement dans l'interface Build de Tock Studio bot (non fourni) Internet / partenaires Le bot lui-m\u00eame, impl\u00e9mentant les parcours programmatiques, accessible des partenaires/canaux externes via des WebHooks Bien s\u00fbr, l'impl\u00e9mentation du bot lui-m\u00eame n'est pas fournie avec Tock (chacun impl\u00e9mente ses fonctionnalit\u00e9s propres pour son besoin). Proxies HTTP \u00b6 Les propri\u00e9t\u00e9s syst\u00e8me Java https.proxyHost , http.proxyHost et http.nonProxyHosts sont la m\u00e9thode recommand\u00e9e pour configurer un proxy. Packaging du bot \u00b6 Un exemple de bot en mode Tock Bot int\u00e9gr\u00e9 est disponible dans docker-compose-bot-open-data.yml . Des exemples et indications pour packager des bots en mode Tock Bot API ( WebHooks , WebSockets ) seront bient\u00f4t disponibles. Configurations minimales \u00b6 Le param\u00e8tre principal \u00e0 surveiller est la m\u00e9moire vive disponible. Construction des mod\u00e8les \u00b6 En particulier, plus vos mod\u00e8les sont importants, plus il est n\u00e9cessaire d'augmenter la m\u00e9moire pour reconstruire les mod\u00e8les (composant tock/build_worker ). Pour donner un ordre de grandeur, un mod\u00e8le de 50000 phrases avec plusieurs intentions, comportant une vingtaine d'entit\u00e9s, n\u00e9cessitera de provisionner environ 8 Go de RAM pour le composant tock/build_worker . Cependant, des mod\u00e8les importants mais contenant peu d'entit\u00e9s fonctionnent facilement avec seulement 1 Go de RAM. M\u00e9moire JVM \u00b6 Pour garantir que les conteneurs/instances Docker ne d\u00e9passent pas la m\u00e9moire disponible, il est recommand\u00e9 de limiter la m\u00e9moire des JVMs en suivant l'exemple suivant : JAVA_ARGS =- Xmx1g - XX : MaxMetaspaceSize = 256 m Param\u00e9trage fonctionnel \u00b6 S\u00e9lection du moteur NLU \u00b6 TODO : documenter comment utiliser OpenNLP (par d\u00e9faut), Stanford CoreNLP ou autre. Voir aussi... \u00b6 Pour une utilisation de Tock en production, nous vous recommandons de parcourir \u00e9galement les pages suivantes : S\u00e9curit\u00e9 Supervision Cloud Haute disponibilit\u00e9","title":"Installation"},{"location":"admin/installation/#installation-tock","text":"La page architecture pr\u00e9sente l'architecture fonctionnelle et technique Tock, le r\u00f4le des diff\u00e9rents composants ainsi que les diff\u00e9rents modes de d\u00e9ploiement. Ce chapitre pr\u00e9sente les diff\u00e9rentes options d'installation de Tock. En particulier, il s'agit d'\u00e9voquer le cas d'une installation en production ainsi que partager quelques retours d'exp\u00e9rience sur les performances, la r\u00e9silience, la capacit\u00e9 de Tock \u00e0 monter en charge, les d\u00e9ploiementsde type Cloud , la supervision, etc. Si vous cherchez seulement \u00e0 tester Tock avec des donn\u00e9es non sensibles, vous pouvez pr\u00e9f\u00e9rer utiliser la plateforme de d\u00e9monstration Tock .","title":"Installation Tock"},{"location":"admin/installation/#installation-avec-docker","text":"Les informations ci-dessous concernent l'installation avec Docker . En analysant les descripteurs Docker et Docker Compose fournis (les Dockerfile et docker-compose.yml ) on peut facilement concevoir une installation sans Docker. Tock est compos\u00e9 par d\u00e9faut de plusieurs conteneurs/images dockers et d'une base de donn\u00e9e MongoDB . Le guide d\u00e9ployer Tock avec Docker dans la section D\u00e9couvrir Tock donne un exemple de d\u00e9ploiement d'une plateforme compl\u00e8te en quelques minutes avec une empreinte minimale en utilisant Docker et Docker Compose. Cependant, cette m\u00e9thode n'est pas envisageable pour un d\u00e9ploiement p\u00e9renne comme une plateforme de production. Si vous souhaitez utiliser Docker Compose en production, merci de lire cet article et de revoir la configuration, qui est uniquement donn\u00e9e dans le projet tock-docker \u00e0 titre d'exemple. En particulier, la configuration des instances MongoDB doit \u00eatre revue attentivement.","title":"Installation avec Docker"},{"location":"admin/installation/#base-de-donnees-mongodb","text":"La base Mongo devant \u00eatre configur\u00e9e en replica set , c'est \u00e0 dire avec au minimum 3 instances d\u00e9ploy\u00e9es. Un tutoriel d'installation en replica set est disponible sur le site de MongoDB.","title":"Base de donn\u00e9es MongoDB"},{"location":"admin/installation/#composants-applicatifs","text":"Selon les composants applicatifs de Tock, obligatoires ou facultatifs, certains doivent \u00eatre mono-instance et d'autres peuvent \u00eatre d\u00e9ploy\u00e9s en plusieurs instances (voir la section haute disponibilit\u00e9 pour en savoir plus). Pour plus de commodit\u00e9, les composants ci-dessous sont nomm\u00e9 comme les images Docker fournies avec Tock, bien que l'utilisation de Docker ne soit pas obligatoire pour installer Tock.","title":"Composants applicatifs"},{"location":"admin/installation/#exposition-reseau","text":"Par d\u00e9faut, les composants ou conteneurs de la plateforme Tock ne doivent pas \u00eatre expos\u00e9s \u00e0 l'ext\u00e9rieur du VPN ou VPC . Seul le bot lui-m\u00eame doit \u00eatre accessible des partenaires et canaux externes auxquels on veut s'int\u00e9grer, pour le fonctionnement des WebHooks . Composant / Image Exposition r\u00e9seau Description tock/bot_admin VPN / VPC uniquement Interfaces et outils Tock Studio tock/build_worker VPN / VPC uniquement Reconstruit les mod\u00e8les automatiquement d\u00e8s que n\u00e9cessaire tock/duckling VPN / VPC uniquement Analyse les dates et types primitifs en utilisant Duckling tock/nlp_api VPN / VPC uniquement Analyse les phrases \u00e0 partir des mod\u00e8les construits dans Tock Studio tock/bot_api VPN / VPC uniquement API pour d\u00e9velopper des bots (mode Tock Bot API ) tock/kotlin_compiler VPN / VPC uniquement (Facultatif) Compilateur de scripts pour les saisir directement dans l'interface Build de Tock Studio bot (non fourni) Internet / partenaires Le bot lui-m\u00eame, impl\u00e9mentant les parcours programmatiques, accessible des partenaires/canaux externes via des WebHooks Bien s\u00fbr, l'impl\u00e9mentation du bot lui-m\u00eame n'est pas fournie avec Tock (chacun impl\u00e9mente ses fonctionnalit\u00e9s propres pour son besoin).","title":"Exposition r\u00e9seau"},{"location":"admin/installation/#proxies-http","text":"Les propri\u00e9t\u00e9s syst\u00e8me Java https.proxyHost , http.proxyHost et http.nonProxyHosts sont la m\u00e9thode recommand\u00e9e pour configurer un proxy.","title":"Proxies HTTP"},{"location":"admin/installation/#packaging-du-bot","text":"Un exemple de bot en mode Tock Bot int\u00e9gr\u00e9 est disponible dans docker-compose-bot-open-data.yml . Des exemples et indications pour packager des bots en mode Tock Bot API ( WebHooks , WebSockets ) seront bient\u00f4t disponibles.","title":"Packaging du bot"},{"location":"admin/installation/#configurations-minimales","text":"Le param\u00e8tre principal \u00e0 surveiller est la m\u00e9moire vive disponible.","title":"Configurations minimales"},{"location":"admin/installation/#construction-des-modeles","text":"En particulier, plus vos mod\u00e8les sont importants, plus il est n\u00e9cessaire d'augmenter la m\u00e9moire pour reconstruire les mod\u00e8les (composant tock/build_worker ). Pour donner un ordre de grandeur, un mod\u00e8le de 50000 phrases avec plusieurs intentions, comportant une vingtaine d'entit\u00e9s, n\u00e9cessitera de provisionner environ 8 Go de RAM pour le composant tock/build_worker . Cependant, des mod\u00e8les importants mais contenant peu d'entit\u00e9s fonctionnent facilement avec seulement 1 Go de RAM.","title":"Construction des mod\u00e8les"},{"location":"admin/installation/#memoire-jvm","text":"Pour garantir que les conteneurs/instances Docker ne d\u00e9passent pas la m\u00e9moire disponible, il est recommand\u00e9 de limiter la m\u00e9moire des JVMs en suivant l'exemple suivant : JAVA_ARGS =- Xmx1g - XX : MaxMetaspaceSize = 256 m","title":"M\u00e9moire JVM"},{"location":"admin/installation/#parametrage-fonctionnel","text":"","title":"Param\u00e9trage fonctionnel"},{"location":"admin/installation/#selection-du-moteur-nlu","text":"TODO : documenter comment utiliser OpenNLP (par d\u00e9faut), Stanford CoreNLP ou autre.","title":"S\u00e9lection du moteur NLU"},{"location":"admin/installation/#voir-aussi","text":"Pour une utilisation de Tock en production, nous vous recommandons de parcourir \u00e9galement les pages suivantes : S\u00e9curit\u00e9 Supervision Cloud Haute disponibilit\u00e9","title":"Voir aussi..."},{"location":"admin/monitoring/","text":"Supervision \u00b6 Ce chapitre pr\u00e9sente quelques aspects supervision et monitoring du fonctionnement de la plateforme et des bots Tock. A venir : plus de d\u00e9tails sur la mani\u00e8re de monitorer les bots, voire des exemples de dashboards pour quelques technologies de monitoring classiques. N'h\u00e9sitez pas \u00e0 partager les v\u00f4tres. Lignes de vie (healthchecks) \u00b6 L'url /healthcheck renvoie une code HTTP 200 si tout est correct. Pour certaines images, le ligne de vie peut ne pas \u00eatre pr\u00e9sente \u00e0 la racine. En particulier : Pour tock/admin , la ligne de vie est localis\u00e9e par d\u00e9faut dans /rest/admin/healthcheck Pour tock/nlp_api , la ligne de vie est /rest/nlp/healthcheck Journalisation (logs) \u00b6 Logs applicatifs \u00b6 Tock utilise SLF4J pour g\u00e9n\u00e9rer ses logs. Chiffrage et anonymisation \u00b6 Voir la page s\u00e9curit\u00e9 concernant les possibilit\u00e9s de chiffrage et anonymisation des logs.","title":"Monitoring"},{"location":"admin/monitoring/#supervision","text":"Ce chapitre pr\u00e9sente quelques aspects supervision et monitoring du fonctionnement de la plateforme et des bots Tock. A venir : plus de d\u00e9tails sur la mani\u00e8re de monitorer les bots, voire des exemples de dashboards pour quelques technologies de monitoring classiques. N'h\u00e9sitez pas \u00e0 partager les v\u00f4tres.","title":"Supervision"},{"location":"admin/monitoring/#lignes-de-vie-healthchecks","text":"L'url /healthcheck renvoie une code HTTP 200 si tout est correct. Pour certaines images, le ligne de vie peut ne pas \u00eatre pr\u00e9sente \u00e0 la racine. En particulier : Pour tock/admin , la ligne de vie est localis\u00e9e par d\u00e9faut dans /rest/admin/healthcheck Pour tock/nlp_api , la ligne de vie est /rest/nlp/healthcheck","title":"Lignes de vie (healthchecks)"},{"location":"admin/monitoring/#journalisation-logs","text":"","title":"Journalisation (logs)"},{"location":"admin/monitoring/#logs-applicatifs","text":"Tock utilise SLF4J pour g\u00e9n\u00e9rer ses logs.","title":"Logs applicatifs"},{"location":"admin/monitoring/#chiffrage-et-anonymisation","text":"Voir la page s\u00e9curit\u00e9 concernant les possibilit\u00e9s de chiffrage et anonymisation des logs.","title":"Chiffrage et anonymisation"},{"location":"admin/security/","text":"S\u00e9curit\u00e9 \u00b6 Authentification \u00b6 Tock supporte plusieurs syst\u00e8mes d'authentification pour l'interface d'administration. Il utilise les librairies vert.x correspondantes. Voici les syst\u00e8mes disponibles par d\u00e9faut : Un mod\u00e8le par \"propri\u00e9t\u00e9s\", utilis\u00e9 par d\u00e9faut. Le code est disponible dans la classe PropertyBasedAuthProvider Un mod\u00e8le OAuth2 dont un exemple est donn\u00e9 par GithubOAuthProvider Un mod\u00e8le bas\u00e9 sur des jetons JWT , dont une impl\u00e9mentation pour AWS est disponible dans AWSJWTAuthProvider Si ces mod\u00e8les ne correspondent pas \u00e0 votre besoin, il est relativement simple d'en d\u00e9velopper d'autres en se basant sur les exemples ci-dessus. N'h\u00e9sitez pas \u00e0 contribuer au projet et \u00e0 nous contacter pour toute question! Chiffrage et anonymisation \u00b6 Chiffrage \u00b6 Il est recommand\u00e9 de d\u00e9ployer vos bases de donn\u00e9es MongoDB en mode chiffr\u00e9 . Vous pouvez cependant ajouter un chiffrage applicatif (facultatif) de certains champs en base de donn\u00e9es. C'est le r\u00f4le de la propri\u00e9t\u00e9 tock_encrypt_pass qui permet d'indiquer un mot de passe pour chiffrer et d\u00e9chiffrer ces champs. Par d\u00e9faut, Tock chiffre toutes les donn\u00e9es utilisateurs jug\u00e9es sensibles \u00e0 condition que ce mot de passe soit sp\u00e9cifi\u00e9. Pour plus de d\u00e9tails, vous pouvez vous r\u00e9ferrer au code source . Anonymisation \u00b6 Il est souvent souhaitable que certaines phrases soient anonymis\u00e9es que ce soit dans les logs (journalisation) ou dans l'interface ( Tock Studio ). Par exemple, des coordonn\u00e9es, num\u00e9ros de cartes de fid\u00e9lit\u00e9, etc. ne devraient \u00eatre lus ni par les utilisateurs de Tock Studio ni par les administrateurs de la plateforme. Pour anonymiser ces donn\u00e9es, Tock met \u00e0 disposition dans son framework une solution bas\u00e9e sur des expressions r\u00e9guli\u00e8res (RegExp) dont l'interface de base est StringObfuscator .","title":"Security"},{"location":"admin/security/#securite","text":"","title":"S\u00e9curit\u00e9"},{"location":"admin/security/#authentification","text":"Tock supporte plusieurs syst\u00e8mes d'authentification pour l'interface d'administration. Il utilise les librairies vert.x correspondantes. Voici les syst\u00e8mes disponibles par d\u00e9faut : Un mod\u00e8le par \"propri\u00e9t\u00e9s\", utilis\u00e9 par d\u00e9faut. Le code est disponible dans la classe PropertyBasedAuthProvider Un mod\u00e8le OAuth2 dont un exemple est donn\u00e9 par GithubOAuthProvider Un mod\u00e8le bas\u00e9 sur des jetons JWT , dont une impl\u00e9mentation pour AWS est disponible dans AWSJWTAuthProvider Si ces mod\u00e8les ne correspondent pas \u00e0 votre besoin, il est relativement simple d'en d\u00e9velopper d'autres en se basant sur les exemples ci-dessus. N'h\u00e9sitez pas \u00e0 contribuer au projet et \u00e0 nous contacter pour toute question!","title":"Authentification"},{"location":"admin/security/#chiffrage-et-anonymisation","text":"","title":"Chiffrage et anonymisation"},{"location":"admin/security/#chiffrage","text":"Il est recommand\u00e9 de d\u00e9ployer vos bases de donn\u00e9es MongoDB en mode chiffr\u00e9 . Vous pouvez cependant ajouter un chiffrage applicatif (facultatif) de certains champs en base de donn\u00e9es. C'est le r\u00f4le de la propri\u00e9t\u00e9 tock_encrypt_pass qui permet d'indiquer un mot de passe pour chiffrer et d\u00e9chiffrer ces champs. Par d\u00e9faut, Tock chiffre toutes les donn\u00e9es utilisateurs jug\u00e9es sensibles \u00e0 condition que ce mot de passe soit sp\u00e9cifi\u00e9. Pour plus de d\u00e9tails, vous pouvez vous r\u00e9ferrer au code source .","title":"Chiffrage"},{"location":"admin/security/#anonymisation","text":"Il est souvent souhaitable que certaines phrases soient anonymis\u00e9es que ce soit dans les logs (journalisation) ou dans l'interface ( Tock Studio ). Par exemple, des coordonn\u00e9es, num\u00e9ros de cartes de fid\u00e9lit\u00e9, etc. ne devraient \u00eatre lus ni par les utilisateurs de Tock Studio ni par les administrateurs de la plateforme. Pour anonymiser ces donn\u00e9es, Tock met \u00e0 disposition dans son framework une solution bas\u00e9e sur des expressions r\u00e9guli\u00e8res (RegExp) dont l'interface de base est StringObfuscator .","title":"Anonymisation"},{"location":"dev/api/","text":"Les APIs Tock \u00b6 Cette section de la documentation Tock pr\u00e9sente sommairement les diff\u00e9rentes API fournies avec Tock. Tock NLU API \u00b6 L'API NLU de Tock (reconnaissance du langage naturel) permet d'interroger programmatiquement le mod\u00e8le conversationnel et d'analyser une phrase. La documentation de l'API Tock NLU est disponible dans /api . Vous pouvez retrouver cette documentation sur la plateforme de d\u00e9monstration Tock, \u00e0 l'adresse https://demo.tock.ai/doc/ . Si vous avez d\u00e9ploy\u00e9 une plateforme Tock en local avec les images docker fournies, vous pouvez retrouver cette documentation en ligne \u00e0 l'adresse http://localhost/doc/index.html . Tock Studio API \u00b6 De m\u00eame, la documentation de l'API Tock Studio est disponible dans /api/admin . Vous pouvez retrouver cette documentation sur la plateforme de d\u00e9monstration Tock, \u00e0 l'adresse https://demo.tock.ai/doc/admin.html . Si vous avez d\u00e9ploy\u00e9 une plateforme Tock en local avec les images docker fournies, vous pouvez retrouver cette documentation en ligne \u00e0 l'adresse http://localhost/doc/admin.html . Tock Bot API \u00b6 Cette API permet de d\u00e9velopper des bots Tock avec n'importe quel langage. Elle est utilis\u00e9e par les clients Kotlin en modes WebHook et WebSocket . L'API est toutefois encore en d\u00e9veloppement (b\u00e9ta) et sa documentation arrivera bient\u00f4t. Pour d\u00e9velopper en mode Bot API , voir cette page .","title":"APIs"},{"location":"dev/api/#les-apis-tock","text":"Cette section de la documentation Tock pr\u00e9sente sommairement les diff\u00e9rentes API fournies avec Tock.","title":"Les APIs Tock"},{"location":"dev/api/#tock-nlu-api","text":"L'API NLU de Tock (reconnaissance du langage naturel) permet d'interroger programmatiquement le mod\u00e8le conversationnel et d'analyser une phrase. La documentation de l'API Tock NLU est disponible dans /api . Vous pouvez retrouver cette documentation sur la plateforme de d\u00e9monstration Tock, \u00e0 l'adresse https://demo.tock.ai/doc/ . Si vous avez d\u00e9ploy\u00e9 une plateforme Tock en local avec les images docker fournies, vous pouvez retrouver cette documentation en ligne \u00e0 l'adresse http://localhost/doc/index.html .","title":"Tock NLU API"},{"location":"dev/api/#tock-studio-api","text":"De m\u00eame, la documentation de l'API Tock Studio est disponible dans /api/admin . Vous pouvez retrouver cette documentation sur la plateforme de d\u00e9monstration Tock, \u00e0 l'adresse https://demo.tock.ai/doc/admin.html . Si vous avez d\u00e9ploy\u00e9 une plateforme Tock en local avec les images docker fournies, vous pouvez retrouver cette documentation en ligne \u00e0 l'adresse http://localhost/doc/admin.html .","title":"Tock Studio API"},{"location":"dev/api/#tock-bot-api","text":"Cette API permet de d\u00e9velopper des bots Tock avec n'importe quel langage. Elle est utilis\u00e9e par les clients Kotlin en modes WebHook et WebSocket . L'API est toutefois encore en d\u00e9veloppement (b\u00e9ta) et sa documentation arrivera bient\u00f4t. Pour d\u00e9velopper en mode Bot API , voir cette page .","title":"Tock Bot API"},{"location":"dev/bot-api/","text":"D\u00e9velopper en mode Tock Bot API \u00b6 Le mode Bot API de Tock permet de d\u00e9velopper des bots en se connectant \u00e0 une plateforme NLU Tock d'une mani\u00e8re peu coupl\u00e9e car n'ayant pas acc\u00e8s \u00e0 la base de donn\u00e9es (MongoDB), contrairement au mode Bot Framework . C'est donc le mode de d\u00e9veloppement Tock recommand\u00e9 pour d\u00e9marrer, ainsi que dans des scenarios ou l'acc\u00e8s partag\u00e9 \u00e0 la base de donn\u00e9es serait un probl\u00e8me. Par exemple, seul le mode Bot API est autoris\u00e9 sur la plateforme de d\u00e9monstration publique Tock (pour des raisons de s\u00e9curit\u00e9 \u00e9videntes). Cette page pr\u00e9sente le d\u00e9veloppement de bots Tock en mode Bot API en Kotlin . Notez qu'il est possible de d\u00e9velopper dans n'importe quel langage via la Bot API - une documentation pour un autre langage devrait bient\u00f4t arriver. Une autre section pr\u00e9sente le mode Bot Framework , plus int\u00e9gr\u00e9 mais aussi plus coupl\u00e9 \u00e0 la plateforme Tock. D\u00e9velopper en Bot API en Kotlin \u00b6 Pr\u00e9-requis / Architecture \u00b6 Pour utiliser le mode Bot API de Tock, un module sp\u00e9cifique doit \u00eatre d\u00e9ploy\u00e9 avec la plateforme. G\u00e9n\u00e9ralement appel\u00e9 bot-api dans les descripteurs Docker Compose par exemple, ce service a pour r\u00f4le : D'exposer la Bot API aux clients potentiels quelque soit leur langage de programmation D'accepter des connexions en WebSocket Le guide D\u00e9ployer Tock avec Docker ou encore le chapitre Installation montrent comment d\u00e9ployer ce module si n\u00e9cessaire. Le module bot-api est d\u00e9j\u00e0 d\u00e9ploy\u00e9 sur la plateforme de d\u00e9monstration Tock . Activer le mode WebSocket \u00b6 C'est le mode \u00e0 privil\u00e9gier au d\u00e9marrage car le plus simple \u00e0 mettre en oeuvre. Pour utiliser le client websocket, il faut ajouter la d\u00e9pendance tock-bot-api-websocket \u00e0 votre application/projet Kotlin . Par exemple dans un projet Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-websocket </artifactId> <version> 19.3.3 </version> </dependency> Ou dans un projet Gradle : compile 'ai.tock:tock-bot-api-websocket:19.3.3' Activer le mode WebHook \u00b6 Pour utiliser le client WebHook , il faut ajouter la d\u00e9pendance tock-bot-api-webhook \u00e0 votre application/projet Kotlin . Par exemple dans un projet Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-webhook </artifactId> <version> 19.3.3 </version> </dependency> Ou dans un projet Gradle : compile 'ai.tock:tock-bot-api-webhook:19.3.3' Dans ce cas, contrairement au mode WebSocket , il faut que l'application/bot d\u00e9marr\u00e9e soit joignable par la plateforme Tock. Son URL doit \u00eatre indiqu\u00e9e dans le champ webhook url dans la vue Configuration > Bot Configurations de l'interface Tock Studio . Param\u00e9trer la cl\u00e9 d'API \u00b6 Dans Tock Studio , apr\u00e8s avoir configur\u00e9 un bot, allez dans Configuration > Bot Configurations et copiez la cl\u00e9 d'API du bot auquel vous souhaitez vous connecter. Vous pourrez saisir/coller cette clef dans le code Kotlin (voir ci-dessous). Cr\u00e9er des parcours en Kotlin \u00b6 Pour le moment, les composants suivants sont support\u00e9s pour les r\u00e9ponses : Texte brut Format \"carte\" Formats sp\u00e9cfiques aux diff\u00e9rents canaux int\u00e9gr\u00e9s Voici un exemple de bot simple avec quelques parcours d\u00e9clar\u00e9s : fun main () { start ( newBot ( \"PUT-YOUR-TOCK-APP-API-KEY-HERE\" , // Get your app API key from Bot Configurations in Tock Studio newStory ( \"greetings\" ) { // Intent 'greetings' end ( \"Bonjour!\" ) // Raw text answer }, newStory ( \"location\" ) { // Intent 'location' end ( newCard ( \"Le titre de la carte\" , \"Un sous-titre\" , newAttachment ( \"https://url-image.png\" ), newAction ( \"Action 1\" ), newAction ( \"Action 2\" , \"http://redirection\" ) // Anwser with a card - including text, image and actions ) ) }, newStory ( \"goodbye\" ) { // Intent 'goodbye' end { // Answer with Messenger-specific button/quick reply buttonsTemplate ( \"Etes-vous s\u00fbr(e) de vouloir partir ?\" , nlpQuickReply ( \"Je reste\" )) } }, unknownStory { end ( \"Je n'ai pas compris. Mais j'apprends tous les jours :)\" ) // Default answer } ), \"http://localhost:8080\" // Local platform URL (default host/port) ) } Tester avec la plateforme de d\u00e9monstration \u00b6 Plut\u00f4t que d\u00e9ployer se propre plateforme Tock, il est possible de tester le mode WebSocket directement sur la plateforme de d\u00e9monstration Tock . Pour cela, il suffit de remplacer la m\u00e9thode start par startWithDemo (sans pr\u00e9ciser l'adresse de la plateforme). D\u00e9velopper dans un autre langage \u00b6 Il est possible de d\u00e9velopper dans n'importe quel langage en programmant directement via l'API. TODO : contrat en cours de stabilisation & documentation \u00e0 venir.","title":"Tock Bot API"},{"location":"dev/bot-api/#developper-en-mode-tock-bot-api","text":"Le mode Bot API de Tock permet de d\u00e9velopper des bots en se connectant \u00e0 une plateforme NLU Tock d'une mani\u00e8re peu coupl\u00e9e car n'ayant pas acc\u00e8s \u00e0 la base de donn\u00e9es (MongoDB), contrairement au mode Bot Framework . C'est donc le mode de d\u00e9veloppement Tock recommand\u00e9 pour d\u00e9marrer, ainsi que dans des scenarios ou l'acc\u00e8s partag\u00e9 \u00e0 la base de donn\u00e9es serait un probl\u00e8me. Par exemple, seul le mode Bot API est autoris\u00e9 sur la plateforme de d\u00e9monstration publique Tock (pour des raisons de s\u00e9curit\u00e9 \u00e9videntes). Cette page pr\u00e9sente le d\u00e9veloppement de bots Tock en mode Bot API en Kotlin . Notez qu'il est possible de d\u00e9velopper dans n'importe quel langage via la Bot API - une documentation pour un autre langage devrait bient\u00f4t arriver. Une autre section pr\u00e9sente le mode Bot Framework , plus int\u00e9gr\u00e9 mais aussi plus coupl\u00e9 \u00e0 la plateforme Tock.","title":"D\u00e9velopper en mode Tock Bot API"},{"location":"dev/bot-api/#developper-en-bot-api-en-kotlin","text":"","title":"D\u00e9velopper en Bot API en Kotlin"},{"location":"dev/bot-api/#pre-requis-architecture","text":"Pour utiliser le mode Bot API de Tock, un module sp\u00e9cifique doit \u00eatre d\u00e9ploy\u00e9 avec la plateforme. G\u00e9n\u00e9ralement appel\u00e9 bot-api dans les descripteurs Docker Compose par exemple, ce service a pour r\u00f4le : D'exposer la Bot API aux clients potentiels quelque soit leur langage de programmation D'accepter des connexions en WebSocket Le guide D\u00e9ployer Tock avec Docker ou encore le chapitre Installation montrent comment d\u00e9ployer ce module si n\u00e9cessaire. Le module bot-api est d\u00e9j\u00e0 d\u00e9ploy\u00e9 sur la plateforme de d\u00e9monstration Tock .","title":"Pr\u00e9-requis / Architecture"},{"location":"dev/bot-api/#activer-le-mode-websocket","text":"C'est le mode \u00e0 privil\u00e9gier au d\u00e9marrage car le plus simple \u00e0 mettre en oeuvre. Pour utiliser le client websocket, il faut ajouter la d\u00e9pendance tock-bot-api-websocket \u00e0 votre application/projet Kotlin . Par exemple dans un projet Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-websocket </artifactId> <version> 19.3.3 </version> </dependency> Ou dans un projet Gradle : compile 'ai.tock:tock-bot-api-websocket:19.3.3'","title":"Activer le mode WebSocket"},{"location":"dev/bot-api/#activer-le-mode-webhook","text":"Pour utiliser le client WebHook , il faut ajouter la d\u00e9pendance tock-bot-api-webhook \u00e0 votre application/projet Kotlin . Par exemple dans un projet Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-webhook </artifactId> <version> 19.3.3 </version> </dependency> Ou dans un projet Gradle : compile 'ai.tock:tock-bot-api-webhook:19.3.3' Dans ce cas, contrairement au mode WebSocket , il faut que l'application/bot d\u00e9marr\u00e9e soit joignable par la plateforme Tock. Son URL doit \u00eatre indiqu\u00e9e dans le champ webhook url dans la vue Configuration > Bot Configurations de l'interface Tock Studio .","title":"Activer le mode WebHook"},{"location":"dev/bot-api/#parametrer-la-cle-dapi","text":"Dans Tock Studio , apr\u00e8s avoir configur\u00e9 un bot, allez dans Configuration > Bot Configurations et copiez la cl\u00e9 d'API du bot auquel vous souhaitez vous connecter. Vous pourrez saisir/coller cette clef dans le code Kotlin (voir ci-dessous).","title":"Param\u00e9trer la cl\u00e9 d'API"},{"location":"dev/bot-api/#creer-des-parcours-en-kotlin","text":"Pour le moment, les composants suivants sont support\u00e9s pour les r\u00e9ponses : Texte brut Format \"carte\" Formats sp\u00e9cfiques aux diff\u00e9rents canaux int\u00e9gr\u00e9s Voici un exemple de bot simple avec quelques parcours d\u00e9clar\u00e9s : fun main () { start ( newBot ( \"PUT-YOUR-TOCK-APP-API-KEY-HERE\" , // Get your app API key from Bot Configurations in Tock Studio newStory ( \"greetings\" ) { // Intent 'greetings' end ( \"Bonjour!\" ) // Raw text answer }, newStory ( \"location\" ) { // Intent 'location' end ( newCard ( \"Le titre de la carte\" , \"Un sous-titre\" , newAttachment ( \"https://url-image.png\" ), newAction ( \"Action 1\" ), newAction ( \"Action 2\" , \"http://redirection\" ) // Anwser with a card - including text, image and actions ) ) }, newStory ( \"goodbye\" ) { // Intent 'goodbye' end { // Answer with Messenger-specific button/quick reply buttonsTemplate ( \"Etes-vous s\u00fbr(e) de vouloir partir ?\" , nlpQuickReply ( \"Je reste\" )) } }, unknownStory { end ( \"Je n'ai pas compris. Mais j'apprends tous les jours :)\" ) // Default answer } ), \"http://localhost:8080\" // Local platform URL (default host/port) ) }","title":"Cr\u00e9er des parcours en Kotlin"},{"location":"dev/bot-api/#tester-avec-la-plateforme-de-demonstration","text":"Plut\u00f4t que d\u00e9ployer se propre plateforme Tock, il est possible de tester le mode WebSocket directement sur la plateforme de d\u00e9monstration Tock . Pour cela, il suffit de remplacer la m\u00e9thode start par startWithDemo (sans pr\u00e9ciser l'adresse de la plateforme).","title":"Tester avec la plateforme de d\u00e9monstration"},{"location":"dev/bot-api/#developper-dans-un-autre-langage","text":"Il est possible de d\u00e9velopper dans n'importe quel langage en programmant directement via l'API. TODO : contrat en cours de stabilisation & documentation \u00e0 venir.","title":"D\u00e9velopper dans un autre langage"},{"location":"dev/connecteurs/","text":"Les connecteurs Tock \u00b6 La page Bot multicanal de la documentation utilisateur pr\u00e9sente la notion de connecteur Tock, ainsi que la liste des connecteurs d\u00e9j\u00e0 disponibles. Cette page n'ajoute donc que les \u00e9l\u00e9ments propres au d\u00e9veloppement avec les connecteurs Tock ou le d\u00e9veloppement de nouveaux connecteurs. G\u00e9n\u00e9ralit\u00e9s \u00b6 TODO : composants sp\u00e9cifiques \u00e0 un connecteur/canal et utilisation en mode Bot API ou en mode Bot int\u00e9gr\u00e9 . Messenger \u00b6 Pour en savoir plus sur ce connecteur, vous pouvez aussi vous rendre dans le dossier connector-messenger sur GitHub, o\u00f9 vous retrouverez les sources et le README du connecteur. Slack \u00b6 Pour en savoir plus sur ce connecteur, vous pouvez aussi vous rendre dans le dossier connector-slack sur GitHub, o\u00f9 vous retrouverez les sources et le README du connecteur. Google Assistant / Google Home \u00b6 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-ga sur GitHub. Alexa / Echo \u00b6 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-alexa sur GitHub. Rocket.Chat \u00b6 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-rocketchat sur GitHub. WhatsApp \u00b6 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-whatsapp sur GitHub. Teams \u00b6 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-teams sur GitHub. Business Chat / Messages \u00b6 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-businesschat sur GitHub. Twitter \u00b6 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-twitter sur GitHub. Web \u00b6 Work in progress D\u00e9velopper son propre connecteur \u00b6 Il est possible de cr\u00e9er son propre connecteur Tock, par exemple pour interfacer un bot Tock avec un canal propre \u00e0 l'organisation (souvent un site Web ou une application mobile sp\u00e9cifiques), ou bien quand un canal grand public s'ouvre aux bots conversationnels et que le connecteur Tock n'existe pas encore. Pour cela quatres \u00e9tapes sont n\u00e9cessaires : 1) Impl\u00e9menter l'interface Connector Voici un exemple d'impl\u00e9mentation : val testConnectorType = ConnectorType ( \"test\" ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router -> //main API router . post ( \"$path/message\" ). blockingHandler { context -> //ConnectorRequest est mon objet m\u00e9tier pass\u00e9 par l'appli front val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //transformation de l'objet m\u00e9tier en Event tock val event = readUserMessage ( message ) // on passe l'\u00e9v\u00e8nement au framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //on enregistre l'action callback . actions . add ( event ) //si c'est la derni\u00e8re action \u00e0 envoyer, on envoie la r\u00e9ponse if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { \"unsupported event: $event\" } } } } // pour r\u00e9cup\u00e9rer toutes les actions avant envoi class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList < Action > = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //on transforme la liste des r\u00e9ponses Tock en r\u00e9ponse m\u00e9tier val response = mapper . writeValueAsString ( actions . map {...}) //puis on envoie la r\u00e9ponse context . response (). end ( response ) } } 2) Impl\u00e9menter l'interface ConnectorProvider Voici un exemple d'impl\u00e9mentation : object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Rendre disponible ce connecteur via un Service Loader : Pour cela, placez un fichier META-INF/services/fr.vsct.tock.bot.connector.ConnectorProvider dans le classpath, contenant le nom de la classe : mypackage.TestConnectorProviderService 4) Rajouter toutes les classes et fichiers cr\u00e9\u00e9s dans le classpath de l'admin et du bot. Le nouveau connecteur doit alors \u00eatre disponible dans l'interface Bot Configurations de Tock Studio .","title":"Connectors"},{"location":"dev/connecteurs/#les-connecteurs-tock","text":"La page Bot multicanal de la documentation utilisateur pr\u00e9sente la notion de connecteur Tock, ainsi que la liste des connecteurs d\u00e9j\u00e0 disponibles. Cette page n'ajoute donc que les \u00e9l\u00e9ments propres au d\u00e9veloppement avec les connecteurs Tock ou le d\u00e9veloppement de nouveaux connecteurs.","title":"Les connecteurs Tock"},{"location":"dev/connecteurs/#generalites","text":"TODO : composants sp\u00e9cifiques \u00e0 un connecteur/canal et utilisation en mode Bot API ou en mode Bot int\u00e9gr\u00e9 .","title":"G\u00e9n\u00e9ralit\u00e9s"},{"location":"dev/connecteurs/#messenger","text":"Pour en savoir plus sur ce connecteur, vous pouvez aussi vous rendre dans le dossier connector-messenger sur GitHub, o\u00f9 vous retrouverez les sources et le README du connecteur.","title":"Messenger"},{"location":"dev/connecteurs/#slack","text":"Pour en savoir plus sur ce connecteur, vous pouvez aussi vous rendre dans le dossier connector-slack sur GitHub, o\u00f9 vous retrouverez les sources et le README du connecteur.","title":"Slack"},{"location":"dev/connecteurs/#google-assistant-google-home","text":"Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-ga sur GitHub.","title":"Google Assistant / Google Home"},{"location":"dev/connecteurs/#alexa-echo","text":"Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-alexa sur GitHub.","title":"Alexa / Echo"},{"location":"dev/connecteurs/#rocketchat","text":"Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-rocketchat sur GitHub.","title":"Rocket.Chat"},{"location":"dev/connecteurs/#whatsapp","text":"Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-whatsapp sur GitHub.","title":"WhatsApp"},{"location":"dev/connecteurs/#teams","text":"Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-teams sur GitHub.","title":"Teams"},{"location":"dev/connecteurs/#business-chat-messages","text":"Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-businesschat sur GitHub.","title":"Business Chat / Messages"},{"location":"dev/connecteurs/#twitter","text":"Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-twitter sur GitHub.","title":"Twitter"},{"location":"dev/connecteurs/#web","text":"Work in progress","title":"Web"},{"location":"dev/connecteurs/#developper-son-propre-connecteur","text":"Il est possible de cr\u00e9er son propre connecteur Tock, par exemple pour interfacer un bot Tock avec un canal propre \u00e0 l'organisation (souvent un site Web ou une application mobile sp\u00e9cifiques), ou bien quand un canal grand public s'ouvre aux bots conversationnels et que le connecteur Tock n'existe pas encore. Pour cela quatres \u00e9tapes sont n\u00e9cessaires : 1) Impl\u00e9menter l'interface Connector Voici un exemple d'impl\u00e9mentation : val testConnectorType = ConnectorType ( \"test\" ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router -> //main API router . post ( \"$path/message\" ). blockingHandler { context -> //ConnectorRequest est mon objet m\u00e9tier pass\u00e9 par l'appli front val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //transformation de l'objet m\u00e9tier en Event tock val event = readUserMessage ( message ) // on passe l'\u00e9v\u00e8nement au framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //on enregistre l'action callback . actions . add ( event ) //si c'est la derni\u00e8re action \u00e0 envoyer, on envoie la r\u00e9ponse if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { \"unsupported event: $event\" } } } } // pour r\u00e9cup\u00e9rer toutes les actions avant envoi class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList < Action > = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //on transforme la liste des r\u00e9ponses Tock en r\u00e9ponse m\u00e9tier val response = mapper . writeValueAsString ( actions . map {...}) //puis on envoie la r\u00e9ponse context . response (). end ( response ) } } 2) Impl\u00e9menter l'interface ConnectorProvider Voici un exemple d'impl\u00e9mentation : object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Rendre disponible ce connecteur via un Service Loader : Pour cela, placez un fichier META-INF/services/fr.vsct.tock.bot.connector.ConnectorProvider dans le classpath, contenant le nom de la classe : mypackage.TestConnectorProviderService 4) Rajouter toutes les classes et fichiers cr\u00e9\u00e9s dans le classpath de l'admin et du bot. Le nouveau connecteur doit alors \u00eatre disponible dans l'interface Bot Configurations de Tock Studio .","title":"D\u00e9velopper son propre connecteur"},{"location":"dev/exemples-code/","text":"Exemples de code Tock \u00b6 Les exemples dans Bot Samples \u00b6 Le d\u00e9p\u00f4t GitHub tock-bot-samples contient des exemples de code, notamment ceux utilis\u00e9s dans la documentation Tock pour programmer des parcours en modes WebHook ou WebSocket . Le bot Open Data \u00b6 Le d\u00e9p\u00f4t GitHub tock-bot-open-data contient un exemple d'impl\u00e9mentation de bot bas\u00e9 sur les API Open Data de la SNCF . Ce bot utilise le framework Kotlin pour Tock (et pas le mode Bot API via Webhook ou WebSocket ). Il impl\u00e9mente \u00e9galement une internationalisation avec deux langues propos\u00e9es : Fran\u00e7ais et Anglais. TODO : description des principales fonctionnalit\u00e9s, parcours \u00e0 tester, comment tester l'i18n, etc. D\u00e9ployer le bot avec Docker \u00b6 Pour d\u00e9ployer le bot avec Docker / Docker Compose , suivez les instructions du d\u00e9p\u00f4t tock-docker . D\u00e9ployer le bot dans son IDE \u00b6 Si vous pr\u00e9f\u00e9rez d\u00e9ployer une plateforme Tock sans le Bot Open Data, et ex\u00e9cuter celui-ci dans votre IDE (vous permettant par exemple de faire du debug pas-\u00e0-pas), suivez ces instructions : D\u00e9ployez une stack Tock NLU gr\u00e2ce au descripteur docker-compose.yml comme expliqu\u00e9 ici Demandez votre propre clef SNCF Open Data (gratuite) et configurez la variable d'environnement (voir OpenDataConfiguration ) Configurez un connecteur : Messenger, Google Assistant ou autre (voir canaux et connecteurs ) D\u00e9marrez le lanceur OpenDataBot dans votre IDE, IntelliJ ou autre. Le bot est op\u00e9rationnel, parlez-lui ! :) Tester le bot & l'internationalisation \u00b6 TODO","title":"Code samples"},{"location":"dev/exemples-code/#exemples-de-code-tock","text":"","title":"Exemples de code Tock"},{"location":"dev/exemples-code/#les-exemples-dans-bot-samples","text":"Le d\u00e9p\u00f4t GitHub tock-bot-samples contient des exemples de code, notamment ceux utilis\u00e9s dans la documentation Tock pour programmer des parcours en modes WebHook ou WebSocket .","title":"Les exemples dans Bot Samples"},{"location":"dev/exemples-code/#le-bot-open-data","text":"Le d\u00e9p\u00f4t GitHub tock-bot-open-data contient un exemple d'impl\u00e9mentation de bot bas\u00e9 sur les API Open Data de la SNCF . Ce bot utilise le framework Kotlin pour Tock (et pas le mode Bot API via Webhook ou WebSocket ). Il impl\u00e9mente \u00e9galement une internationalisation avec deux langues propos\u00e9es : Fran\u00e7ais et Anglais. TODO : description des principales fonctionnalit\u00e9s, parcours \u00e0 tester, comment tester l'i18n, etc.","title":"Le bot Open Data"},{"location":"dev/exemples-code/#deployer-le-bot-avec-docker","text":"Pour d\u00e9ployer le bot avec Docker / Docker Compose , suivez les instructions du d\u00e9p\u00f4t tock-docker .","title":"D\u00e9ployer le bot avec Docker"},{"location":"dev/exemples-code/#deployer-le-bot-dans-son-ide","text":"Si vous pr\u00e9f\u00e9rez d\u00e9ployer une plateforme Tock sans le Bot Open Data, et ex\u00e9cuter celui-ci dans votre IDE (vous permettant par exemple de faire du debug pas-\u00e0-pas), suivez ces instructions : D\u00e9ployez une stack Tock NLU gr\u00e2ce au descripteur docker-compose.yml comme expliqu\u00e9 ici Demandez votre propre clef SNCF Open Data (gratuite) et configurez la variable d'environnement (voir OpenDataConfiguration ) Configurez un connecteur : Messenger, Google Assistant ou autre (voir canaux et connecteurs ) D\u00e9marrez le lanceur OpenDataBot dans votre IDE, IntelliJ ou autre. Le bot est op\u00e9rationnel, parlez-lui ! :)","title":"D\u00e9ployer le bot dans son IDE"},{"location":"dev/exemples-code/#tester-le-bot-linternationalisation","text":"TODO","title":"Tester le bot &amp; l'internationalisation"},{"location":"dev/i18n/","text":"D\u00e9velopper un bot multilingue ( i18n ) \u00b6 La page Bot multilingue de la documentation utilisateur pr\u00e9sente les bases de l'internationalisation ( i18n ) pour construire des bots avec Tock : pr\u00e9-requis, Locale , etc. Cette page vient compl\u00e9ter cette documentation avec des \u00e9l\u00e9ments propres au d\u00e9veloppement. Pr\u00e9-requis \u00b6 Pour activer l'internationalisation dans Tock, programmatiquement ou pas, voir Bot multilingue . Principes \u00b6 Le code ne change pas une fois l'internationalisation activ\u00e9e. Par exemple : send ( \"Arrival at {0}\" , time ) est un code valide que le module soit activ\u00e9 ou non. Par contre, \u00e0 l'ex\u00e9cution, le comportement diff\u00e8re significativement. Si l'internationalisation est activ\u00e9e, les op\u00e9rations suivantes vont \u00eatre effectu\u00e9es : Une cl\u00e9 va \u00eatre g\u00e9n\u00e9r\u00e9e \u00e0 partir du texte pass\u00e9 en param\u00e8tre, en fonction du namespace (l'organisation du cr\u00e9ateur du bot) et de la story dans laquelle est demand\u00e9 ce libell\u00e9. Dans le cas ci-dessus, cela devrait ressembler \u00e0 app_arrivals_Arrival at {0} o\u00f9 app est le namespace et arrivals l'intention principale de la story. Tock v\u00e9rifie ensuite si cette cl\u00e9 est d\u00e9j\u00e0 pr\u00e9sente en base. Si c'est le cas, il utilise le libell\u00e9 pr\u00e9sent en base pour la langue demand\u00e9e afin de trouver la traduction la plus appropri\u00e9e (le connecteur ou le type d'interface peuvent \u00e9galement \u00eatre pris en compte) Sinon, une cl\u00e9 est cr\u00e9\u00e9e en base avec le libell\u00e9 par d\u00e9faut (\"Arrival at {0}\" dans notre exemple) utilis\u00e9e pour la langue courante Il est ensuite possible de consulter et de modifier ce libell\u00e9 dans l'interface d'administration : Format des messages \u00b6 Le format support\u00e9 est celui du support i18n de java, en particulier celui de la classe MessageFormat en java. Cela inclut le support de ChoiceFormat : send ( \"There {0,choice,0#are no files|1#is one file|1<are {0,number,integer} files}.\" , 2 ) Par ailleurs, Tock met \u00e0 disposition une extension by pour les dates qui permet d'indiquer un format dans les param\u00e8tres : send ( \"Departure at {0}\" , departureDateTime by timeFormat ) Locale utilisateur \u00b6 Voir Bot multilingue . Points d'attention \u00b6 Le module d'internationalisation de Tock est efficace, mais certaines pratiques, pourtant intuitives en Kotlin, sont \u00e0 bannir sous peine de mauvaises surprises. Par exemple, ce code fonctionne parfaitement bien avec le module i18n d\u00e9sactiv\u00e9. send ( \"There are $nb files\" ) //DANGER!! mais pose probl\u00e8me si il est activ\u00e9. En effet, un nouveau libell\u00e9 sera cr\u00e9\u00e9 pour chaque valeur diff\u00e9rente de la variable nb ! Si il est n\u00e9cessaire d'envoyer des r\u00e9ponses \"\u00e0 ne pas traduire\", utilisez les m\u00e9thodes BotBus.sendRaw , BotBus.endRaw ou String.raw send ( \"There are $nb files\" . raw ) //CORRECT send ( \"There are {0} files\" , nb ) //FORMAT A SUIVRE Le risque de collision entre deux libell\u00e9s est faible puisque l'intention principale de la story fait partie de la cl\u00e9. Si vous souhaitez cependant \u00e9viter tout risque, vous pouvez utiliser la m\u00e9thode i18nKey : send ( i18nKey ( \"my_unique_key\" , \"There are {0} files\" , nb )) Tester l'internationalisation \u00b6 Un exemple de dispositif de test est disponible dans le code source du bot d'exemple Il est n\u00e9cessaire d'\u00e9tendre l'extension de test pour ensuite indiquer la correspondance des libell\u00e9s \u00e0 tester. Il ne reste plus qu'\u00e0 indiquer la locale souhait\u00e9e : @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Recherche\" , search , locale = Locale . FRENCH ) { destination = lille origin = paris run () firstAnswer . assertText ( \"Quand souhaitez-vous partir?\" ) } }","title":"i18n"},{"location":"dev/i18n/#developper-un-bot-multilingue-i18n","text":"La page Bot multilingue de la documentation utilisateur pr\u00e9sente les bases de l'internationalisation ( i18n ) pour construire des bots avec Tock : pr\u00e9-requis, Locale , etc. Cette page vient compl\u00e9ter cette documentation avec des \u00e9l\u00e9ments propres au d\u00e9veloppement.","title":"D\u00e9velopper un bot multilingue (i18n)"},{"location":"dev/i18n/#pre-requis","text":"Pour activer l'internationalisation dans Tock, programmatiquement ou pas, voir Bot multilingue .","title":"Pr\u00e9-requis"},{"location":"dev/i18n/#principes","text":"Le code ne change pas une fois l'internationalisation activ\u00e9e. Par exemple : send ( \"Arrival at {0}\" , time ) est un code valide que le module soit activ\u00e9 ou non. Par contre, \u00e0 l'ex\u00e9cution, le comportement diff\u00e8re significativement. Si l'internationalisation est activ\u00e9e, les op\u00e9rations suivantes vont \u00eatre effectu\u00e9es : Une cl\u00e9 va \u00eatre g\u00e9n\u00e9r\u00e9e \u00e0 partir du texte pass\u00e9 en param\u00e8tre, en fonction du namespace (l'organisation du cr\u00e9ateur du bot) et de la story dans laquelle est demand\u00e9 ce libell\u00e9. Dans le cas ci-dessus, cela devrait ressembler \u00e0 app_arrivals_Arrival at {0} o\u00f9 app est le namespace et arrivals l'intention principale de la story. Tock v\u00e9rifie ensuite si cette cl\u00e9 est d\u00e9j\u00e0 pr\u00e9sente en base. Si c'est le cas, il utilise le libell\u00e9 pr\u00e9sent en base pour la langue demand\u00e9e afin de trouver la traduction la plus appropri\u00e9e (le connecteur ou le type d'interface peuvent \u00e9galement \u00eatre pris en compte) Sinon, une cl\u00e9 est cr\u00e9\u00e9e en base avec le libell\u00e9 par d\u00e9faut (\"Arrival at {0}\" dans notre exemple) utilis\u00e9e pour la langue courante Il est ensuite possible de consulter et de modifier ce libell\u00e9 dans l'interface d'administration :","title":"Principes"},{"location":"dev/i18n/#format-des-messages","text":"Le format support\u00e9 est celui du support i18n de java, en particulier celui de la classe MessageFormat en java. Cela inclut le support de ChoiceFormat : send ( \"There {0,choice,0#are no files|1#is one file|1<are {0,number,integer} files}.\" , 2 ) Par ailleurs, Tock met \u00e0 disposition une extension by pour les dates qui permet d'indiquer un format dans les param\u00e8tres : send ( \"Departure at {0}\" , departureDateTime by timeFormat )","title":"Format des messages"},{"location":"dev/i18n/#locale-utilisateur","text":"Voir Bot multilingue .","title":"Locale utilisateur"},{"location":"dev/i18n/#points-dattention","text":"Le module d'internationalisation de Tock est efficace, mais certaines pratiques, pourtant intuitives en Kotlin, sont \u00e0 bannir sous peine de mauvaises surprises. Par exemple, ce code fonctionne parfaitement bien avec le module i18n d\u00e9sactiv\u00e9. send ( \"There are $nb files\" ) //DANGER!! mais pose probl\u00e8me si il est activ\u00e9. En effet, un nouveau libell\u00e9 sera cr\u00e9\u00e9 pour chaque valeur diff\u00e9rente de la variable nb ! Si il est n\u00e9cessaire d'envoyer des r\u00e9ponses \"\u00e0 ne pas traduire\", utilisez les m\u00e9thodes BotBus.sendRaw , BotBus.endRaw ou String.raw send ( \"There are $nb files\" . raw ) //CORRECT send ( \"There are {0} files\" , nb ) //FORMAT A SUIVRE Le risque de collision entre deux libell\u00e9s est faible puisque l'intention principale de la story fait partie de la cl\u00e9. Si vous souhaitez cependant \u00e9viter tout risque, vous pouvez utiliser la m\u00e9thode i18nKey : send ( i18nKey ( \"my_unique_key\" , \"There are {0} files\" , nb ))","title":"Points d'attention"},{"location":"dev/i18n/#tester-linternationalisation","text":"Un exemple de dispositif de test est disponible dans le code source du bot d'exemple Il est n\u00e9cessaire d'\u00e9tendre l'extension de test pour ensuite indiquer la correspondance des libell\u00e9s \u00e0 tester. Il ne reste plus qu'\u00e0 indiquer la locale souhait\u00e9e : @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Recherche\" , search , locale = Locale . FRENCH ) { destination = lille origin = paris run () firstAnswer . assertText ( \"Quand souhaitez-vous partir?\" ) } }","title":"Tester l'internationalisation"},{"location":"dev/integrated-bot/","text":"D\u00e9velopper en mode Tock Bot int\u00e9gr\u00e9 \u00b6 Le mode Bot int\u00e9gr\u00e9 Tock permet de d\u00e9velopper un bot en utilisant un Domain Specifique Language (DSL) en Kotlin . Contrairement au mode Bot API encore en d\u00e9veloppement, le Bot Framework Kotlin permet d'exploiter toutes les possibilit\u00e9s de la plateforme Tock, notamment : Gestion des contextes utilisateurs Historique de conversation Notions avanc\u00e9es comme la fusion d'entit\u00e9s Etc. Exemple de fusion d'entit\u00e9s : lorsque un utilisateur demande \"demain\" dans une phrase (appelons cette entit\u00e9 date ) puis \"plut\u00f4t le soir\" dans une phrase suivante, la fusion permet de mettre \u00e0 jour automatiquement l'entit\u00e9 ( date ) avec les deux informations compl\u00e9mentaires : jour et cr\u00e9neau horaire dans cet exemple. Attention : dans ce mode de d\u00e9veloppement, contrairement au mode Bot API , il est n\u00e9cessaire que le module bot dispose d'une connexion \u00e0 la base de donn\u00e9e (MongoDB) de la plateforme Tock utilis\u00e9e. Pour appr\u00e9hender compl\u00e8tement ce qui va suivre, il est recommand\u00e9 de ma\u00eetriser les bases du langage de programmation Kotlin . D\u00e9marrer avec le framework \u00b6 Documentation KDoc \u00b6 La documentation du framework au format KDoc est disponible ici . D\u00e9pendance bot-toolkit \u00b6 Pour utiliser le framework conversationnel, il faut ajouter la d\u00e9pendance bot-tookit \u00e0 l'application / au projet Kotlin. Par exemple dans un projet Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> bot-toolkit </artifactId> <version> 19.3.3 </version> </dependency> Ou dans un projet Gradle : compile 'ai.tock:bot-toolkit:19.3.3' Un bot est un ensemble de parcours (stories) \u00b6 Voici par exemple comment le Bot Open Data est d\u00e9fini : val openBot = bot ( \"bot_open_data\" , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) Ce bot comporte un identifiant (obligatoire - \"bot_open_data\") et une liste de parcours ou stories . Une Story est un regroupement fonctionnel qui correspond \u00e0 une intention principale et, de mani\u00e8re optionelle, \u00e0 une ou plusieurs intentions dites \"secondaires\" (voir Concepts ). Ici le bot d\u00e9finit 4 parcours : greetings , departures , arrivals et search . Le parcours greetings est d\u00e9clar\u00e9 comme parcours principal, il sera pr\u00e9sent\u00e9 par d\u00e9faut au d\u00e9but d'une conversation : hello = greetings . Une Story simple \u00b6 Comment d\u00e9finit-on une Story? Voici une premi\u00e8re version simplifi\u00e9e du parcours greetings : val greetings = story ( \"greetings\" ) { send ( \"Bienvenue chez le Bot Open Data Sncf! :)\" ) end ( \"Il s'agit d'un bot de d\u00e9monstration du framework Tock : https://github.com/theopenconversationkit/tock\" ) } Notez que dans le corps de la fonction, this est de type BotBus , \u00e0 partir duquel vous pouvez interagir avec l'utilisateur, et qui permet \u00e9galement d'acc\u00e8der \u00e0 tous les \u00e9lements contextuels disponibles. Concr\u00e8tement sela signifie que quand l'intention greetings sera d\u00e9tect\u00e9e par le mod\u00e8le NLP, la fonction ci-dessus sera appel\u00e9e par le framework Tock. Le bot envoie donc successivement une premi\u00e8re phrase de r\u00e9ponse ( bus.send() ), puis un deuxi\u00e8me en indiquant que c'est la derni\u00e8re phrase de sa r\u00e9ponse \u00e0 l'aide d'un bus.end() . Voici maintenant la version compl\u00e8te de greetings : val greetings = story ( \"greetings\" ) { //cleanup state resetDialogState () send ( \"Bienvenue chez le Bot Open Data Sncf! :)\" ) send ( \"Il s'agit d'un bot de d\u00e9monstration du framework Tock : https://github.com/theopenconversationkit/tock\" ) withMessenger { buttonsTemplate ( \"Il est volontairement tr\u00e8s limit\u00e9, mais demandez lui un itin\u00e9raire ou les d\u00e9parts \u00e0 partir d'une gare et constatez le r\u00e9sultat! :) \" , postbackButton ( \"Itin\u00e9raires\" , search ), postbackButton ( \"D\u00e9parts\" , Departures ), postbackButton ( \"Arriv\u00e9es\" , Arrivals ) ) } withGoogleAssistant { gaMessage ( \"Il est volontairement tr\u00e8s limit\u00e9, mais demandez lui un itin\u00e9raire ou les d\u00e9parts \u00e0 partir d'une gare et constatez le r\u00e9sultat! :) \" , \"Itin\u00e9raires\" , \"D\u00e9parts\" , \"Arriv\u00e9es\" ) } end () } Deux notions ont \u00e9t\u00e9 ajout\u00e9es : resetDialogState() qui permet de repartir d'un contexte utilisateur vide (en oubliant les \u00e9ventuels \u00e9changes pr\u00e9c\u00e9dents) les m\u00e9thodes withMessenger{} et withGoogleAssistant{} qui permettent de d\u00e9finir des r\u00e9ponses sp\u00e9cifiques pour chaque connecteur. Ici un texte avec des boutons pour Messenger, et un texte avec des suggestions pour Google Assistant. D\u00e9marrer et connecter le bot \u00b6 Pour d\u00e9marrer le bot, il suffit de rajouter dans votre main principal l'appel suivant : registerAndInstallBot ( openBot ) La variable openBot dans l'exemple est le bot que vous avez d\u00e9fini plus haut. Une fois le bot d\u00e9marr\u00e9, il est \u00e9galement n\u00e9cessaire de sp\u00e9cifier quels connecteurs sont utilis\u00e9s dans l'interface d'administration du bot, du menu Configuration > Bot Configurations > Create a new configuration . Pour en savoir plus sur les diff\u00e9rents canaux et connecteurs, voir cette page . Aller plus loin \u00b6 Bien s\u00fbr, le StoryHandler de greetings ne d\u00e9pend pas du contexte : la r\u00e9ponse est toujours la m\u00eame. Pour le d\u00e9veloppement de stories complexes, nous avons besoin d'une abstraction suppl\u00e9mentaire. Intentions secondaires \u00b6 Voici le d\u00e9but de la d\u00e9finition de la story search : val search = storyDef < SearchDef >( \"search\" , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } Le parcours search d\u00e9finit une intention secondaire \"de d\u00e9marrage\" ( indicate_origin ) et une intention secondaire simple ( indicate_location ). Une intention secondaire \"de d\u00e9marrage\" est semblable en tout point \u00e0 une intention principale : d\u00e8s que cette intention est d\u00e9tect\u00e9e, le parcours search va \u00eatre ex\u00e9cut\u00e9, si la story courante ne poss\u00e8de pas cette intention en tant qu'intention secondaire. Pour une intention secondaire simple, par contre, la story ne sera ex\u00e9cut\u00e9e que si la story courante du contexte est \"d\u00e9j\u00e0\" la story search. Plusieurs story diff\u00e9rentes peuvent donc partager les m\u00eames intentions secondaires. Manipuler les entit\u00e9s \u00b6 Pour r\u00e9cup\u00e9rer les valeurs des entit\u00e9s, une bonne pratique est de d\u00e9finir des extensions . Par exemple voici le code utilis\u00e9 pour r\u00e9cup\u00e9rer l'entit\u00e9 destination : val destinationEntity = openBot . entity ( \"location\" , \"destination\" ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) Une entit\u00e9 de type location et de role destination est cr\u00e9\u00e9e. Il s'agit de l'entit\u00e9 correspondante dans le mod\u00e8le NLP. Une variable destination est d\u00e9finie, qui va simplifier la manipulation de cette entit\u00e9 dans le code m\u00e9tier. Cette variable contient la valeur actuelle de la destination dans le contexte utilisateur. Voici une version compl\u00e9t\u00e9e de la story search qui utilise destination : val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null -> end ( \"Pour quelle destination?\" ) origin == null -> end ( \"Pour quelle origine?\" ) departureDate == null -> end ( \"Quand souhaitez-vous partir?\" ) } } Si il n'y a pas de valeur dans le contexte courant pour la destination, le bot demande de sp\u00e9cifier la destination et en reste l\u00e0. Idem pour l'origine ou la date de d\u00e9part. Si les 3 valeurs obligatoires sont sp\u00e9cifi\u00e9es, il passe \u00e0 la r\u00e9ponse proprement dite d\u00e9velopp\u00e9e dans la classe ( SearchDef ). La version compl\u00e8te de cette premi\u00e8re partie du code est la suivante : val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) && location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null -> end ( \"Pour quelle destination?\" ) origin == null -> end ( \"Pour quelle origine?\" ) departureDate == null -> end ( \"Quand souhaitez-vous partir?\" ) } } Dans le cas o\u00f9 l'intention d\u00e9tect\u00e9e est indicate_location , nous ne savons pas si la localit\u00e9 indiqu\u00e9e repr\u00e9sente l'origine ou la destination. Il est donc cod\u00e9 une r\u00e8gle simple : Si il existe d\u00e9j\u00e0 dans le contexte une origine et pas de destination, la nouvelle localit\u00e9 est en fait la destination. Sinon, il s'agit de l'origine. Utiliser HandlerDef \u00b6 Dans la d\u00e9finition de la story search ci-dessus, vous avez pu noter le typage g\u00e9n\u00e9rique SearchDef . Voici le code de cette classe : @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef < SearchConnector >( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( \"De {0} \u00e0 {1}\" , o , d ) send ( \"D\u00e9part le {0}\" , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( \"D\u00e9sol\u00e9, aucun itin\u00e9raire trouv\u00e9 :(\" ) } else { send ( \"Voici la premi\u00e8re proposition :\" ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef \u00e9tend HandlerDef qui est un alias d'une classe du framework Tock. C'est en g\u00e9n\u00e9ral ici que l'on va d\u00e9finir le code m\u00e9tier des parcours complexes. Le code est relativement parlant, mais il contient une abstraction suppl\u00e9mentaire : SearchConnector . SearchConnector est la classe qui d\u00e9finit le comportement sp\u00e9cifique \u00e0 chaque connecteur, et les annotations @GAHandler(GASearchConnector::class) et @MessengerHandler(MessengerSearchConnector::class) indiquent les impl\u00e9mentations correspondantes pour les diff\u00e9rents connecteurs support\u00e9s (respectivement Google Assistant et Messenger). Que se passerait-il s'il n'y avait pas de connecteur pour Google Assistant par exemple ? La m\u00e9thode connector?.sendFirstJourney(journeys.first()) n'enverrait pas la r\u00e9ponse finale, puisque connector serait null . Utiliser ConnectorDef \u00b6 Voici maintenant une version simplifi\u00e9e de SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef < SearchDef >( context ) { fun Section . title (): CharSequence = i18n ( \"{0} - {1}\" , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List < Section >): ConnectorMessage } Et voici son impl\u00e9mentation pour Messenger : class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List < Section >): ConnectorMessage = flexibleListTemplate ( sections . map { section -> with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } Le code sp\u00e9cifique \u00e0 chaque connecteur est ainsi correctement d\u00e9coupl\u00e9. Le code commun \u00e0 chaque connecteur est pr\u00e9sent dans SearchConnector et le comportement sp\u00e9cifique \u00e0 chaque connecteur se trouve dans les classes d\u00e9di\u00e9es. Utiliser StoryStep \u00b6 Parfois il est n\u00e9cessaire de se souvenir de l'\u00e9tape \u00e0 laquelle l'utilisateur se trouve dans la story courante. Pour cela Tock met \u00e0 disposition la notion de StoryStep . Il existe deux types de StoryStep : SimpleStoryStep \u00b6 A utiliser dans les cas simples, pour lequels on va g\u00e9rer le comportement induit directement : enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps < MyStep >( \"intent\" ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } Pour modifier l'\u00e9tape courante, deux m\u00e9thodes sont disponibles : Modifier manuellement l'\u00e9tape val story = storyWithSteps < MyStep >( \"intent\" ) { //(...) step = MyStep . a // l'\u00e9tape sera persist\u00e9e tant que nous resterons dans cette story } Utiliser les boutons ou autres quick replies Plus de d\u00e9tails sur ce sujet plus bas . Les StoryStep avec comportement \u00b6 Dans des cas plus complexes, on souhaite pouvoir d\u00e9finir un comportement pour chaque \u00e9tape. L'utilisation de HandlerDef est alors un pr\u00e9requis. enum class MySteps : StoryStep < MyHandlerDef > { //pas de comportement sp\u00e9cifique display , select { // la step \"select\" sera automatiquement s\u00e9lectionn\u00e9e si la sous-intention select est d\u00e9tect\u00e9e override val intent : IntentAware ? = SecondaryIntent . select //dans ce cas la r\u00e9ponse suivante sera apport\u00e9e override fun answer (): MyHandlerDef .() -> Any ? = { end ( \"I don't know yet how to select something\" ) } }, disruption { //seule la r\u00e9ponse est configur\u00e9e override fun answer (): ScoreboardDef .() -> Any ? = { end ( \"some perturbation\" ) } }; } Davantage d'options de configuration sont disponibles. Consultez la description de StoryStep . Postback buttons & quick replies \u00b6 Messenger met \u00e0 disposition ce type de bouton, et la plupart des connecteurs avec interface graphique font de m\u00eame. Tock permet de d\u00e9finir l'action effectu\u00e9e suite \u00e0 un clic sur ces boutons. Dans l'exemple suivant, le bouton redirigera vers l'intention search . buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , search ) ) Il est possible de d\u00e9finir \u00e9galement une StoryStep et des param\u00e8tres d\u00e9di\u00e9s : //pour d\u00e9finir des param\u00e8tres, la pratique recommand\u00e9e est d'\u00e9tendre l'interface ParameterKey enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , intent = search , //si aucune step n'est indiqu\u00e9e, c'est la step courante qui est utilis\u00e9e step = MyStep . a , parameters = //ce param\u00e8tre est stock\u00e9 sous forme de cha\u00eene de caract\u00e8re (les crochets sont utilis\u00e9s) nextResultDate [ nextDate ] + //ce param\u00e8tre est stock\u00e9 en json (les parenth\u00e8ses sont utilis\u00e9es) nextResultOrigin ( origin ) ) ) Pour r\u00e9cup\u00e9rer les param\u00e8tres du bouton sur lequel on a cliqu\u00e9 : val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin ) Tests Unitaires \u00b6 La page Tests Unitaires pr\u00e9sente le framework fourni pour r\u00e9aliser des TUs avec Tock.","title":"Tock Integrated Bot"},{"location":"dev/integrated-bot/#developper-en-mode-tock-bot-integre","text":"Le mode Bot int\u00e9gr\u00e9 Tock permet de d\u00e9velopper un bot en utilisant un Domain Specifique Language (DSL) en Kotlin . Contrairement au mode Bot API encore en d\u00e9veloppement, le Bot Framework Kotlin permet d'exploiter toutes les possibilit\u00e9s de la plateforme Tock, notamment : Gestion des contextes utilisateurs Historique de conversation Notions avanc\u00e9es comme la fusion d'entit\u00e9s Etc. Exemple de fusion d'entit\u00e9s : lorsque un utilisateur demande \"demain\" dans une phrase (appelons cette entit\u00e9 date ) puis \"plut\u00f4t le soir\" dans une phrase suivante, la fusion permet de mettre \u00e0 jour automatiquement l'entit\u00e9 ( date ) avec les deux informations compl\u00e9mentaires : jour et cr\u00e9neau horaire dans cet exemple. Attention : dans ce mode de d\u00e9veloppement, contrairement au mode Bot API , il est n\u00e9cessaire que le module bot dispose d'une connexion \u00e0 la base de donn\u00e9e (MongoDB) de la plateforme Tock utilis\u00e9e. Pour appr\u00e9hender compl\u00e8tement ce qui va suivre, il est recommand\u00e9 de ma\u00eetriser les bases du langage de programmation Kotlin .","title":"D\u00e9velopper en mode Tock Bot int\u00e9gr\u00e9"},{"location":"dev/integrated-bot/#demarrer-avec-le-framework","text":"","title":"D\u00e9marrer avec le framework"},{"location":"dev/integrated-bot/#documentation-kdoc","text":"La documentation du framework au format KDoc est disponible ici .","title":"Documentation KDoc"},{"location":"dev/integrated-bot/#dependance-bot-toolkit","text":"Pour utiliser le framework conversationnel, il faut ajouter la d\u00e9pendance bot-tookit \u00e0 l'application / au projet Kotlin. Par exemple dans un projet Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> bot-toolkit </artifactId> <version> 19.3.3 </version> </dependency> Ou dans un projet Gradle : compile 'ai.tock:bot-toolkit:19.3.3'","title":"D\u00e9pendance bot-toolkit"},{"location":"dev/integrated-bot/#un-bot-est-un-ensemble-de-parcours-stories","text":"Voici par exemple comment le Bot Open Data est d\u00e9fini : val openBot = bot ( \"bot_open_data\" , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) Ce bot comporte un identifiant (obligatoire - \"bot_open_data\") et une liste de parcours ou stories . Une Story est un regroupement fonctionnel qui correspond \u00e0 une intention principale et, de mani\u00e8re optionelle, \u00e0 une ou plusieurs intentions dites \"secondaires\" (voir Concepts ). Ici le bot d\u00e9finit 4 parcours : greetings , departures , arrivals et search . Le parcours greetings est d\u00e9clar\u00e9 comme parcours principal, il sera pr\u00e9sent\u00e9 par d\u00e9faut au d\u00e9but d'une conversation : hello = greetings .","title":"Un bot est un ensemble de parcours (stories)"},{"location":"dev/integrated-bot/#une-story-simple","text":"Comment d\u00e9finit-on une Story? Voici une premi\u00e8re version simplifi\u00e9e du parcours greetings : val greetings = story ( \"greetings\" ) { send ( \"Bienvenue chez le Bot Open Data Sncf! :)\" ) end ( \"Il s'agit d'un bot de d\u00e9monstration du framework Tock : https://github.com/theopenconversationkit/tock\" ) } Notez que dans le corps de la fonction, this est de type BotBus , \u00e0 partir duquel vous pouvez interagir avec l'utilisateur, et qui permet \u00e9galement d'acc\u00e8der \u00e0 tous les \u00e9lements contextuels disponibles. Concr\u00e8tement sela signifie que quand l'intention greetings sera d\u00e9tect\u00e9e par le mod\u00e8le NLP, la fonction ci-dessus sera appel\u00e9e par le framework Tock. Le bot envoie donc successivement une premi\u00e8re phrase de r\u00e9ponse ( bus.send() ), puis un deuxi\u00e8me en indiquant que c'est la derni\u00e8re phrase de sa r\u00e9ponse \u00e0 l'aide d'un bus.end() . Voici maintenant la version compl\u00e8te de greetings : val greetings = story ( \"greetings\" ) { //cleanup state resetDialogState () send ( \"Bienvenue chez le Bot Open Data Sncf! :)\" ) send ( \"Il s'agit d'un bot de d\u00e9monstration du framework Tock : https://github.com/theopenconversationkit/tock\" ) withMessenger { buttonsTemplate ( \"Il est volontairement tr\u00e8s limit\u00e9, mais demandez lui un itin\u00e9raire ou les d\u00e9parts \u00e0 partir d'une gare et constatez le r\u00e9sultat! :) \" , postbackButton ( \"Itin\u00e9raires\" , search ), postbackButton ( \"D\u00e9parts\" , Departures ), postbackButton ( \"Arriv\u00e9es\" , Arrivals ) ) } withGoogleAssistant { gaMessage ( \"Il est volontairement tr\u00e8s limit\u00e9, mais demandez lui un itin\u00e9raire ou les d\u00e9parts \u00e0 partir d'une gare et constatez le r\u00e9sultat! :) \" , \"Itin\u00e9raires\" , \"D\u00e9parts\" , \"Arriv\u00e9es\" ) } end () } Deux notions ont \u00e9t\u00e9 ajout\u00e9es : resetDialogState() qui permet de repartir d'un contexte utilisateur vide (en oubliant les \u00e9ventuels \u00e9changes pr\u00e9c\u00e9dents) les m\u00e9thodes withMessenger{} et withGoogleAssistant{} qui permettent de d\u00e9finir des r\u00e9ponses sp\u00e9cifiques pour chaque connecteur. Ici un texte avec des boutons pour Messenger, et un texte avec des suggestions pour Google Assistant.","title":"Une Story simple"},{"location":"dev/integrated-bot/#demarrer-et-connecter-le-bot","text":"Pour d\u00e9marrer le bot, il suffit de rajouter dans votre main principal l'appel suivant : registerAndInstallBot ( openBot ) La variable openBot dans l'exemple est le bot que vous avez d\u00e9fini plus haut. Une fois le bot d\u00e9marr\u00e9, il est \u00e9galement n\u00e9cessaire de sp\u00e9cifier quels connecteurs sont utilis\u00e9s dans l'interface d'administration du bot, du menu Configuration > Bot Configurations > Create a new configuration . Pour en savoir plus sur les diff\u00e9rents canaux et connecteurs, voir cette page .","title":"D\u00e9marrer et connecter le bot"},{"location":"dev/integrated-bot/#aller-plus-loin","text":"Bien s\u00fbr, le StoryHandler de greetings ne d\u00e9pend pas du contexte : la r\u00e9ponse est toujours la m\u00eame. Pour le d\u00e9veloppement de stories complexes, nous avons besoin d'une abstraction suppl\u00e9mentaire.","title":"Aller plus loin"},{"location":"dev/integrated-bot/#intentions-secondaires","text":"Voici le d\u00e9but de la d\u00e9finition de la story search : val search = storyDef < SearchDef >( \"search\" , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } Le parcours search d\u00e9finit une intention secondaire \"de d\u00e9marrage\" ( indicate_origin ) et une intention secondaire simple ( indicate_location ). Une intention secondaire \"de d\u00e9marrage\" est semblable en tout point \u00e0 une intention principale : d\u00e8s que cette intention est d\u00e9tect\u00e9e, le parcours search va \u00eatre ex\u00e9cut\u00e9, si la story courante ne poss\u00e8de pas cette intention en tant qu'intention secondaire. Pour une intention secondaire simple, par contre, la story ne sera ex\u00e9cut\u00e9e que si la story courante du contexte est \"d\u00e9j\u00e0\" la story search. Plusieurs story diff\u00e9rentes peuvent donc partager les m\u00eames intentions secondaires.","title":"Intentions secondaires"},{"location":"dev/integrated-bot/#manipuler-les-entites","text":"Pour r\u00e9cup\u00e9rer les valeurs des entit\u00e9s, une bonne pratique est de d\u00e9finir des extensions . Par exemple voici le code utilis\u00e9 pour r\u00e9cup\u00e9rer l'entit\u00e9 destination : val destinationEntity = openBot . entity ( \"location\" , \"destination\" ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) Une entit\u00e9 de type location et de role destination est cr\u00e9\u00e9e. Il s'agit de l'entit\u00e9 correspondante dans le mod\u00e8le NLP. Une variable destination est d\u00e9finie, qui va simplifier la manipulation de cette entit\u00e9 dans le code m\u00e9tier. Cette variable contient la valeur actuelle de la destination dans le contexte utilisateur. Voici une version compl\u00e9t\u00e9e de la story search qui utilise destination : val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null -> end ( \"Pour quelle destination?\" ) origin == null -> end ( \"Pour quelle origine?\" ) departureDate == null -> end ( \"Quand souhaitez-vous partir?\" ) } } Si il n'y a pas de valeur dans le contexte courant pour la destination, le bot demande de sp\u00e9cifier la destination et en reste l\u00e0. Idem pour l'origine ou la date de d\u00e9part. Si les 3 valeurs obligatoires sont sp\u00e9cifi\u00e9es, il passe \u00e0 la r\u00e9ponse proprement dite d\u00e9velopp\u00e9e dans la classe ( SearchDef ). La version compl\u00e8te de cette premi\u00e8re partie du code est la suivante : val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) && location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null -> end ( \"Pour quelle destination?\" ) origin == null -> end ( \"Pour quelle origine?\" ) departureDate == null -> end ( \"Quand souhaitez-vous partir?\" ) } } Dans le cas o\u00f9 l'intention d\u00e9tect\u00e9e est indicate_location , nous ne savons pas si la localit\u00e9 indiqu\u00e9e repr\u00e9sente l'origine ou la destination. Il est donc cod\u00e9 une r\u00e8gle simple : Si il existe d\u00e9j\u00e0 dans le contexte une origine et pas de destination, la nouvelle localit\u00e9 est en fait la destination. Sinon, il s'agit de l'origine.","title":"Manipuler les entit\u00e9s"},{"location":"dev/integrated-bot/#utiliser-handlerdef","text":"Dans la d\u00e9finition de la story search ci-dessus, vous avez pu noter le typage g\u00e9n\u00e9rique SearchDef . Voici le code de cette classe : @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef < SearchConnector >( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( \"De {0} \u00e0 {1}\" , o , d ) send ( \"D\u00e9part le {0}\" , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( \"D\u00e9sol\u00e9, aucun itin\u00e9raire trouv\u00e9 :(\" ) } else { send ( \"Voici la premi\u00e8re proposition :\" ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef \u00e9tend HandlerDef qui est un alias d'une classe du framework Tock. C'est en g\u00e9n\u00e9ral ici que l'on va d\u00e9finir le code m\u00e9tier des parcours complexes. Le code est relativement parlant, mais il contient une abstraction suppl\u00e9mentaire : SearchConnector . SearchConnector est la classe qui d\u00e9finit le comportement sp\u00e9cifique \u00e0 chaque connecteur, et les annotations @GAHandler(GASearchConnector::class) et @MessengerHandler(MessengerSearchConnector::class) indiquent les impl\u00e9mentations correspondantes pour les diff\u00e9rents connecteurs support\u00e9s (respectivement Google Assistant et Messenger). Que se passerait-il s'il n'y avait pas de connecteur pour Google Assistant par exemple ? La m\u00e9thode connector?.sendFirstJourney(journeys.first()) n'enverrait pas la r\u00e9ponse finale, puisque connector serait null .","title":"Utiliser HandlerDef"},{"location":"dev/integrated-bot/#utiliser-connectordef","text":"Voici maintenant une version simplifi\u00e9e de SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef < SearchDef >( context ) { fun Section . title (): CharSequence = i18n ( \"{0} - {1}\" , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List < Section >): ConnectorMessage } Et voici son impl\u00e9mentation pour Messenger : class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List < Section >): ConnectorMessage = flexibleListTemplate ( sections . map { section -> with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } Le code sp\u00e9cifique \u00e0 chaque connecteur est ainsi correctement d\u00e9coupl\u00e9. Le code commun \u00e0 chaque connecteur est pr\u00e9sent dans SearchConnector et le comportement sp\u00e9cifique \u00e0 chaque connecteur se trouve dans les classes d\u00e9di\u00e9es.","title":"Utiliser ConnectorDef"},{"location":"dev/integrated-bot/#utiliser-storystep","text":"Parfois il est n\u00e9cessaire de se souvenir de l'\u00e9tape \u00e0 laquelle l'utilisateur se trouve dans la story courante. Pour cela Tock met \u00e0 disposition la notion de StoryStep . Il existe deux types de StoryStep :","title":"Utiliser StoryStep"},{"location":"dev/integrated-bot/#simplestorystep","text":"A utiliser dans les cas simples, pour lequels on va g\u00e9rer le comportement induit directement : enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps < MyStep >( \"intent\" ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } Pour modifier l'\u00e9tape courante, deux m\u00e9thodes sont disponibles : Modifier manuellement l'\u00e9tape val story = storyWithSteps < MyStep >( \"intent\" ) { //(...) step = MyStep . a // l'\u00e9tape sera persist\u00e9e tant que nous resterons dans cette story } Utiliser les boutons ou autres quick replies Plus de d\u00e9tails sur ce sujet plus bas .","title":"SimpleStoryStep"},{"location":"dev/integrated-bot/#les-storystep-avec-comportement","text":"Dans des cas plus complexes, on souhaite pouvoir d\u00e9finir un comportement pour chaque \u00e9tape. L'utilisation de HandlerDef est alors un pr\u00e9requis. enum class MySteps : StoryStep < MyHandlerDef > { //pas de comportement sp\u00e9cifique display , select { // la step \"select\" sera automatiquement s\u00e9lectionn\u00e9e si la sous-intention select est d\u00e9tect\u00e9e override val intent : IntentAware ? = SecondaryIntent . select //dans ce cas la r\u00e9ponse suivante sera apport\u00e9e override fun answer (): MyHandlerDef .() -> Any ? = { end ( \"I don't know yet how to select something\" ) } }, disruption { //seule la r\u00e9ponse est configur\u00e9e override fun answer (): ScoreboardDef .() -> Any ? = { end ( \"some perturbation\" ) } }; } Davantage d'options de configuration sont disponibles. Consultez la description de StoryStep .","title":"Les StoryStep avec comportement"},{"location":"dev/integrated-bot/#postback-buttons-quick-replies","text":"Messenger met \u00e0 disposition ce type de bouton, et la plupart des connecteurs avec interface graphique font de m\u00eame. Tock permet de d\u00e9finir l'action effectu\u00e9e suite \u00e0 un clic sur ces boutons. Dans l'exemple suivant, le bouton redirigera vers l'intention search . buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , search ) ) Il est possible de d\u00e9finir \u00e9galement une StoryStep et des param\u00e8tres d\u00e9di\u00e9s : //pour d\u00e9finir des param\u00e8tres, la pratique recommand\u00e9e est d'\u00e9tendre l'interface ParameterKey enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , intent = search , //si aucune step n'est indiqu\u00e9e, c'est la step courante qui est utilis\u00e9e step = MyStep . a , parameters = //ce param\u00e8tre est stock\u00e9 sous forme de cha\u00eene de caract\u00e8re (les crochets sont utilis\u00e9s) nextResultDate [ nextDate ] + //ce param\u00e8tre est stock\u00e9 en json (les parenth\u00e8ses sont utilis\u00e9es) nextResultOrigin ( origin ) ) ) Pour r\u00e9cup\u00e9rer les param\u00e8tres du bouton sur lequel on a cliqu\u00e9 : val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin )","title":"Postback buttons &amp; quick replies"},{"location":"dev/integrated-bot/#tests-unitaires","text":"La page Tests Unitaires pr\u00e9sente le framework fourni pour r\u00e9aliser des TUs avec Tock.","title":"Tests Unitaires"},{"location":"dev/modes/","text":"D\u00e9velopper des bots avec Tock \u00b6 Pour aller plus loin que les possibilit\u00e9s de Tock Studio pour construire bots & assistants conversationnels, on peut programmer des parcours, en Kotlin ou dans d'autres langages. Deux modes / frameworks / architectures sont propos\u00e9s : Le mode Bot API \u00b6 Le mode Tock Bot API (recommand\u00e9 pour la plupart des cas) permet de d\u00e9velopper en Kotlin ou un autre langage \u00e0 travers l'API conversationnelle de Tock : Ce mode est le seul disponible sur la plateforme de d\u00e9monstration Tock . C'est aussi le seul mode permettant de d\u00e9velopper dans n'importe quel langage de programmation, via l'API. Pour en savoir plus, voir la page Bot API . Le mode Bot int\u00e9gr\u00e9 \u00b6 Dans ce mode, vous pouvez acc\u00e9der \u00e0 toutes les fonctionnalit\u00e9s et possibilit\u00e9s du framework Tock pour d\u00e9velopper un bot. C'est le mode de d\u00e9veloppement historique de Tock, et actuellement la plupart des bots publi\u00e9s par les concepteurs de Tock. sont d\u00e9velopp\u00e9s de cette mani\u00e8re. La mise en place de la solution est plus complexe que le mode Bot API et n\u00e9cessite notamment que le composant bot acc\u00e8de directement \u00e0 la base de donn\u00e9es MongoDB. Il est donc n\u00e9cessaire pour utiliser ce mode : D'installer une plateforme (g\u00e9n\u00e9ralement avec Docker ) sur son poste ou sur un serveur De partager la connexion \u00e0 la base MongoDB entre les poste de d\u00e9veloppement et les autres composants de la plateforme Tock utilis\u00e9e De ma\u00eetriser le langage de programmation Kotlin Pour en savoir plus, voir la page Bot int\u00e9gr\u00e9 .","title":"Availables modes"},{"location":"dev/modes/#developper-des-bots-avec-tock","text":"Pour aller plus loin que les possibilit\u00e9s de Tock Studio pour construire bots & assistants conversationnels, on peut programmer des parcours, en Kotlin ou dans d'autres langages. Deux modes / frameworks / architectures sont propos\u00e9s :","title":"D\u00e9velopper des bots avec Tock"},{"location":"dev/modes/#le-mode-bot-api","text":"Le mode Tock Bot API (recommand\u00e9 pour la plupart des cas) permet de d\u00e9velopper en Kotlin ou un autre langage \u00e0 travers l'API conversationnelle de Tock : Ce mode est le seul disponible sur la plateforme de d\u00e9monstration Tock . C'est aussi le seul mode permettant de d\u00e9velopper dans n'importe quel langage de programmation, via l'API. Pour en savoir plus, voir la page Bot API .","title":"Le mode Bot API"},{"location":"dev/modes/#le-mode-bot-integre","text":"Dans ce mode, vous pouvez acc\u00e9der \u00e0 toutes les fonctionnalit\u00e9s et possibilit\u00e9s du framework Tock pour d\u00e9velopper un bot. C'est le mode de d\u00e9veloppement historique de Tock, et actuellement la plupart des bots publi\u00e9s par les concepteurs de Tock. sont d\u00e9velopp\u00e9s de cette mani\u00e8re. La mise en place de la solution est plus complexe que le mode Bot API et n\u00e9cessite notamment que le composant bot acc\u00e8de directement \u00e0 la base de donn\u00e9es MongoDB. Il est donc n\u00e9cessaire pour utiliser ce mode : D'installer une plateforme (g\u00e9n\u00e9ralement avec Docker ) sur son poste ou sur un serveur De partager la connexion \u00e0 la base MongoDB entre les poste de d\u00e9veloppement et les autres composants de la plateforme Tock utilis\u00e9e De ma\u00eetriser le langage de programmation Kotlin Pour en savoir plus, voir la page Bot int\u00e9gr\u00e9 .","title":"Le mode Bot int\u00e9gr\u00e9"},{"location":"dev/test/","text":"Utiliser le framework de test \u00b6 Tock met \u00e0 disposition des extensions pour tester le bot unitairement. Pour les utiliser, il est n\u00e9cessaire d'ajouter la librairie bot-test \u00e0 votre projet. Avec Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> bot-test </artifactId> <version> 19.3.3 </version> <scope> test </scope> </dependency> ou Gradle : testCompile 'ai.tock:bot-test:19.3.3' L'ensemble de ce framework est document\u00e9 au format KDoc ici . Ecrire un test simple \u00b6 L'ensemble des exemples suivants utilisent JUnit5 . Une extension d\u00e9di\u00e9e \u00e0 Tock et JUnit5 est disponible . @RegisterExtension @JvmField val ext = TockJUnit5Extension () Afin de tester la story greetings du bot Open Data, il suffit d'utiliser la m\u00e9thode ext.send() qui permet d'obtenir un mock du bus conversationnel. Le test unitaire s'\u00e9crit alors ainsi : @Test fun `greetings story displays welcome message WHEN locale is fr` () { ext . send ( locale = Locale . FRENCH ) { firstAnswer . assertText ( \"Bienvenue chez le Bot Open Data Sncf! :)\" ) secondAnswer . assertText ( \"Il s'agit d'un bot de d\u00e9monstration du framework Tock : https://github.com/theopenconversationkit/tock\" ) } } Comme le connector par d\u00e9faut est celui de Messenger, il est possible de tester de la m\u00eame mani\u00e8re le message sp\u00e9cifique \u00e0 Messenger : lastAnswer . assertMessage ( buttonsTemplate ( \"Il est volontairement tr\u00e8s limit\u00e9, mais demandez lui un itin\u00e9raire ou les d\u00e9parts \u00e0 partir d'une gare et constatez le r\u00e9sultat! :)\" , postbackButton ( \"Itin\u00e9raires\" , search ), postbackButton ( \"D\u00e9parts\" , Departures ), postbackButton ( \"Arriv\u00e9es\" , Arrivals ) ) ) Pour tester le message sp\u00e9cifique \u00e0 Google Assistant (ou tout autre connecteur), il est n\u00e9cessaire de sp\u00e9cifier le connecteur que l'on souhaite tester : ext . send ( connectorType = gaConnectorType , locale = Locale . FRENCH ) { firstAnswer . assertText ( \"Bienvenue chez le Bot Open Data Sncf! :)\" ) secondAnswer . assertText ( \"Il s'agit d'un bot de d\u00e9monstration du framework Tock : https://github.com/theopenconversationkit/tock\" ) lastAnswer . assertMessage ( gaMessage ( \"Il est volontairement tr\u00e8s limit\u00e9, mais demandez lui un itin\u00e9raire ou les d\u00e9parts \u00e0 partir d'une gare et constatez le r\u00e9sultat! :)\" , \"Itin\u00e9raires\" , \"D\u00e9parts\" , \"Arriv\u00e9es\" ) ) } Tester une Story sp\u00e9cifique \u00b6 Dans les exemples pr\u00e9c\u00e9dents, il n'\u00e9tait pas n\u00e9cessaire d'indiquer la story \u00e0 tester ( greetings \u00e9tant la story par d\u00e9faut). Supposons que nous souhaitons la story search , nous devons pr\u00e9ciser la story \u00e0 tester de la mani\u00e8re suivante : @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search , locale = Locale . FRENCH ) { firstAnswer . assertText ( \"Pour quelle destination?\" ) } } Tester un dialogue \u00b6 Il est possible de simuler un dialogue complet. Par exemple, on simule ici que l'utilisateur indique la destination, puis l'origine : @Test fun `search story asks for origin WHEN there is a destination but no origin in context` () { ext . send ( \"Je voudrais rechercher un itin\u00e9raire\" , search , locale = Locale . FRENCH ) { firstAnswer . assertText ( \"Pour quelle destination?\" ) } ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( \"Pour quelle origine?\" ) } ext . send ( \"Paris\" , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( \"Quand souhaitez-vous partir?\" ) } } Le texte en premier param\u00e8tre de la m\u00e9thode send est simplement indicatif, pour aider \u00e0 la compr\u00e9hension des tests. Les param\u00e8tres suivants permettent de d\u00e9finir comment le NLP va analyser la phrase. Par exemple : private val lille = PlaceValue ( SncfPlace ( \"stop_area\" , 90 , \"Lille Europe\" , \"Lille Europe (Lille)\" , \"stop_area:OCE:SA:87223263\" , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) permet d'indiquer que la phrase \"Lille\" est cat\u00e9goris\u00e9e comme une intention indicate_location et avec une valeur pour l'entit\u00e9 location qui va \u00eatre la localisation lille Enfin il est possible de modifier toutes les valeurs du bus mock\u00e9 \u00e0 l'initialisation. Dans l'exemple suivant, on simule l'intention secondaire indicate_location afin d'indiquer l'origine : @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Recherche\" , search , locale = Locale . FRENCH ) { destination = lille origin = paris run () firstAnswer . assertText ( \"Quand souhaitez-vous partir?\" ) } } Les variables origin et destination sont mises \u00e0 jour, puis un appel au bus est simul\u00e9 avec la fonction run() .","title":"Utiliser le framework de test"},{"location":"dev/test/#utiliser-le-framework-de-test","text":"Tock met \u00e0 disposition des extensions pour tester le bot unitairement. Pour les utiliser, il est n\u00e9cessaire d'ajouter la librairie bot-test \u00e0 votre projet. Avec Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> bot-test </artifactId> <version> 19.3.3 </version> <scope> test </scope> </dependency> ou Gradle : testCompile 'ai.tock:bot-test:19.3.3' L'ensemble de ce framework est document\u00e9 au format KDoc ici .","title":"Utiliser le framework de test"},{"location":"dev/test/#ecrire-un-test-simple","text":"L'ensemble des exemples suivants utilisent JUnit5 . Une extension d\u00e9di\u00e9e \u00e0 Tock et JUnit5 est disponible . @RegisterExtension @JvmField val ext = TockJUnit5Extension () Afin de tester la story greetings du bot Open Data, il suffit d'utiliser la m\u00e9thode ext.send() qui permet d'obtenir un mock du bus conversationnel. Le test unitaire s'\u00e9crit alors ainsi : @Test fun `greetings story displays welcome message WHEN locale is fr` () { ext . send ( locale = Locale . FRENCH ) { firstAnswer . assertText ( \"Bienvenue chez le Bot Open Data Sncf! :)\" ) secondAnswer . assertText ( \"Il s'agit d'un bot de d\u00e9monstration du framework Tock : https://github.com/theopenconversationkit/tock\" ) } } Comme le connector par d\u00e9faut est celui de Messenger, il est possible de tester de la m\u00eame mani\u00e8re le message sp\u00e9cifique \u00e0 Messenger : lastAnswer . assertMessage ( buttonsTemplate ( \"Il est volontairement tr\u00e8s limit\u00e9, mais demandez lui un itin\u00e9raire ou les d\u00e9parts \u00e0 partir d'une gare et constatez le r\u00e9sultat! :)\" , postbackButton ( \"Itin\u00e9raires\" , search ), postbackButton ( \"D\u00e9parts\" , Departures ), postbackButton ( \"Arriv\u00e9es\" , Arrivals ) ) ) Pour tester le message sp\u00e9cifique \u00e0 Google Assistant (ou tout autre connecteur), il est n\u00e9cessaire de sp\u00e9cifier le connecteur que l'on souhaite tester : ext . send ( connectorType = gaConnectorType , locale = Locale . FRENCH ) { firstAnswer . assertText ( \"Bienvenue chez le Bot Open Data Sncf! :)\" ) secondAnswer . assertText ( \"Il s'agit d'un bot de d\u00e9monstration du framework Tock : https://github.com/theopenconversationkit/tock\" ) lastAnswer . assertMessage ( gaMessage ( \"Il est volontairement tr\u00e8s limit\u00e9, mais demandez lui un itin\u00e9raire ou les d\u00e9parts \u00e0 partir d'une gare et constatez le r\u00e9sultat! :)\" , \"Itin\u00e9raires\" , \"D\u00e9parts\" , \"Arriv\u00e9es\" ) ) }","title":"Ecrire un test simple"},{"location":"dev/test/#tester-une-story-specifique","text":"Dans les exemples pr\u00e9c\u00e9dents, il n'\u00e9tait pas n\u00e9cessaire d'indiquer la story \u00e0 tester ( greetings \u00e9tant la story par d\u00e9faut). Supposons que nous souhaitons la story search , nous devons pr\u00e9ciser la story \u00e0 tester de la mani\u00e8re suivante : @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search , locale = Locale . FRENCH ) { firstAnswer . assertText ( \"Pour quelle destination?\" ) } }","title":"Tester une Story sp\u00e9cifique"},{"location":"dev/test/#tester-un-dialogue","text":"Il est possible de simuler un dialogue complet. Par exemple, on simule ici que l'utilisateur indique la destination, puis l'origine : @Test fun `search story asks for origin WHEN there is a destination but no origin in context` () { ext . send ( \"Je voudrais rechercher un itin\u00e9raire\" , search , locale = Locale . FRENCH ) { firstAnswer . assertText ( \"Pour quelle destination?\" ) } ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( \"Pour quelle origine?\" ) } ext . send ( \"Paris\" , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( \"Quand souhaitez-vous partir?\" ) } } Le texte en premier param\u00e8tre de la m\u00e9thode send est simplement indicatif, pour aider \u00e0 la compr\u00e9hension des tests. Les param\u00e8tres suivants permettent de d\u00e9finir comment le NLP va analyser la phrase. Par exemple : private val lille = PlaceValue ( SncfPlace ( \"stop_area\" , 90 , \"Lille Europe\" , \"Lille Europe (Lille)\" , \"stop_area:OCE:SA:87223263\" , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) permet d'indiquer que la phrase \"Lille\" est cat\u00e9goris\u00e9e comme une intention indicate_location et avec une valeur pour l'entit\u00e9 location qui va \u00eatre la localisation lille Enfin il est possible de modifier toutes les valeurs du bus mock\u00e9 \u00e0 l'initialisation. Dans l'exemple suivant, on simule l'intention secondaire indicate_location afin d'indiquer l'origine : @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Recherche\" , search , locale = Locale . FRENCH ) { destination = lille origin = paris run () firstAnswer . assertText ( \"Quand souhaitez-vous partir?\" ) } } Les variables origin et destination sont mises \u00e0 jour, puis un appel au bus est simul\u00e9 avec la fonction run() .","title":"Tester un dialogue"},{"location":"guide/api/","text":"Programmer des parcours en Kotlin \u00b6 Les interfaces Tock Studio permettent de cr\u00e9er des bots et des parcours relativement simples, comme des arbres de d\u00e9cision et des r\u00e9ponses \u00e0 des questions courantes. Cela s'av\u00e8re suffisant pour de nombreux cas d'usages conversationnels. Toutefois, il est possible de construire des r\u00e9ponses et des parcours plus complexes : Se brancher \u00e0 un compte utilisateur Aggr\u00e9ger les informations de r\u00e9f\u00e9rentiels m\u00e9tier Appeler les services du SI (Syst\u00e8me d'Information) dans une organisation Int\u00e9grer des API externes pour enrichir ses parcours de services tiers Effectuer des actions et des transactions : cr\u00e9ation de tickets, paiements, etc. Impl\u00e9menter des r\u00e8gles de gestion et comportements sp\u00e9cifiques Optimiser les encha\u00eenements entre les intentions Pour construire des parcours complexes, Tock propose plusieurs modes d'int\u00e9gration destin\u00e9s \u00e0 diff\u00e9rents langages et frameworks de d\u00e9veloppement. Dans ce guide, vous utiliserez le langage Kotlin et le mode WebSocket pour ajouter une intention \u00e0 un bot initi\u00e9 dans Tock Studio . Si vous le souhaitez, vous pouvez sauter cette \u00e9tape et d\u00e9ployer un plateforme avec Docker ou passer directement au manuel utilisateur pour en savoir plus sur les possibilit\u00e9s de Tock Studio . Ce que vous allez cr\u00e9er \u00b6 Une intention Tock d\u00e9velopp\u00e9e avec le langage Kotlin Un programme se connectant au bot en WebSocket pour l'enrichir de parcours programm\u00e9s Pr\u00e9-requis \u00b6 Environ 10 minutes Un bot Tock fonctionnel (par exemple suite au guide premier bot Tock ) Un environnement de d\u00e9veloppement (ou IDE ) supportant Kotlin , par exemple IntelliJ avec des versions r\u00e9centes du JDK et de Maven Si vous ne souhaitez pas utiliser d' IDE , ou Maven, pas de probl\u00e8me. Il est tout \u00e0 fait possible de r\u00e9aliser le m\u00eame exercice avec d'autres outils. Il est \u00e9galement possible d'utiliser d'autres mani\u00e8res de d\u00e9velopper que le mode WebSocket et d'autres langages que Kotlin. Vous en apprendrez plus dans le manuel utilisateur Tock . Cr\u00e9er un programme Kotlin avec la d\u00e9pendance Tock \u00b6 Il existe de nombreuses mani\u00e8res de cr\u00e9er un projet en Kotlin. Ajoutez au classpath la biblioth\u00e8que tock-bot-api-websocket pour le mode WebSocket . Si vous utilisez Apache Maven , voici un exemple de POM ( pom.xml ) pour Kotlin avec la d\u00e9pendance tock-bot-api-websocket incluse : <?xml version=\"1.0\" encoding=\"UTF-8\"?> <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <groupId> test </groupId> <artifactId> tock-kotlin-websocket </artifactId> <version> 0.0.1-SNAPSHOT </version> <properties> <project.build.sourceEncoding> UTF-8 </project.build.sourceEncoding> <project.build.sourceDirectory> ${project.basedir}/src/main/kotlin </project.build.sourceDirectory> <project.build.testSourceDirectory> ${project.basedir}/src/test/kotlin </project.build.testSourceDirectory> <lib.tock.version> 19.3.3 </lib.tock.version> <plugin.kotlin.version> 1.3.41 </plugin.kotlin.version> <plugin.source.version> 3.1.0 </plugin.source.version> </properties> <dependencies> <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-websocket </artifactId> <version> ${lib.tock.version} </version> </dependency> </dependencies> <build> <sourceDirectory> ${project.build.sourceDirectory} </sourceDirectory> <testSourceDirectory> ${project.build.testSourceDirectory} </testSourceDirectory> <plugins> <plugin> <groupId> org.jetbrains.kotlin </groupId> <artifactId> kotlin-maven-plugin </artifactId> <version> ${plugin.kotlin.version} </version> <executions> <execution> <id> compile </id> <phase> compile </phase> <goals> <goal> compile </goal> </goals> </execution> <execution> <id> test-compile </id> <phase> test-compile </phase> <goals> <goal> test-compile </goal> </goals> </execution> </executions> </plugin> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-source-plugin </artifactId> <version> ${plugin.source.version} </version> <executions> <execution> <id> attach-sources </id> <phase> verify </phase> <goals> <goal> jar-no-fork </goal> </goals> </execution> </executions> </plugin> </plugins> </build> </project> Vous pouvez retrouver ce code (et d'autres exemples) dans le d\u00e9p\u00f4t tock-bot-samples . Cr\u00e9er une fonction qui se connecte \u00e0 Tock \u00b6 Cr\u00e9ez un fichier Kotlin (par exemple dans `src/main/kotlin/StartWebSocket.kt) Editez-le avec le code suivant : import fr.vsct.tock.bot.api.client.newBot import fr.vsct.tock.bot.api.client.newStory import fr.vsct.tock.bot.api.websocket.startWithDemo fun main () { startWithDemo ( // Integrate with the Tock demo platform by default newBot ( \"PUT-YOUR-TOCK-APP-API-KEY-HERE\" , // Get your app API key from Bot Configurations in Tock Studio newStory ( \"qui-es-tu\" ) { // Answer for the 'qui-es-tu' story send ( \"Je suis un assistant conversationnel construit avec Tock\" ) end ( \"Comment puis-je aider ?\" ) } ) ) } Vous pouvez retrouver ce code (et d'autres exemples) dans le d\u00e9p\u00f4t tock-bot-samples . Remplacez la clef d'API par celle de votre propre application Tock. Pour cela, dans Tock Studio , allez dans Configuration > Bot Configurations et reportez la valeur API Key dans le code. Ex\u00e9cutez la fonction ( main ) dans votre environnement de d\u00e9veloppement. Vous devriez voir appara\u00eetre une ligne de log ressemblant \u00e0 celle-ci : [ main ] INFO fr . vsct . tock . bot . api . websocket . BotApiWebSocketClient - start web socket client : { ... } V\u00e9rifiez \u00e9ventuellement que d'autres logs provenant de BotApiWebSocketClient n'indiquent pas d'erreur. Si c'est le cas, il peut s'agir d'une erreur de configuration de la clef d'API. Terminer la configuration dans Tock Studio \u00b6 Retournez dans Tock et allez dans Build > Search Stories D\u00e9cochez l'option Only Configured Stories . Vous voyez alors tous parcours, y compris \"qui-es-tu\" que vous venez de d\u00e9clarer programmatiquement Allez dans Test > Test the bot et saisissez une ou plusieurs phrases comme \"qui es-tu ?\" par exemple. Vous contastez que le bot ne r\u00e9pond pas encore \u00e0 cette question - il r\u00e9pond peut-\u00eatre m\u00eame \u00e0 une autre intention. Il reste en effet une configuration \u00e0 effectuer pour que la qualification fonctionne. A ce stade, le parcours existe bien dans Tock, mais l' intention n'a pas \u00e9t\u00e9 cr\u00e9\u00e9e automatiquement. Vous pouvez le v\u00e9rifier en regardant la liste des intentions disponibles dans NLU > Intents > build (la cat\u00e9gorie par d\u00e9faut). TODO : fix #533 Allez dans NLU > Inbox , pour la derni\u00e8re phrase que vous venez de saisir : Changez l'intention pour New intent Nommez-la \"qui-es-tu\" comme dans le code (pour que le lien se fasse) Cr\u00e9ez l'intention avec Create Puis terminez la qualification de la phrase avec Validate Si vous avez saisi d'autres phrases pour cette intention, pour chacune d'elles s\u00e9lectionnez l'intention dans la liste puis confirmez avec Validate Retournez dans Test > Test the bot . Si vous reposez la question, le bot vous donne d\u00e9sormais la r\u00e9ponse construite dans le code Kotlin (ie. \"Je suis un assistant...\"). F\u00e9licitations! \u00b6 Vous venez de configurer votre premi\u00e8re story programmatique en Kotlin. De cette mani\u00e8re, vous pouvez tirer pleinement parti des possibilit\u00e9s d'un langage de programmation pour construire toutes sortes de parcours simples et complexes, interroger des API tierces, impl\u00e9menter des r\u00e8gles de gestion, etc. Si vous programmez ainsi une story d\u00e9j\u00e0 d\u00e9finie dans Tock Studio , c'est la d\u00e9finition pr\u00e9sente dans Tock Studio qui est utilis\u00e9e pour construire les r\u00e9ponses \u00e0 l'ex\u00e9cution. Continuer... \u00b6 Dans la section suivante vous apprendez \u00e0 : D\u00e9ployer une plateforme Tock en quelques minutes avec Docker Pour en savoir plus sur l'utilisation de Tock Bot API en mode WebSocket , mais aussi les autres modes de d\u00e9ploiement, les types de messages support\u00e9s par Tock, etc. vous pouvez consulter le manuel utilisateur .","title":"Program stories"},{"location":"guide/api/#programmer-des-parcours-en-kotlin","text":"Les interfaces Tock Studio permettent de cr\u00e9er des bots et des parcours relativement simples, comme des arbres de d\u00e9cision et des r\u00e9ponses \u00e0 des questions courantes. Cela s'av\u00e8re suffisant pour de nombreux cas d'usages conversationnels. Toutefois, il est possible de construire des r\u00e9ponses et des parcours plus complexes : Se brancher \u00e0 un compte utilisateur Aggr\u00e9ger les informations de r\u00e9f\u00e9rentiels m\u00e9tier Appeler les services du SI (Syst\u00e8me d'Information) dans une organisation Int\u00e9grer des API externes pour enrichir ses parcours de services tiers Effectuer des actions et des transactions : cr\u00e9ation de tickets, paiements, etc. Impl\u00e9menter des r\u00e8gles de gestion et comportements sp\u00e9cifiques Optimiser les encha\u00eenements entre les intentions Pour construire des parcours complexes, Tock propose plusieurs modes d'int\u00e9gration destin\u00e9s \u00e0 diff\u00e9rents langages et frameworks de d\u00e9veloppement. Dans ce guide, vous utiliserez le langage Kotlin et le mode WebSocket pour ajouter une intention \u00e0 un bot initi\u00e9 dans Tock Studio . Si vous le souhaitez, vous pouvez sauter cette \u00e9tape et d\u00e9ployer un plateforme avec Docker ou passer directement au manuel utilisateur pour en savoir plus sur les possibilit\u00e9s de Tock Studio .","title":"Programmer des parcours en Kotlin"},{"location":"guide/api/#ce-que-vous-allez-creer","text":"Une intention Tock d\u00e9velopp\u00e9e avec le langage Kotlin Un programme se connectant au bot en WebSocket pour l'enrichir de parcours programm\u00e9s","title":"Ce que vous allez cr\u00e9er"},{"location":"guide/api/#pre-requis","text":"Environ 10 minutes Un bot Tock fonctionnel (par exemple suite au guide premier bot Tock ) Un environnement de d\u00e9veloppement (ou IDE ) supportant Kotlin , par exemple IntelliJ avec des versions r\u00e9centes du JDK et de Maven Si vous ne souhaitez pas utiliser d' IDE , ou Maven, pas de probl\u00e8me. Il est tout \u00e0 fait possible de r\u00e9aliser le m\u00eame exercice avec d'autres outils. Il est \u00e9galement possible d'utiliser d'autres mani\u00e8res de d\u00e9velopper que le mode WebSocket et d'autres langages que Kotlin. Vous en apprendrez plus dans le manuel utilisateur Tock .","title":"Pr\u00e9-requis"},{"location":"guide/api/#creer-un-programme-kotlin-avec-la-dependance-tock","text":"Il existe de nombreuses mani\u00e8res de cr\u00e9er un projet en Kotlin. Ajoutez au classpath la biblioth\u00e8que tock-bot-api-websocket pour le mode WebSocket . Si vous utilisez Apache Maven , voici un exemple de POM ( pom.xml ) pour Kotlin avec la d\u00e9pendance tock-bot-api-websocket incluse : <?xml version=\"1.0\" encoding=\"UTF-8\"?> <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <groupId> test </groupId> <artifactId> tock-kotlin-websocket </artifactId> <version> 0.0.1-SNAPSHOT </version> <properties> <project.build.sourceEncoding> UTF-8 </project.build.sourceEncoding> <project.build.sourceDirectory> ${project.basedir}/src/main/kotlin </project.build.sourceDirectory> <project.build.testSourceDirectory> ${project.basedir}/src/test/kotlin </project.build.testSourceDirectory> <lib.tock.version> 19.3.3 </lib.tock.version> <plugin.kotlin.version> 1.3.41 </plugin.kotlin.version> <plugin.source.version> 3.1.0 </plugin.source.version> </properties> <dependencies> <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-websocket </artifactId> <version> ${lib.tock.version} </version> </dependency> </dependencies> <build> <sourceDirectory> ${project.build.sourceDirectory} </sourceDirectory> <testSourceDirectory> ${project.build.testSourceDirectory} </testSourceDirectory> <plugins> <plugin> <groupId> org.jetbrains.kotlin </groupId> <artifactId> kotlin-maven-plugin </artifactId> <version> ${plugin.kotlin.version} </version> <executions> <execution> <id> compile </id> <phase> compile </phase> <goals> <goal> compile </goal> </goals> </execution> <execution> <id> test-compile </id> <phase> test-compile </phase> <goals> <goal> test-compile </goal> </goals> </execution> </executions> </plugin> <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-source-plugin </artifactId> <version> ${plugin.source.version} </version> <executions> <execution> <id> attach-sources </id> <phase> verify </phase> <goals> <goal> jar-no-fork </goal> </goals> </execution> </executions> </plugin> </plugins> </build> </project> Vous pouvez retrouver ce code (et d'autres exemples) dans le d\u00e9p\u00f4t tock-bot-samples .","title":"Cr\u00e9er un programme Kotlin avec la d\u00e9pendance Tock"},{"location":"guide/api/#creer-une-fonction-qui-se-connecte-a-tock","text":"Cr\u00e9ez un fichier Kotlin (par exemple dans `src/main/kotlin/StartWebSocket.kt) Editez-le avec le code suivant : import fr.vsct.tock.bot.api.client.newBot import fr.vsct.tock.bot.api.client.newStory import fr.vsct.tock.bot.api.websocket.startWithDemo fun main () { startWithDemo ( // Integrate with the Tock demo platform by default newBot ( \"PUT-YOUR-TOCK-APP-API-KEY-HERE\" , // Get your app API key from Bot Configurations in Tock Studio newStory ( \"qui-es-tu\" ) { // Answer for the 'qui-es-tu' story send ( \"Je suis un assistant conversationnel construit avec Tock\" ) end ( \"Comment puis-je aider ?\" ) } ) ) } Vous pouvez retrouver ce code (et d'autres exemples) dans le d\u00e9p\u00f4t tock-bot-samples . Remplacez la clef d'API par celle de votre propre application Tock. Pour cela, dans Tock Studio , allez dans Configuration > Bot Configurations et reportez la valeur API Key dans le code. Ex\u00e9cutez la fonction ( main ) dans votre environnement de d\u00e9veloppement. Vous devriez voir appara\u00eetre une ligne de log ressemblant \u00e0 celle-ci : [ main ] INFO fr . vsct . tock . bot . api . websocket . BotApiWebSocketClient - start web socket client : { ... } V\u00e9rifiez \u00e9ventuellement que d'autres logs provenant de BotApiWebSocketClient n'indiquent pas d'erreur. Si c'est le cas, il peut s'agir d'une erreur de configuration de la clef d'API.","title":"Cr\u00e9er une fonction qui se connecte \u00e0 Tock"},{"location":"guide/api/#terminer-la-configuration-dans-tock-studio","text":"Retournez dans Tock et allez dans Build > Search Stories D\u00e9cochez l'option Only Configured Stories . Vous voyez alors tous parcours, y compris \"qui-es-tu\" que vous venez de d\u00e9clarer programmatiquement Allez dans Test > Test the bot et saisissez une ou plusieurs phrases comme \"qui es-tu ?\" par exemple. Vous contastez que le bot ne r\u00e9pond pas encore \u00e0 cette question - il r\u00e9pond peut-\u00eatre m\u00eame \u00e0 une autre intention. Il reste en effet une configuration \u00e0 effectuer pour que la qualification fonctionne. A ce stade, le parcours existe bien dans Tock, mais l' intention n'a pas \u00e9t\u00e9 cr\u00e9\u00e9e automatiquement. Vous pouvez le v\u00e9rifier en regardant la liste des intentions disponibles dans NLU > Intents > build (la cat\u00e9gorie par d\u00e9faut). TODO : fix #533 Allez dans NLU > Inbox , pour la derni\u00e8re phrase que vous venez de saisir : Changez l'intention pour New intent Nommez-la \"qui-es-tu\" comme dans le code (pour que le lien se fasse) Cr\u00e9ez l'intention avec Create Puis terminez la qualification de la phrase avec Validate Si vous avez saisi d'autres phrases pour cette intention, pour chacune d'elles s\u00e9lectionnez l'intention dans la liste puis confirmez avec Validate Retournez dans Test > Test the bot . Si vous reposez la question, le bot vous donne d\u00e9sormais la r\u00e9ponse construite dans le code Kotlin (ie. \"Je suis un assistant...\").","title":"Terminer la configuration dans Tock Studio"},{"location":"guide/api/#felicitations","text":"Vous venez de configurer votre premi\u00e8re story programmatique en Kotlin. De cette mani\u00e8re, vous pouvez tirer pleinement parti des possibilit\u00e9s d'un langage de programmation pour construire toutes sortes de parcours simples et complexes, interroger des API tierces, impl\u00e9menter des r\u00e8gles de gestion, etc. Si vous programmez ainsi une story d\u00e9j\u00e0 d\u00e9finie dans Tock Studio , c'est la d\u00e9finition pr\u00e9sente dans Tock Studio qui est utilis\u00e9e pour construire les r\u00e9ponses \u00e0 l'ex\u00e9cution.","title":"F\u00e9licitations!"},{"location":"guide/api/#continuer","text":"Dans la section suivante vous apprendez \u00e0 : D\u00e9ployer une plateforme Tock en quelques minutes avec Docker Pour en savoir plus sur l'utilisation de Tock Bot API en mode WebSocket , mais aussi les autres modes de d\u00e9ploiement, les types de messages support\u00e9s par Tock, etc. vous pouvez consulter le manuel utilisateur .","title":"Continuer..."},{"location":"guide/messenger/","text":"Configurer son bot pour Messenger \u00b6 TODO","title":"Configure Messenger"},{"location":"guide/messenger/#configurer-son-bot-pour-messenger","text":"TODO","title":"Configurer son bot pour Messenger"},{"location":"guide/platform/","text":"D\u00e9ployer une plateforme avec Docker \u00b6 Dans les sections pr\u00e9c\u00e9dentes pour d\u00e9couvrir et tester Tock, vous avez utilis\u00e9 la plateforme de d\u00e9monstration . Cela vous a permis de d\u00e9couvrir la construction et la configuration des bots Tock sans avoir \u00e0 installer la plateforme au pr\u00e9alable. Dans ce guide, vous allez apprendre \u00e0 d\u00e9ployer une plateforme compl\u00e8te Tock en quelques minutes, gr\u00e2ce aux exemples d'impl\u00e9mentations Docker / Docker Compose fournies. Notez qu'il est tout \u00e0 fait possible de d\u00e9ployer Tock sans utiliser Docker. Une section sp\u00e9cifique du manuel utilisateur vous en apprendra plus sur l'architecture, les possibilit\u00e9s et les recommandations pour le d\u00e9ploiement et l'utilisation de Tock en production. Ce que vous allez cr\u00e9er \u00b6 Une plateforme Tock compl\u00e8te en local : Tock Studio , Bot API , etc. Un bot et une configuration minimale pour tester la plateforme (Optionnel) Un programme Kotlin se connectant \u00e0 la plateforme locale en WebSocket Pr\u00e9-requis \u00b6 Environ 20 minutes Pour d\u00e9ployer la plateforme en local, un environnement de d\u00e9veloppement avec des versions r\u00e9centes de Docker et Docker Compose install\u00e9es Si vous ne souhaitez pas utiliser Docker, pas de probl\u00e8me. Il y a d'autres mani\u00e8res de d\u00e9ployer la base MongoDB et les services Kotlin sur JVM. Vous pouvez toutefois parcourir les Dockerfile et docker-compose.yml \u00e0 titre d'exemples pour instancier ces services. (Optionnel) Pour le programme en WebSocket, un environnement de d\u00e9veloppement (ou IDE ) supportant Kotlin , par exemple IntelliJ avec des versions r\u00e9centes du JDK et de Maven Sans IDE ou sans Maven, pas de probl\u00e8me. Il est tout \u00e0 fait possible de compiler et ex\u00e9cuter le programme avec d'autres outils. D'autres modes que Kotlin et WebSocket sont pr\u00e9sent\u00e9s dans le manuel utilisateur Tock . D\u00e9ployer une plateforme Tock - sans les sources \u00b6 Il est possible de r\u00e9cup\u00e9rer seulement quelques fichiers du d\u00e9p\u00f4t GitHub, sans t\u00e9l\u00e9charger toutes les sources Tock. En quelques lignes de commande, la plateforme est op\u00e9rationnelle. Il est cependant indispensable d'avoir des versions r\u00e9centes de Docker et Docker Compose . Pour d\u00e9marrer depuis les sources du d\u00e9p\u00f4t Tock Docker, passez plut\u00f4t au paragraphe suivant . # Get the lastest docker-compose from GitHub (including Bot API) $ curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose-bot.yml # Get the lastest database-init script from GitHub $ mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh # Get the lastest Tock version/tag from GitHub $ curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env # Run the stack $ docker-compose up D\u00e9ployer une plateforme Tock - depuis les sources \u00b6 Ceci est une mani\u00e8re alternative de d\u00e9marrer Tock, \u00e0 partir du d\u00e9p\u00f4t Tock Docker . Il vous faut, en plus de Docker et Docker Compose , soit un client Git pour r\u00e9cup\u00e9rer les sources (commande git clone ) soit avoir d\u00e9j\u00e0 copi\u00e9 les sources de GitHub en local. Pour d\u00e9marrer sans Git ni les sources du d\u00e9p\u00f4t en local, suivez le paragraphe pr\u00e9c\u00e9dent . # Get the lastest sources from GitHub $ git clone https://github.com/theopenconversationkit/tock-docker.git && cd tock-docker # Make the database-init script executable $ chmod +x scripts/setup.sh # Run the stack (including Bot API) $ docker-compose -f docker-compose-bot.yml up Acc\u00e9der \u00e0 Tock Studio \u00b6 Une fois la plateforme pr\u00eate, les interfaces Tock Studio sont sur le port 80 par d\u00e9faut : Allez sur http://localhost Apr\u00e8s le d\u00e9ploiement de la plateforme, celle-ci s'initialise, et il peut falloir attendre quelques secondes avant que les interfaces Tock Studio soient accessibles. Connectez-vous avec les identifiants admin@app.com / password par d\u00e9faut Il est \u00e9videmment recommand\u00e9 de changer ces valeurs \u00e0 l'installation d'une plateforme destin\u00e9e \u00e0 une utilisation p\u00e9renne (production, plateforme partag\u00e9e entre \u00e9quipes, etc.). Cr\u00e9er une application, un connecteur et une intention \u00b6 Comme dans le guide premier bot utilisant la plateforme de d\u00e9monstration, vous allez cr\u00e9er une application Tock et un connecteur pour commencer \u00e0 utiliser la plateforme locale. N'h\u00e9sitez pas \u00e0 retourner voir les pr\u00e9c\u00e9dents guides pour plus de commentaires. Au premier acc\u00e8s \u00e0 la plateforme locale : Saisissez un nom pour l'application S\u00e9lectionnez une langue - vous pourrez en ajouter d'autres par la suite Validez pour cr\u00e9er l'application Allez dans Configuration > Bot Configurations Create a new Configuration S\u00e9lectionnez le type de connecteur Slack Create Notez l' API Key automatiquement g\u00e9n\u00e9r\u00e9e pour votre application. Elle vous servira si vous essayez le mode WebSocket dans la suite de ce guide (optionnel). Allez dans Build > New Story Saisissez une phrase utilisateur par exemple \"bonjour\" Dans le champs Add new Answer , saisissez une r\u00e9ponse par exemple \"quelle belle journ\u00e9e!\" Terminez avec Create Story Allez dans Test > Test the bot Dites \"bonjour\" \ud83d\ude4b, le bot vous r\u00e9pond \ud83e\udd16 Connecter un parcours en Kotlin (optionnel) \u00b6 Comme dans le guide programmer des parcours utilisant la plateforme de d\u00e9monstration, vous allez cr\u00e9er une application Kotlin se connectant en WebSocket \u00e0 la plateforme Tock locale. N'h\u00e9sitez pas \u00e0 retourner voir les pr\u00e9c\u00e9dents guides pour plus de d\u00e9tails. Cr\u00e9ez un projet Kotlin par exemple avec Maven comme indiqu\u00e9 dans le guide programmer des parcours Le classpath doit inclure tock-bot-api-websocket pour utiliser le mode WebSocket . Cr\u00e9ez un fichier Kotlin (par exemple dans `src/main/kotlin/StartWebSocket.kt) Editez-le avec le code suivant : import fr.vsct.tock.bot.api.client.newBot import fr.vsct.tock.bot.api.client.newStory import fr.vsct.tock.bot.api.websocket.start fun main () { start ( // Do not use #startWithDemo when integrating with a local platform newBot ( \"PUT-YOUR-TOCK-APP-API-KEY-HERE\" , // Get your app API key from Bot Configurations in Tock Studio newStory ( \"qui-es-tu\" ) { // Answer for the 'qui-es-tu' story send ( \"Je suis un assistant conversationnel construit avec Tock\" ) end ( \"Comment puis-je aider ?\" ) } ), \"http://localhost:8080\" // Local platform URL (default host/port) ) } Vous pouvez retrouver ce code (et d'autres exemples) dans le d\u00e9p\u00f4t tock-bot-samples . Remplacez la clef d'API par celle de votre propre application Tock. Pour cela, dans Tock Studio , allez dans Configuration > Bot Configurations et reportez la valeur API Key dans le code. Ex\u00e9cutez la fonction ( main ) dans votre environnement de d\u00e9veloppement. Retournez dans Tock dans Test > Test the bot et dites \"qui es-tu ?\" : le bot ne r\u00e9pond pas encore. Allez dans NLU > Inbox , pour la phrase que vous venez de saisir : Changez l'intention pour New intent Nommez-la \"qui-es-tu\" comme dans le code (pour que le lien se fasse) Cr\u00e9ez l'intention avec Create Terminez la qualification de la phrase avec Validate Retournez dans Test > Test the bot . Dites \"qui es-tu ?\" : le bot r\u00e9pond ! F\u00e9licitations! \u00b6 Vous venez de d\u00e9ployer votre propre plateforme conversationnelle Tock en local. Cela peut servir \u00e0 mieux appr\u00e9hender l'architecture et v\u00e9rifier la portabilit\u00e9 de la solution, mais aussi lors de d\u00e9veloppements, pour les contributeurs Tock ou encore si vous devez travailler sans acc\u00e8s \u00e0 Internet (en mobilit\u00e9, sur un r\u00e9seau restreint, etc.). Attention, l'impl\u00e9mentation Docker fournie ne suffit pas \u00e0 garantir r\u00e9silience et mont\u00e9e en charge de la plateforme quelles que soient les conditions en production. Pour cela, quelques recommandations sont propos\u00e9es dans la section haute disponibilit\u00e9 du manuel Tock. Continuer... \u00b6 Vous venez de terminer les guides de d\u00e9marrage rapide Tock. A partir de l\u00e0, vous pouvez vous lancer directement sur une plateforme Tock, ou parcourir le manuel utilisateur pour en savoir plus sur Tock Studio , Bot API et Bot Flow par exemple. D'autres pages pr\u00e9sentent aussi des \u00e9tudes de cas clients, des exemples de code, comment contacter la communaut\u00e9 Tock, etc.","title":"Deploy with Docker"},{"location":"guide/platform/#deployer-une-plateforme-avec-docker","text":"Dans les sections pr\u00e9c\u00e9dentes pour d\u00e9couvrir et tester Tock, vous avez utilis\u00e9 la plateforme de d\u00e9monstration . Cela vous a permis de d\u00e9couvrir la construction et la configuration des bots Tock sans avoir \u00e0 installer la plateforme au pr\u00e9alable. Dans ce guide, vous allez apprendre \u00e0 d\u00e9ployer une plateforme compl\u00e8te Tock en quelques minutes, gr\u00e2ce aux exemples d'impl\u00e9mentations Docker / Docker Compose fournies. Notez qu'il est tout \u00e0 fait possible de d\u00e9ployer Tock sans utiliser Docker. Une section sp\u00e9cifique du manuel utilisateur vous en apprendra plus sur l'architecture, les possibilit\u00e9s et les recommandations pour le d\u00e9ploiement et l'utilisation de Tock en production.","title":"D\u00e9ployer une plateforme avec Docker"},{"location":"guide/platform/#ce-que-vous-allez-creer","text":"Une plateforme Tock compl\u00e8te en local : Tock Studio , Bot API , etc. Un bot et une configuration minimale pour tester la plateforme (Optionnel) Un programme Kotlin se connectant \u00e0 la plateforme locale en WebSocket","title":"Ce que vous allez cr\u00e9er"},{"location":"guide/platform/#pre-requis","text":"Environ 20 minutes Pour d\u00e9ployer la plateforme en local, un environnement de d\u00e9veloppement avec des versions r\u00e9centes de Docker et Docker Compose install\u00e9es Si vous ne souhaitez pas utiliser Docker, pas de probl\u00e8me. Il y a d'autres mani\u00e8res de d\u00e9ployer la base MongoDB et les services Kotlin sur JVM. Vous pouvez toutefois parcourir les Dockerfile et docker-compose.yml \u00e0 titre d'exemples pour instancier ces services. (Optionnel) Pour le programme en WebSocket, un environnement de d\u00e9veloppement (ou IDE ) supportant Kotlin , par exemple IntelliJ avec des versions r\u00e9centes du JDK et de Maven Sans IDE ou sans Maven, pas de probl\u00e8me. Il est tout \u00e0 fait possible de compiler et ex\u00e9cuter le programme avec d'autres outils. D'autres modes que Kotlin et WebSocket sont pr\u00e9sent\u00e9s dans le manuel utilisateur Tock .","title":"Pr\u00e9-requis"},{"location":"guide/platform/#deployer-une-plateforme-tock-sans-les-sources","text":"Il est possible de r\u00e9cup\u00e9rer seulement quelques fichiers du d\u00e9p\u00f4t GitHub, sans t\u00e9l\u00e9charger toutes les sources Tock. En quelques lignes de commande, la plateforme est op\u00e9rationnelle. Il est cependant indispensable d'avoir des versions r\u00e9centes de Docker et Docker Compose . Pour d\u00e9marrer depuis les sources du d\u00e9p\u00f4t Tock Docker, passez plut\u00f4t au paragraphe suivant . # Get the lastest docker-compose from GitHub (including Bot API) $ curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose-bot.yml # Get the lastest database-init script from GitHub $ mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh # Get the lastest Tock version/tag from GitHub $ curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env # Run the stack $ docker-compose up","title":"D\u00e9ployer une plateforme Tock - sans les sources"},{"location":"guide/platform/#deployer-une-plateforme-tock-depuis-les-sources","text":"Ceci est une mani\u00e8re alternative de d\u00e9marrer Tock, \u00e0 partir du d\u00e9p\u00f4t Tock Docker . Il vous faut, en plus de Docker et Docker Compose , soit un client Git pour r\u00e9cup\u00e9rer les sources (commande git clone ) soit avoir d\u00e9j\u00e0 copi\u00e9 les sources de GitHub en local. Pour d\u00e9marrer sans Git ni les sources du d\u00e9p\u00f4t en local, suivez le paragraphe pr\u00e9c\u00e9dent . # Get the lastest sources from GitHub $ git clone https://github.com/theopenconversationkit/tock-docker.git && cd tock-docker # Make the database-init script executable $ chmod +x scripts/setup.sh # Run the stack (including Bot API) $ docker-compose -f docker-compose-bot.yml up","title":"D\u00e9ployer une plateforme Tock - depuis les sources"},{"location":"guide/platform/#acceder-a-tock-studio","text":"Une fois la plateforme pr\u00eate, les interfaces Tock Studio sont sur le port 80 par d\u00e9faut : Allez sur http://localhost Apr\u00e8s le d\u00e9ploiement de la plateforme, celle-ci s'initialise, et il peut falloir attendre quelques secondes avant que les interfaces Tock Studio soient accessibles. Connectez-vous avec les identifiants admin@app.com / password par d\u00e9faut Il est \u00e9videmment recommand\u00e9 de changer ces valeurs \u00e0 l'installation d'une plateforme destin\u00e9e \u00e0 une utilisation p\u00e9renne (production, plateforme partag\u00e9e entre \u00e9quipes, etc.).","title":"Acc\u00e9der \u00e0 Tock Studio"},{"location":"guide/platform/#creer-une-application-un-connecteur-et-une-intention","text":"Comme dans le guide premier bot utilisant la plateforme de d\u00e9monstration, vous allez cr\u00e9er une application Tock et un connecteur pour commencer \u00e0 utiliser la plateforme locale. N'h\u00e9sitez pas \u00e0 retourner voir les pr\u00e9c\u00e9dents guides pour plus de commentaires. Au premier acc\u00e8s \u00e0 la plateforme locale : Saisissez un nom pour l'application S\u00e9lectionnez une langue - vous pourrez en ajouter d'autres par la suite Validez pour cr\u00e9er l'application Allez dans Configuration > Bot Configurations Create a new Configuration S\u00e9lectionnez le type de connecteur Slack Create Notez l' API Key automatiquement g\u00e9n\u00e9r\u00e9e pour votre application. Elle vous servira si vous essayez le mode WebSocket dans la suite de ce guide (optionnel). Allez dans Build > New Story Saisissez une phrase utilisateur par exemple \"bonjour\" Dans le champs Add new Answer , saisissez une r\u00e9ponse par exemple \"quelle belle journ\u00e9e!\" Terminez avec Create Story Allez dans Test > Test the bot Dites \"bonjour\" \ud83d\ude4b, le bot vous r\u00e9pond \ud83e\udd16","title":"Cr\u00e9er une application, un connecteur et une intention"},{"location":"guide/platform/#connecter-un-parcours-en-kotlin-optionnel","text":"Comme dans le guide programmer des parcours utilisant la plateforme de d\u00e9monstration, vous allez cr\u00e9er une application Kotlin se connectant en WebSocket \u00e0 la plateforme Tock locale. N'h\u00e9sitez pas \u00e0 retourner voir les pr\u00e9c\u00e9dents guides pour plus de d\u00e9tails. Cr\u00e9ez un projet Kotlin par exemple avec Maven comme indiqu\u00e9 dans le guide programmer des parcours Le classpath doit inclure tock-bot-api-websocket pour utiliser le mode WebSocket . Cr\u00e9ez un fichier Kotlin (par exemple dans `src/main/kotlin/StartWebSocket.kt) Editez-le avec le code suivant : import fr.vsct.tock.bot.api.client.newBot import fr.vsct.tock.bot.api.client.newStory import fr.vsct.tock.bot.api.websocket.start fun main () { start ( // Do not use #startWithDemo when integrating with a local platform newBot ( \"PUT-YOUR-TOCK-APP-API-KEY-HERE\" , // Get your app API key from Bot Configurations in Tock Studio newStory ( \"qui-es-tu\" ) { // Answer for the 'qui-es-tu' story send ( \"Je suis un assistant conversationnel construit avec Tock\" ) end ( \"Comment puis-je aider ?\" ) } ), \"http://localhost:8080\" // Local platform URL (default host/port) ) } Vous pouvez retrouver ce code (et d'autres exemples) dans le d\u00e9p\u00f4t tock-bot-samples . Remplacez la clef d'API par celle de votre propre application Tock. Pour cela, dans Tock Studio , allez dans Configuration > Bot Configurations et reportez la valeur API Key dans le code. Ex\u00e9cutez la fonction ( main ) dans votre environnement de d\u00e9veloppement. Retournez dans Tock dans Test > Test the bot et dites \"qui es-tu ?\" : le bot ne r\u00e9pond pas encore. Allez dans NLU > Inbox , pour la phrase que vous venez de saisir : Changez l'intention pour New intent Nommez-la \"qui-es-tu\" comme dans le code (pour que le lien se fasse) Cr\u00e9ez l'intention avec Create Terminez la qualification de la phrase avec Validate Retournez dans Test > Test the bot . Dites \"qui es-tu ?\" : le bot r\u00e9pond !","title":"Connecter un parcours en Kotlin (optionnel)"},{"location":"guide/platform/#felicitations","text":"Vous venez de d\u00e9ployer votre propre plateforme conversationnelle Tock en local. Cela peut servir \u00e0 mieux appr\u00e9hender l'architecture et v\u00e9rifier la portabilit\u00e9 de la solution, mais aussi lors de d\u00e9veloppements, pour les contributeurs Tock ou encore si vous devez travailler sans acc\u00e8s \u00e0 Internet (en mobilit\u00e9, sur un r\u00e9seau restreint, etc.). Attention, l'impl\u00e9mentation Docker fournie ne suffit pas \u00e0 garantir r\u00e9silience et mont\u00e9e en charge de la plateforme quelles que soient les conditions en production. Pour cela, quelques recommandations sont propos\u00e9es dans la section haute disponibilit\u00e9 du manuel Tock.","title":"F\u00e9licitations!"},{"location":"guide/platform/#continuer","text":"Vous venez de terminer les guides de d\u00e9marrage rapide Tock. A partir de l\u00e0, vous pouvez vous lancer directement sur une plateforme Tock, ou parcourir le manuel utilisateur pour en savoir plus sur Tock Studio , Bot API et Bot Flow par exemple. D'autres pages pr\u00e9sentent aussi des \u00e9tudes de cas clients, des exemples de code, comment contacter la communaut\u00e9 Tock, etc.","title":"Continuer..."},{"location":"guide/slack/","text":"Configurer son bot pour Slack \u00b6 Si vous avez suivi le guide Cr\u00e9er son premier bot avec Tock Studio , vous avez d\u00e9clar\u00e9 un connecteur de type Slack mais celui-ci n'est pas encore configur\u00e9 pour que le bot parle r\u00e9ellement sur Slack . Avec un peu de configuration c\u00f4t\u00e9 Slack et c\u00f4t\u00e9 Tock, un bot peut recevoir des messages et r\u00e9pondre sur ce canal. Si vous le souhaitez, vous pouvez aussi sauter cette \u00e9tape et configurer un canal Messenger ou passer directement \u00e0 la suite . Ce que vous allez cr\u00e9er \u00b6 Une configuration (dans Slack et dans Tock) pour recevoir et envoyer des messages Slack Un bot qui parle sur une cha\u00eene Slack Pr\u00e9-requis \u00b6 Environ 15 minutes Un bot Tock fonctionnel (par exemple suite au guide premier bot Tock ) Un compte Slack et un espace de travail / une cha\u00eene o\u00f9 int\u00e9grer le bot Si vous n'avez jamais utilis\u00e9 Slack, rendez-vous sur sur https://slack.com/ Cr\u00e9er une application dans Slack \u00b6 Allez sur la page Create a Slack app Entrez un nom pour l' application S\u00e9lectionnez un espace de travail Terminez avec Create App Activer l'envoi de messages \u00e0 Slack \u00b6 Ouvrez Incoming Webhooks et cochez Activate Incoming Webhooks Cliquez sur Add New Webhook to Workspace S\u00e9lectionnez une cha\u00eene ou une personne pour la conversation avec le bot Terminez par Installer Copiez la Webhook URL qui vient d'\u00eatre cr\u00e9\u00e9e La Webhook URL ressemble dans son format \u00e0 quelque chose comme : https://hooks.slack.com/services/{workspaceToken}/{webhookToken}/{authToken} Dans Tock Studio allez dans Configuration > Bot Configurations Trouvez votre connecteur de type Slack (ou cr\u00e9ez-en un nouveau si besoin) et ouvrez la section Connector Custom Configuration Saisissez dans les trois champs tokens les jetons issus de l'adresse pr\u00e9c\u00e9demment copi\u00e9e : Token 1 : le premier token de la WebhookURL , ou workspaceToken Token 2 : le deuxi\u00e8me token de la WebhookURL , ou webhookToken Token 3 : le dernier token de la WebhookURL , ou authToken Terminez avec Update Activer la reception de messages depuis Slack \u00b6 Dans la page de votre application Slack, allez dans Event Subscriptions et activez Enable Events Entrez dans le champ Request URL l'adresse compl\u00e8te de votre connecteur Slack dans Tock. Sur la plateforme de d\u00e9monstration Tock, cette adresse sera du type https://demo.tock.ai/{chemin_relatif_du_connecteur_slack} Le chemin relatif du connecteur est indiqu\u00e9 dans la page Bot Configurations . Sur la ligne correspondant \u00e0 votre connecteur Slack, il s'agit du champ Relative REST path Ouvrez Add Workspace Event et s\u00e9lectionnez l'\u00e9venement message.channels Validez avec Save Changes Allez dans Interactive Components et activez Interactivity Entrez la m\u00eame Request URL que pr\u00e9c\u00e9demment Validez avec Save Changes Cr\u00e9er un bot Slack (et lui parler) \u00b6 Dans la page de votre application Slack, allez dans Bot Users et faites Add a Bot User Choisissez un nom / identifiant pour le bot dans Slack Validez avec Add Bot User Allez dans Install App et Reinstall App S\u00e9lectionnez la cha\u00eene Slack puis Installer Dans Slack, allez sur la cha\u00eene et parlez au bot (par exemple \"bonjour\"). Le bot vous r\u00e9pond maintenant dans Slack ! Regarder la conversation dans Tock Studio (optionnel) \u00b6 Quelque soient les canaux utilis\u00e9s pour converser avec le bot, vous pouvez suivre les conversations directement dans tous les \u00e9crans Tock Studio , par exemple : NLU > Inbox et Logs , Build > Bot Flow ou encore Monitoring > Users et Dialogs : Dans Tock, ouvrez Monitoring > Users et cliquez sur l'ic\u00f4ne Display dialog pour voir toute la conversation provenant de Slack F\u00e9licitations! \u00b6 Vous venez de configurer votre bot pour qu'il parle \u00e9galement sur Slack. Comme vous le constatez, connecter un bot Tock \u00e0 un (ou plusieurs) canaux externes n'est qu'une affaire de configuration. Vous pouvez construire le mod\u00e8le conversationnel, les fonctionnalit\u00e9s et la personnalit\u00e9 de votre assistant ind\u00e9pendamment des canaux sur lesquels vous souhaitez lui parler, aujourd'hui ou \u00e0 l'avenir. Continuer... \u00b6 Dans les sections suivantes vous apprendez \u00e0 : Configurer le bot pour le canal Messenger (requiert un compte Facebook) Cr\u00e9er des parcours programm\u00e9s en Kotlin , ouvrant la voie \u00e0 des comportements complexes et l'int\u00e9gration d'API tierces si besoin D\u00e9ployer une plateforme Tock en quelques minutes avec Docker Pour en savoir plus sur le connecteur Slack fourni avec Tock, rendez-vous dans le dossier connector-slack sur GitHub, o\u00f9 vous retrouverez les sources et le README du connecteur. Pour en savoir plus sur Tock Studio , les fonctionnalit\u00e9s et les modes de d\u00e9ploiement de Tock, vous pouvez aussi parcourir le manuel utilisateur , plus complet.","title":"Configure Slack"},{"location":"guide/slack/#configurer-son-bot-pour-slack","text":"Si vous avez suivi le guide Cr\u00e9er son premier bot avec Tock Studio , vous avez d\u00e9clar\u00e9 un connecteur de type Slack mais celui-ci n'est pas encore configur\u00e9 pour que le bot parle r\u00e9ellement sur Slack . Avec un peu de configuration c\u00f4t\u00e9 Slack et c\u00f4t\u00e9 Tock, un bot peut recevoir des messages et r\u00e9pondre sur ce canal. Si vous le souhaitez, vous pouvez aussi sauter cette \u00e9tape et configurer un canal Messenger ou passer directement \u00e0 la suite .","title":"Configurer son bot pour Slack"},{"location":"guide/slack/#ce-que-vous-allez-creer","text":"Une configuration (dans Slack et dans Tock) pour recevoir et envoyer des messages Slack Un bot qui parle sur une cha\u00eene Slack","title":"Ce que vous allez cr\u00e9er"},{"location":"guide/slack/#pre-requis","text":"Environ 15 minutes Un bot Tock fonctionnel (par exemple suite au guide premier bot Tock ) Un compte Slack et un espace de travail / une cha\u00eene o\u00f9 int\u00e9grer le bot Si vous n'avez jamais utilis\u00e9 Slack, rendez-vous sur sur https://slack.com/","title":"Pr\u00e9-requis"},{"location":"guide/slack/#creer-une-application-dans-slack","text":"Allez sur la page Create a Slack app Entrez un nom pour l' application S\u00e9lectionnez un espace de travail Terminez avec Create App","title":"Cr\u00e9er une application dans Slack"},{"location":"guide/slack/#activer-lenvoi-de-messages-a-slack","text":"Ouvrez Incoming Webhooks et cochez Activate Incoming Webhooks Cliquez sur Add New Webhook to Workspace S\u00e9lectionnez une cha\u00eene ou une personne pour la conversation avec le bot Terminez par Installer Copiez la Webhook URL qui vient d'\u00eatre cr\u00e9\u00e9e La Webhook URL ressemble dans son format \u00e0 quelque chose comme : https://hooks.slack.com/services/{workspaceToken}/{webhookToken}/{authToken} Dans Tock Studio allez dans Configuration > Bot Configurations Trouvez votre connecteur de type Slack (ou cr\u00e9ez-en un nouveau si besoin) et ouvrez la section Connector Custom Configuration Saisissez dans les trois champs tokens les jetons issus de l'adresse pr\u00e9c\u00e9demment copi\u00e9e : Token 1 : le premier token de la WebhookURL , ou workspaceToken Token 2 : le deuxi\u00e8me token de la WebhookURL , ou webhookToken Token 3 : le dernier token de la WebhookURL , ou authToken Terminez avec Update","title":"Activer l'envoi de messages \u00e0 Slack"},{"location":"guide/slack/#activer-la-reception-de-messages-depuis-slack","text":"Dans la page de votre application Slack, allez dans Event Subscriptions et activez Enable Events Entrez dans le champ Request URL l'adresse compl\u00e8te de votre connecteur Slack dans Tock. Sur la plateforme de d\u00e9monstration Tock, cette adresse sera du type https://demo.tock.ai/{chemin_relatif_du_connecteur_slack} Le chemin relatif du connecteur est indiqu\u00e9 dans la page Bot Configurations . Sur la ligne correspondant \u00e0 votre connecteur Slack, il s'agit du champ Relative REST path Ouvrez Add Workspace Event et s\u00e9lectionnez l'\u00e9venement message.channels Validez avec Save Changes Allez dans Interactive Components et activez Interactivity Entrez la m\u00eame Request URL que pr\u00e9c\u00e9demment Validez avec Save Changes","title":"Activer la reception de messages depuis Slack"},{"location":"guide/slack/#creer-un-bot-slack-et-lui-parler","text":"Dans la page de votre application Slack, allez dans Bot Users et faites Add a Bot User Choisissez un nom / identifiant pour le bot dans Slack Validez avec Add Bot User Allez dans Install App et Reinstall App S\u00e9lectionnez la cha\u00eene Slack puis Installer Dans Slack, allez sur la cha\u00eene et parlez au bot (par exemple \"bonjour\"). Le bot vous r\u00e9pond maintenant dans Slack !","title":"Cr\u00e9er un bot Slack (et lui parler)"},{"location":"guide/slack/#regarder-la-conversation-dans-tock-studio-optionnel","text":"Quelque soient les canaux utilis\u00e9s pour converser avec le bot, vous pouvez suivre les conversations directement dans tous les \u00e9crans Tock Studio , par exemple : NLU > Inbox et Logs , Build > Bot Flow ou encore Monitoring > Users et Dialogs : Dans Tock, ouvrez Monitoring > Users et cliquez sur l'ic\u00f4ne Display dialog pour voir toute la conversation provenant de Slack","title":"Regarder la conversation dans Tock Studio (optionnel)"},{"location":"guide/slack/#felicitations","text":"Vous venez de configurer votre bot pour qu'il parle \u00e9galement sur Slack. Comme vous le constatez, connecter un bot Tock \u00e0 un (ou plusieurs) canaux externes n'est qu'une affaire de configuration. Vous pouvez construire le mod\u00e8le conversationnel, les fonctionnalit\u00e9s et la personnalit\u00e9 de votre assistant ind\u00e9pendamment des canaux sur lesquels vous souhaitez lui parler, aujourd'hui ou \u00e0 l'avenir.","title":"F\u00e9licitations!"},{"location":"guide/slack/#continuer","text":"Dans les sections suivantes vous apprendez \u00e0 : Configurer le bot pour le canal Messenger (requiert un compte Facebook) Cr\u00e9er des parcours programm\u00e9s en Kotlin , ouvrant la voie \u00e0 des comportements complexes et l'int\u00e9gration d'API tierces si besoin D\u00e9ployer une plateforme Tock en quelques minutes avec Docker Pour en savoir plus sur le connecteur Slack fourni avec Tock, rendez-vous dans le dossier connector-slack sur GitHub, o\u00f9 vous retrouverez les sources et le README du connecteur. Pour en savoir plus sur Tock Studio , les fonctionnalit\u00e9s et les modes de d\u00e9ploiement de Tock, vous pouvez aussi parcourir le manuel utilisateur , plus complet.","title":"Continuer..."},{"location":"guide/studio/","text":"Create your first bot with Tock Studio \u00b6 The best way to try Tock is probably to create a first conversational bot using Tock Studio (the graphical user interface provided with the platform). By connecting to the Tock demonstration platform , it is possible to both design and test a conversational assistant in a few minutes, without having to write code. What you will build \u00b6 An application and a connector on the Tock demo platform A story : user sentence / bot answer, testable through the Tock Studio interface An assistant who answers, when you say \"hello\"! \ud83d\ude42 What you need \u00b6 About 5 to 15 minutes (reading the additional notes) A GitHub account, to connect to the demo platform Connect to the demo platform \u00b6 Open https://demo.tock.ai/ to access the Tock demonstration platform. Important : this platform is not supposed to host bots in production. This is merely a sandbox instance, in order to try the Tock solution without installing it. A login dialog invites you to connect with GitHub. Then, you have to accept that Tock gets info from your account - only your account ID will be read from GitHub. Create a Tock application \u00b6 When accessing the demo platform for the first time, a wizard helps to create the first application : Enter a name for the application Select a language - other languages can be added later Validate to create the application The just-created application is now visible from the menu: Configuration > NLU Applications . Once the first application has been created, more can be added by going back to this interface, then Create New Application . Add a connector \u00b6 To interact with the bot (through a communication channel), a connector must be used. Numerous connectors are provided with Tock: Messenger , WhatsApp , Google Assistant and Google Home , Twitter , Alexa , Business Chat , Teams , Slack , Rocket.Chat ... It is even possible to implement your own connectors to integrate with more channels. In this tutorial, you will configure a connector for Slack - the collaborative and instant messaging platform. It will be possible to try the bot using the Tock Studio interface - no need to use Slack or get an account. The following section Configure Slack will present, how to configure both Slack and the Tock application/connector, to integrate and try the bot live on Slack. Similarly the Configure Messenger guide shows, how to deploy the bot to another channel, the Facebook messaging service. Create the first connector for your application: Go to Configuration > Bot Configurations Create a new Configuration Select the connector type Slack Enter anything e.g. token in Token fields (for the moment) Create Note that an API Key is automatically generated for the application, once the first connector is created. This key is required to connect to the bot API, in order to leverage the WebHook or WebSocket modes described in Program stories . Clicking on Display test configurations , you can see another configuration has been created. This connector is special, it is used when the bot is tested directly through the Tock Studio interface. It allows to try the bot without having Slack, for instance. Create a story \u00b6 A conversational bot receives and understands user sentences, using natural-language techniques to identify an intent and possibly entities . Example: from the sentence \"What will the weather be like tomorrow?\", the Tock NLU (Natural Language Understanding) engine should detect a \"weather\" intent and a \"tomorrow\" date/time entity precising the question (like a kind of intent variable/parameter). In order to detect intents and entities, sentences must first be added and qualified - so that the bot learns. The Tock NLU menu permits to manage intents and entities, qualify sentences and supervise the bot training: the more qualified sentences, the more relevant is the bot (the more it understands natural language). Nevertheless, let's leave intents and entities for now... The Tock Stories mode allows to create intents automatically in a few minutes, as well as the expected asnwers. You will now create a first template of a conversation, using the Tock Studio graphical tools: Go to Build > New Story Enter a new user sentence - for instance \"hello\" A form now opens to configure the new story creation, the intent, the type of response, etc. In the Add new Answer field, enter the answer - for instance \"what a nice day!\" End with Create Story It is possible to answer more messages, or more advanced messages including images, links, Actions and buttons to continue within the conversation, etc. To known more, please refer to the Tock Studio section from the Tock user manual. Test the bot \u00b6 It is time to try the bot and its first story! Go to Test > Test the bot Say \"hello\", the bot answers In case the bot answers it did not understand, that is probably a qualification issue. You can check that the story and/or intent are created by looking at Build > Search Stories . Please check that the correct application and language are selected (in case there are more than one) when testing: they are visible in the top-right corner of the interface. If the bot still does not understand, maybe the sentence entered is not exactly the one entered with the story creation, then the bot does not make the connection. In the next section, you will learn how to improve bot understanding by qualifying more user sentences. When a technical error message occurs, it must be a connector configuration problem. Improve the understanding \u00b6 By entering various sentences through the Test the bot interface, you can see it does not understand much your natural language - even with sentences very similar to the one at story creation. That is normal. The conversational model and the Tock NLU engine must be trained and improved by progressively adding user qualified sentences to feed underlying algorithms and give more and more relevant results. Although first tries can be deceiving, several qualified sentences (one or two dozens if necessary) usually make a difference and the bot gets more relevant. Go to NLU > Inbox Here you can see the previously entered sentences, and more interestingly how the bot qualified them. For each sentence, Tock shows the detected intent, the language, as well as the scores (given by the algorithms according to their level of confidence for the sentence). Choose several sentences, for each one: select the correct intent then Validate Return to Test > Test the bot Check the bot now understands these sentences correctly, as well as slightly-different ones you have never entered! Create more stories (optional) \u00b6 To go a little further with Tock stories , you could create more stories and test them directly from Tock Studio . Each bot response comes from the intent detected/triggered, without another form of navigation than the thread of YOUR sentences. Conversational is magic: natural language is the navigation, users are not forced to use traditional links and menus anymore (contrary to Websites and mobile apps). For curious users, let's have a word about managing numerous stories and the possible impact on understanding. If you take time and create many stories , you may experience unintended effects with how work NLU models and algorithms. As an example, numerous intents and entities can make detection difficult (or more random). A general recommendation is to create bots, dedicated to a limited functional perimeter. It makes it easier to train each bot and focus on the model for its own domain. Qualifying a lot of sentences generally improves the bot understanding, however too many sentences (or too similar) can over-train the model for an intent, resulting in degraded performance. As a conclusion, remember the design and maintenance of conversational models is complex, it requires training (the bot, as well as people building it), qualifying and adapting the models on a regular basis to user needs and language. Congratulations! \u00b6 You have just created your first conversational application with Tock. With a few minutes and no particular knowledge or skill, more importantly without writing or deploying code, you have been able to create a simple conversational workflow and test it online. To be continued... \u00b6 In the next sections you will learn how to: Configure the bot for Slack (requires a Slack account) Configure the bot for Messenger (requires a Facebook developer account) Create more stories, written in Kotlin , making it possible to implement complex behaviours and features, possibly integrating 3rd party APIs Deploy a (standalone) Tock platform in minutes with Docker To find more about Tock Studio , its features and deployment modes, you can also browse the complete Tock user manual .","title":"Create your first bot"},{"location":"guide/studio/#create-your-first-bot-with-tock-studio","text":"The best way to try Tock is probably to create a first conversational bot using Tock Studio (the graphical user interface provided with the platform). By connecting to the Tock demonstration platform , it is possible to both design and test a conversational assistant in a few minutes, without having to write code.","title":"Create your first bot with Tock Studio"},{"location":"guide/studio/#what-you-will-build","text":"An application and a connector on the Tock demo platform A story : user sentence / bot answer, testable through the Tock Studio interface An assistant who answers, when you say \"hello\"! \ud83d\ude42","title":"What you will build"},{"location":"guide/studio/#what-you-need","text":"About 5 to 15 minutes (reading the additional notes) A GitHub account, to connect to the demo platform","title":"What you need"},{"location":"guide/studio/#connect-to-the-demo-platform","text":"Open https://demo.tock.ai/ to access the Tock demonstration platform. Important : this platform is not supposed to host bots in production. This is merely a sandbox instance, in order to try the Tock solution without installing it. A login dialog invites you to connect with GitHub. Then, you have to accept that Tock gets info from your account - only your account ID will be read from GitHub.","title":"Connect to the demo platform"},{"location":"guide/studio/#create-a-tock-application","text":"When accessing the demo platform for the first time, a wizard helps to create the first application : Enter a name for the application Select a language - other languages can be added later Validate to create the application The just-created application is now visible from the menu: Configuration > NLU Applications . Once the first application has been created, more can be added by going back to this interface, then Create New Application .","title":"Create a Tock application"},{"location":"guide/studio/#add-a-connector","text":"To interact with the bot (through a communication channel), a connector must be used. Numerous connectors are provided with Tock: Messenger , WhatsApp , Google Assistant and Google Home , Twitter , Alexa , Business Chat , Teams , Slack , Rocket.Chat ... It is even possible to implement your own connectors to integrate with more channels. In this tutorial, you will configure a connector for Slack - the collaborative and instant messaging platform. It will be possible to try the bot using the Tock Studio interface - no need to use Slack or get an account. The following section Configure Slack will present, how to configure both Slack and the Tock application/connector, to integrate and try the bot live on Slack. Similarly the Configure Messenger guide shows, how to deploy the bot to another channel, the Facebook messaging service. Create the first connector for your application: Go to Configuration > Bot Configurations Create a new Configuration Select the connector type Slack Enter anything e.g. token in Token fields (for the moment) Create Note that an API Key is automatically generated for the application, once the first connector is created. This key is required to connect to the bot API, in order to leverage the WebHook or WebSocket modes described in Program stories . Clicking on Display test configurations , you can see another configuration has been created. This connector is special, it is used when the bot is tested directly through the Tock Studio interface. It allows to try the bot without having Slack, for instance.","title":"Add a connector"},{"location":"guide/studio/#create-a-story","text":"A conversational bot receives and understands user sentences, using natural-language techniques to identify an intent and possibly entities . Example: from the sentence \"What will the weather be like tomorrow?\", the Tock NLU (Natural Language Understanding) engine should detect a \"weather\" intent and a \"tomorrow\" date/time entity precising the question (like a kind of intent variable/parameter). In order to detect intents and entities, sentences must first be added and qualified - so that the bot learns. The Tock NLU menu permits to manage intents and entities, qualify sentences and supervise the bot training: the more qualified sentences, the more relevant is the bot (the more it understands natural language). Nevertheless, let's leave intents and entities for now... The Tock Stories mode allows to create intents automatically in a few minutes, as well as the expected asnwers. You will now create a first template of a conversation, using the Tock Studio graphical tools: Go to Build > New Story Enter a new user sentence - for instance \"hello\" A form now opens to configure the new story creation, the intent, the type of response, etc. In the Add new Answer field, enter the answer - for instance \"what a nice day!\" End with Create Story It is possible to answer more messages, or more advanced messages including images, links, Actions and buttons to continue within the conversation, etc. To known more, please refer to the Tock Studio section from the Tock user manual.","title":"Create a story"},{"location":"guide/studio/#test-the-bot","text":"It is time to try the bot and its first story! Go to Test > Test the bot Say \"hello\", the bot answers In case the bot answers it did not understand, that is probably a qualification issue. You can check that the story and/or intent are created by looking at Build > Search Stories . Please check that the correct application and language are selected (in case there are more than one) when testing: they are visible in the top-right corner of the interface. If the bot still does not understand, maybe the sentence entered is not exactly the one entered with the story creation, then the bot does not make the connection. In the next section, you will learn how to improve bot understanding by qualifying more user sentences. When a technical error message occurs, it must be a connector configuration problem.","title":"Test the bot"},{"location":"guide/studio/#improve-the-understanding","text":"By entering various sentences through the Test the bot interface, you can see it does not understand much your natural language - even with sentences very similar to the one at story creation. That is normal. The conversational model and the Tock NLU engine must be trained and improved by progressively adding user qualified sentences to feed underlying algorithms and give more and more relevant results. Although first tries can be deceiving, several qualified sentences (one or two dozens if necessary) usually make a difference and the bot gets more relevant. Go to NLU > Inbox Here you can see the previously entered sentences, and more interestingly how the bot qualified them. For each sentence, Tock shows the detected intent, the language, as well as the scores (given by the algorithms according to their level of confidence for the sentence). Choose several sentences, for each one: select the correct intent then Validate Return to Test > Test the bot Check the bot now understands these sentences correctly, as well as slightly-different ones you have never entered!","title":"Improve the understanding"},{"location":"guide/studio/#create-more-stories-optional","text":"To go a little further with Tock stories , you could create more stories and test them directly from Tock Studio . Each bot response comes from the intent detected/triggered, without another form of navigation than the thread of YOUR sentences. Conversational is magic: natural language is the navigation, users are not forced to use traditional links and menus anymore (contrary to Websites and mobile apps). For curious users, let's have a word about managing numerous stories and the possible impact on understanding. If you take time and create many stories , you may experience unintended effects with how work NLU models and algorithms. As an example, numerous intents and entities can make detection difficult (or more random). A general recommendation is to create bots, dedicated to a limited functional perimeter. It makes it easier to train each bot and focus on the model for its own domain. Qualifying a lot of sentences generally improves the bot understanding, however too many sentences (or too similar) can over-train the model for an intent, resulting in degraded performance. As a conclusion, remember the design and maintenance of conversational models is complex, it requires training (the bot, as well as people building it), qualifying and adapting the models on a regular basis to user needs and language.","title":"Create more stories (optional)"},{"location":"guide/studio/#congratulations","text":"You have just created your first conversational application with Tock. With a few minutes and no particular knowledge or skill, more importantly without writing or deploying code, you have been able to create a simple conversational workflow and test it online.","title":"Congratulations!"},{"location":"guide/studio/#to-be-continued","text":"In the next sections you will learn how to: Configure the bot for Slack (requires a Slack account) Configure the bot for Messenger (requires a Facebook developer account) Create more stories, written in Kotlin , making it possible to implement complex behaviours and features, possibly integrating 3rd party APIs Deploy a (standalone) Tock platform in minutes with Docker To find more about Tock Studio , its features and deployment modes, you can also browse the complete Tock user manual .","title":"To be continued..."},{"location":"utilisateur/channels/","text":"Construire un bot multicanal avec Tock \u00b6 Notion de connecteur \u00b6 Un connecteur Tock permet d'int\u00e9grer un bot \u00e0 un canal de communication textuel ou vocal externe. Mis \u00e0 part le type connecteur de test , d\u00e9di\u00e9 aux tests via l'interface Tock Studio , les connecteurs sont associ\u00e9s \u00e0 des canaux externes \u00e0 la plateforme Tock. Tout l'int\u00e9r\u00eat des connecteurs Tock r\u00e9side dans la possibilit\u00e9 de d\u00e9velopper des assistants conversationnels ind\u00e9pendamment du ou des canaux utilis\u00e9s pour lui parler. Il est ainsi possible de cr\u00e9er un bot pour un canal, puis le rendre multicanal par la suite en ajoutant des connecteurs. Connecteurs fournis avec Tock \u00b6 Tock fournit de nombreux connecteurs pour diff\u00e9rents types de canaux (voir ci-dessous). De nouveaux connecteurs sont r\u00e9guli\u00e8rement ajout\u00e9s \u00e0 la plateforme, en fonction des besoins projets mais aussi du calendrier d'ouverture aux bots des canaux grand public. Exemples : arriv\u00e9e de Google Home en France en 2017, Alexa en 2018, ouverture des API WhatsApp puis Business Chat en 2019, etc. Messenger \u00b6 Canal : Facebook Messenger Type : texte (+ voix via l'upload de messages vocaux) Status : connecteur Tock utilis\u00e9 en production depuis 2016 Le guide Connecter son bot \u00e0 Messenger explique comment int\u00e9grer un bot Tock avec une page Facebook / Messenger . Pour en savoir plus sur ce connecteur, vous pouvez aussi vous rendre dans le dossier connector-messenger sur GitHub, o\u00f9 vous retrouverez les sources et le README du connecteur. Slack \u00b6 Canal : Slack Type : texte Status : connecteur Tock utilis\u00e9 hors production Le guide Connecter son bot \u00e0 Slack explique comment int\u00e9grer un bot Tock avec une cha\u00eene Slack . Pour en savoir plus sur ce connecteur, vous pouvez aussi vous rendre dans le dossier connector-slack sur GitHub, o\u00f9 vous retrouverez les sources et le README du connecteur. Google Assistant / Google Home \u00b6 Canal : Google Assistant / Google Home Type : texte + voix Status : connecteur Tock utilis\u00e9 en production depuis 2017 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-ga sur GitHub. Alexa / Echo \u00b6 Canal : Amazon Alexa Type : voix Status : connecteur Tock utilis\u00e9 en production depuis 2018 Remarque importante : dans le cas d'Alexa, le mod\u00e8le NLP est forc\u00e9ment construit et h\u00e9berg\u00e9 chez Amazon. Seul la partie framework conversationel de Tock peut \u00eatre utilis\u00e9e. Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-alexa sur GitHub. Rocket.Chat \u00b6 Canal : Rocket.Chat Type : texte Status : \u00e0 pr\u00e9ciser Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-rocketchat sur GitHub. WhatsApp \u00b6 Canal : WhatsApp from Facebook Type : texte Status : connecteur Tock utilis\u00e9 en production depuis 2019 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-whatsapp sur GitHub. Teams \u00b6 Canal : Microsoft Teams Type : texte + voix Status : connecteur Tock utilis\u00e9 en production depuis 2019 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-teams sur GitHub. Business Chat / Messages \u00b6 Canal : Apple Business Chat (Messages) Type : texte Status : connecteur Tock utilis\u00e9 en production depuis 2019 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-businesschat sur GitHub. Twitter \u00b6 Canal : Twitter (messages priv\u00e9s) Type : texte Status : connecteur Tock en d\u00e9veloppement Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-twitter sur GitHub. Web \u00b6 Work in progress Test \u00b6 Ce connecteur est interne \u00e0 Tock, il sert \u00e0 dialoguer avec un bot directement dans l'interface Tock Studio (vue Test > Test the bot ). Architecture & gouvernance des mod\u00e8les et donn\u00e9es \u00b6 Dans une optique de gouvernance des mod\u00e8les et donn\u00e9es conversationnelles, l'architecture en connecteurs Tock pr\u00e9sente plusieurs avantages : Le mod\u00e8le est construit dans Tock, il n'est pas partag\u00e9 via les connecteurs Le choix des connecteurs d'un bot permet de maitriser la propagation (ou non) des conversations Par exemple, pour un bot interne \u00e0 une entreprise, on peut choisir de n'utiliser que des connecteurs vers des canaux propres (site Web, etc.) ou internes \u00e0 l'entreprise (applications d'entreprise, espace pro sur un t\u00e9l\u00e9phone Android, etc.). M\u00eame si un bot est connect\u00e9 \u00e0 plusieurs canaux/partenaires externes, seule la plateforme Tock poss\u00e8de l'ensemble des conversations sur tous ces canaux. D\u00e9velopper son propre connecteur \u00b6 Il est possible de cr\u00e9er son propre connecteur Tock, par exemple pour interfacer un bot Tock avec un canal propre \u00e0 l'organisation (souvent un site Web ou une application mobile sp\u00e9cifiques), ou bien quand un canal grand public s'ouvre aux bots conversationnels et que le connecteur Tock n'existe pas encore. La section Bot Framework du manuel d\u00e9veloppeur Tock donne des indications pour impl\u00e9menter son propre connecteur.","title":"Multichannel bot"},{"location":"utilisateur/channels/#construire-un-bot-multicanal-avec-tock","text":"","title":"Construire un bot multicanal avec Tock"},{"location":"utilisateur/channels/#notion-de-connecteur","text":"Un connecteur Tock permet d'int\u00e9grer un bot \u00e0 un canal de communication textuel ou vocal externe. Mis \u00e0 part le type connecteur de test , d\u00e9di\u00e9 aux tests via l'interface Tock Studio , les connecteurs sont associ\u00e9s \u00e0 des canaux externes \u00e0 la plateforme Tock. Tout l'int\u00e9r\u00eat des connecteurs Tock r\u00e9side dans la possibilit\u00e9 de d\u00e9velopper des assistants conversationnels ind\u00e9pendamment du ou des canaux utilis\u00e9s pour lui parler. Il est ainsi possible de cr\u00e9er un bot pour un canal, puis le rendre multicanal par la suite en ajoutant des connecteurs.","title":"Notion de connecteur"},{"location":"utilisateur/channels/#connecteurs-fournis-avec-tock","text":"Tock fournit de nombreux connecteurs pour diff\u00e9rents types de canaux (voir ci-dessous). De nouveaux connecteurs sont r\u00e9guli\u00e8rement ajout\u00e9s \u00e0 la plateforme, en fonction des besoins projets mais aussi du calendrier d'ouverture aux bots des canaux grand public. Exemples : arriv\u00e9e de Google Home en France en 2017, Alexa en 2018, ouverture des API WhatsApp puis Business Chat en 2019, etc.","title":"Connecteurs fournis avec Tock"},{"location":"utilisateur/channels/#messenger","text":"Canal : Facebook Messenger Type : texte (+ voix via l'upload de messages vocaux) Status : connecteur Tock utilis\u00e9 en production depuis 2016 Le guide Connecter son bot \u00e0 Messenger explique comment int\u00e9grer un bot Tock avec une page Facebook / Messenger . Pour en savoir plus sur ce connecteur, vous pouvez aussi vous rendre dans le dossier connector-messenger sur GitHub, o\u00f9 vous retrouverez les sources et le README du connecteur.","title":"Messenger"},{"location":"utilisateur/channels/#slack","text":"Canal : Slack Type : texte Status : connecteur Tock utilis\u00e9 hors production Le guide Connecter son bot \u00e0 Slack explique comment int\u00e9grer un bot Tock avec une cha\u00eene Slack . Pour en savoir plus sur ce connecteur, vous pouvez aussi vous rendre dans le dossier connector-slack sur GitHub, o\u00f9 vous retrouverez les sources et le README du connecteur.","title":"Slack"},{"location":"utilisateur/channels/#google-assistant-google-home","text":"Canal : Google Assistant / Google Home Type : texte + voix Status : connecteur Tock utilis\u00e9 en production depuis 2017 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-ga sur GitHub.","title":"Google Assistant / Google Home"},{"location":"utilisateur/channels/#alexa-echo","text":"Canal : Amazon Alexa Type : voix Status : connecteur Tock utilis\u00e9 en production depuis 2018 Remarque importante : dans le cas d'Alexa, le mod\u00e8le NLP est forc\u00e9ment construit et h\u00e9berg\u00e9 chez Amazon. Seul la partie framework conversationel de Tock peut \u00eatre utilis\u00e9e. Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-alexa sur GitHub.","title":"Alexa / Echo"},{"location":"utilisateur/channels/#rocketchat","text":"Canal : Rocket.Chat Type : texte Status : \u00e0 pr\u00e9ciser Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-rocketchat sur GitHub.","title":"Rocket.Chat"},{"location":"utilisateur/channels/#whatsapp","text":"Canal : WhatsApp from Facebook Type : texte Status : connecteur Tock utilis\u00e9 en production depuis 2019 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-whatsapp sur GitHub.","title":"WhatsApp"},{"location":"utilisateur/channels/#teams","text":"Canal : Microsoft Teams Type : texte + voix Status : connecteur Tock utilis\u00e9 en production depuis 2019 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-teams sur GitHub.","title":"Teams"},{"location":"utilisateur/channels/#business-chat-messages","text":"Canal : Apple Business Chat (Messages) Type : texte Status : connecteur Tock utilis\u00e9 en production depuis 2019 Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-businesschat sur GitHub.","title":"Business Chat / Messages"},{"location":"utilisateur/channels/#twitter","text":"Canal : Twitter (messages priv\u00e9s) Type : texte Status : connecteur Tock en d\u00e9veloppement Pour en savoir plus sur ce connecteur, voir ses sources et son README dans le dossier connector-twitter sur GitHub.","title":"Twitter"},{"location":"utilisateur/channels/#web","text":"Work in progress","title":"Web"},{"location":"utilisateur/channels/#test","text":"Ce connecteur est interne \u00e0 Tock, il sert \u00e0 dialoguer avec un bot directement dans l'interface Tock Studio (vue Test > Test the bot ).","title":"Test"},{"location":"utilisateur/channels/#architecture-gouvernance-des-modeles-et-donnees","text":"Dans une optique de gouvernance des mod\u00e8les et donn\u00e9es conversationnelles, l'architecture en connecteurs Tock pr\u00e9sente plusieurs avantages : Le mod\u00e8le est construit dans Tock, il n'est pas partag\u00e9 via les connecteurs Le choix des connecteurs d'un bot permet de maitriser la propagation (ou non) des conversations Par exemple, pour un bot interne \u00e0 une entreprise, on peut choisir de n'utiliser que des connecteurs vers des canaux propres (site Web, etc.) ou internes \u00e0 l'entreprise (applications d'entreprise, espace pro sur un t\u00e9l\u00e9phone Android, etc.). M\u00eame si un bot est connect\u00e9 \u00e0 plusieurs canaux/partenaires externes, seule la plateforme Tock poss\u00e8de l'ensemble des conversations sur tous ces canaux.","title":"Architecture &amp; gouvernance des mod\u00e8les et donn\u00e9es"},{"location":"utilisateur/channels/#developper-son-propre-connecteur","text":"Il est possible de cr\u00e9er son propre connecteur Tock, par exemple pour interfacer un bot Tock avec un canal propre \u00e0 l'organisation (souvent un site Web ou une application mobile sp\u00e9cifiques), ou bien quand un canal grand public s'ouvre aux bots conversationnels et que le connecteur Tock n'existe pas encore. La section Bot Framework du manuel d\u00e9veloppeur Tock donne des indications pour impl\u00e9menter son propre connecteur.","title":"D\u00e9velopper son propre connecteur"},{"location":"utilisateur/concepts/","text":"Concepts conversationnels pour Tock \u00b6 Cette page pr\u00e9sente et vulgarise les principaux concepts et la terminologie conversationnelle utilis\u00e9e dans Tock et sa documentation. Un tableau propose \u00e9galement des \u00e9quivalences et termes similaires dans d'autres solutions conversationnelles. Notions conversationnelles pour Tock \u00b6 Intentions \u00b6 TODO Entit\u00e9s \u00b6 TODO Actions \u00b6 TODO Messages et phrases (ou sentences ) \u00b6 TODO Parcours (ou stories ) \u00b6 Un parcours ou story est un regroupement fonctionnel qui correspond \u00e0 une intention principale et, de mani\u00e8re optionelle, \u00e0 une ou plusieurs intentions dites \"secondaires\". TODO Connecteur \u00b6 TODO Mod\u00e8le \u00b6 TODO Application \u00b6 TODO Termes & correspondances \u00b6 Le tableau ci-dessous propose des correspondances entre les termes utilis\u00e9s dans Tock et ceux d'autres solutions conversationnelles : Tock DialogFlow Alexa Watson Intent Intent Intent Entity Entity Action Message Sentence Query Utterance / Slot Story Connector Integration Model Dialog model Application Project / Agent Skill La documentation des connecteurs Tock donne \u00e9galement la correspondance avec d'autres termes propres \u00e0 tel ou tel canal. Continuer... \u00b6 Vous pouvez maintenant entamer le chapitre suivant : Interfaces Tock Studio .","title":"Concepts"},{"location":"utilisateur/concepts/#concepts-conversationnels-pour-tock","text":"Cette page pr\u00e9sente et vulgarise les principaux concepts et la terminologie conversationnelle utilis\u00e9e dans Tock et sa documentation. Un tableau propose \u00e9galement des \u00e9quivalences et termes similaires dans d'autres solutions conversationnelles.","title":"Concepts conversationnels pour Tock"},{"location":"utilisateur/concepts/#notions-conversationnelles-pour-tock","text":"","title":"Notions conversationnelles pour Tock"},{"location":"utilisateur/concepts/#intentions","text":"TODO","title":"Intentions"},{"location":"utilisateur/concepts/#entites","text":"TODO","title":"Entit\u00e9s"},{"location":"utilisateur/concepts/#actions","text":"TODO","title":"Actions"},{"location":"utilisateur/concepts/#messages-et-phrases-ou-sentences","text":"TODO","title":"Messages et phrases (ou sentences)"},{"location":"utilisateur/concepts/#parcours-ou-stories","text":"Un parcours ou story est un regroupement fonctionnel qui correspond \u00e0 une intention principale et, de mani\u00e8re optionelle, \u00e0 une ou plusieurs intentions dites \"secondaires\". TODO","title":"Parcours (ou stories)"},{"location":"utilisateur/concepts/#connecteur","text":"TODO","title":"Connecteur"},{"location":"utilisateur/concepts/#modele","text":"TODO","title":"Mod\u00e8le"},{"location":"utilisateur/concepts/#application","text":"TODO","title":"Application"},{"location":"utilisateur/concepts/#termes-correspondances","text":"Le tableau ci-dessous propose des correspondances entre les termes utilis\u00e9s dans Tock et ceux d'autres solutions conversationnelles : Tock DialogFlow Alexa Watson Intent Intent Intent Entity Entity Action Message Sentence Query Utterance / Slot Story Connector Integration Model Dialog model Application Project / Agent Skill La documentation des connecteurs Tock donne \u00e9galement la correspondance avec d'autres termes propres \u00e0 tel ou tel canal.","title":"Termes &amp; correspondances"},{"location":"utilisateur/concepts/#continuer","text":"Vous pouvez maintenant entamer le chapitre suivant : Interfaces Tock Studio .","title":"Continuer..."},{"location":"utilisateur/i18n/","text":"Construire un bot multilingue avec Tock \u00b6 L'interface Tock Studio permet de traduire et moduler les r\u00e9ponses d'un bot en fonction de la langue mais aussi du canal utilis\u00e9s. Pr\u00e9-requis \u00b6 Tock met \u00e0 disposition un framework complet d'internationalisation. Il est activ\u00e9 par d\u00e9faut en mode Bot API (par exemple sur la plateforme de d\u00e9monstration ). Dans le mode Bot int\u00e9gr\u00e9 (voir le manuel d\u00e9veloppeur ), l'internationalisation est d\u00e9sactiv\u00e9e par d\u00e9faut. Pour l'activer, il est alors n\u00e9cessaire de configurer la plateforme \u00e0 son d\u00e9marrage : Soit via le code de d\u00e9marrage du bot (d\u00e9veloppeur) : Translator . enabled = true Soit avec une propri\u00e9t\u00e9 Syst\u00e8me (administrateur) en passant -Dtock_i18n_enabled=true au d\u00e9marrage de la JVM Activer plusieurs langues pour un bot \u00b6 Il est possible d'ajouter et de g\u00e9rer les langues actives pour un bot dans la section NLU Applications (dans Tock Studio ). Voir Le menu Configuration . A tout moment dans Tock Studio , il est possible de changer la langue s\u00e9lectionn\u00e9e dans la banni\u00e8re en haut de page, notamment pour dialoguer avec un bot dans l'interface Test the bot . Voir Interface g\u00e9n\u00e9rale . Langue et locale utilisateur \u00b6 Quand c'est possible, la locale de l'utilisateur (langue / r\u00e9gion) est import\u00e9e de celle de son compte. Par exemple, si le compte d'un utilisateur Messenger est configur\u00e9 en Fran\u00e7ais, le Fran\u00e7ais sera automatiquement s\u00e9lectionn\u00e9 par Tock. S'il n'y a pas d'indication de locale, c'est la locale par d\u00e9faut de Tock qui est utilis\u00e9e. Un d\u00e9veloppeur peut modifier la locale de l'utilisateur dans le code du bot lui-m\u00eame : userPreferences . locale = Locale . FRENCH Enfin, la locale par d\u00e9faut peut \u00eatre modifi\u00e9e par un administrateur de la plateforme, en passant la propri\u00e9t\u00e9 Syst\u00e8me -Dtock_default_locale=fr au d\u00e9marrage de la JVM. Traduire et faire varier les r\u00e9ponses du bot \u00b6 Dans Tock Studio , la section Build > i18n permet de g\u00e9rer les libell\u00e9s des r\u00e9ponses du bot. Voir Le menu Build . Chaque libell\u00e9 a une valeur par d\u00e9faut pour chaque langue du bot. Il est possible de concevoir et configurer diff\u00e9rentes variantes : En fonction de la langue En fonction du canal / connecteur Par exemple, certains canaux requi\u00e8rent des libell\u00e9s sp\u00e9cifiques, soit parce que le propri\u00e9taire du canal l'exige (sur Alexa le vouvoiement est requis), soit parce que l'exp\u00e9rience utilisateur diff\u00e8re des autres canaux (par exemple en vocal on \u00e9vitera de trop longues phrases). Al\u00e9atoirement (pour que le bot ne r\u00e9ponde pas toujours la m\u00eame chose) Traduire massivement les mod\u00e8les et r\u00e9ponses \u00b6 Des fonctionnalit\u00e9s sont \u00e0 l'\u00e9tude pour permettre la traduction plus ou moins automatis\u00e9e de nombreuses phrases utilisateur (corpus / mod\u00e8le conversationnel) et r\u00e9ponses (libell\u00e9s / i18n). A suivre... Pour le moment, pour envisager une traduction de masse, on peut par exemple : Exporter les donn\u00e9es en JSON ou CSV avec Tock Studio Traduire les phrases/r\u00e9ponses en dehors de Tock (API SaaS, agence...) Importer les traductions avec Tock Studio Remarque : au moment de l'import seuls les libell\u00e9s marqu\u00e9s valid\u00e9s sont pris en compte. D\u00e9velopper avec l'internationalisation \u00b6 Le manuel d\u00e9veloppeur Tock donne plus de d\u00e9tails sur le d\u00e9veloppement des bots multilingues.","title":"Multilingual bot"},{"location":"utilisateur/i18n/#construire-un-bot-multilingue-avec-tock","text":"L'interface Tock Studio permet de traduire et moduler les r\u00e9ponses d'un bot en fonction de la langue mais aussi du canal utilis\u00e9s.","title":"Construire un bot multilingue avec Tock"},{"location":"utilisateur/i18n/#pre-requis","text":"Tock met \u00e0 disposition un framework complet d'internationalisation. Il est activ\u00e9 par d\u00e9faut en mode Bot API (par exemple sur la plateforme de d\u00e9monstration ). Dans le mode Bot int\u00e9gr\u00e9 (voir le manuel d\u00e9veloppeur ), l'internationalisation est d\u00e9sactiv\u00e9e par d\u00e9faut. Pour l'activer, il est alors n\u00e9cessaire de configurer la plateforme \u00e0 son d\u00e9marrage : Soit via le code de d\u00e9marrage du bot (d\u00e9veloppeur) : Translator . enabled = true Soit avec une propri\u00e9t\u00e9 Syst\u00e8me (administrateur) en passant -Dtock_i18n_enabled=true au d\u00e9marrage de la JVM","title":"Pr\u00e9-requis"},{"location":"utilisateur/i18n/#activer-plusieurs-langues-pour-un-bot","text":"Il est possible d'ajouter et de g\u00e9rer les langues actives pour un bot dans la section NLU Applications (dans Tock Studio ). Voir Le menu Configuration . A tout moment dans Tock Studio , il est possible de changer la langue s\u00e9lectionn\u00e9e dans la banni\u00e8re en haut de page, notamment pour dialoguer avec un bot dans l'interface Test the bot . Voir Interface g\u00e9n\u00e9rale .","title":"Activer plusieurs langues pour un bot"},{"location":"utilisateur/i18n/#langue-et-locale-utilisateur","text":"Quand c'est possible, la locale de l'utilisateur (langue / r\u00e9gion) est import\u00e9e de celle de son compte. Par exemple, si le compte d'un utilisateur Messenger est configur\u00e9 en Fran\u00e7ais, le Fran\u00e7ais sera automatiquement s\u00e9lectionn\u00e9 par Tock. S'il n'y a pas d'indication de locale, c'est la locale par d\u00e9faut de Tock qui est utilis\u00e9e. Un d\u00e9veloppeur peut modifier la locale de l'utilisateur dans le code du bot lui-m\u00eame : userPreferences . locale = Locale . FRENCH Enfin, la locale par d\u00e9faut peut \u00eatre modifi\u00e9e par un administrateur de la plateforme, en passant la propri\u00e9t\u00e9 Syst\u00e8me -Dtock_default_locale=fr au d\u00e9marrage de la JVM.","title":"Langue et locale utilisateur"},{"location":"utilisateur/i18n/#traduire-et-faire-varier-les-reponses-du-bot","text":"Dans Tock Studio , la section Build > i18n permet de g\u00e9rer les libell\u00e9s des r\u00e9ponses du bot. Voir Le menu Build . Chaque libell\u00e9 a une valeur par d\u00e9faut pour chaque langue du bot. Il est possible de concevoir et configurer diff\u00e9rentes variantes : En fonction de la langue En fonction du canal / connecteur Par exemple, certains canaux requi\u00e8rent des libell\u00e9s sp\u00e9cifiques, soit parce que le propri\u00e9taire du canal l'exige (sur Alexa le vouvoiement est requis), soit parce que l'exp\u00e9rience utilisateur diff\u00e8re des autres canaux (par exemple en vocal on \u00e9vitera de trop longues phrases). Al\u00e9atoirement (pour que le bot ne r\u00e9ponde pas toujours la m\u00eame chose)","title":"Traduire et faire varier les r\u00e9ponses du bot"},{"location":"utilisateur/i18n/#traduire-massivement-les-modeles-et-reponses","text":"Des fonctionnalit\u00e9s sont \u00e0 l'\u00e9tude pour permettre la traduction plus ou moins automatis\u00e9e de nombreuses phrases utilisateur (corpus / mod\u00e8le conversationnel) et r\u00e9ponses (libell\u00e9s / i18n). A suivre... Pour le moment, pour envisager une traduction de masse, on peut par exemple : Exporter les donn\u00e9es en JSON ou CSV avec Tock Studio Traduire les phrases/r\u00e9ponses en dehors de Tock (API SaaS, agence...) Importer les traductions avec Tock Studio Remarque : au moment de l'import seuls les libell\u00e9s marqu\u00e9s valid\u00e9s sont pris en compte.","title":"Traduire massivement les mod\u00e8les et r\u00e9ponses"},{"location":"utilisateur/i18n/#developper-avec-linternationalisation","text":"Le manuel d\u00e9veloppeur Tock donne plus de d\u00e9tails sur le d\u00e9veloppement des bots multilingues.","title":"D\u00e9velopper avec l'internationalisation"},{"location":"utilisateur/studio/","text":"Les interfaces Tock Studio \u00b6 Tock Studio regroupe l'ensemble des interfaces utilisateur, techniques et m\u00e9tier, permettant de concevoir les mod\u00e8les conversationnels, cr\u00e9er des parcours et des r\u00e9ponses, suivre les conversations, analyser les tendances, etc. Dans cette section, vous trouverez la description de chaque vue mais aussi des pages d\u00e9di\u00e9es \u00e0 des th\u00e8mes ou des fonctionnalit\u00e9s particuli\u00e8res : Les interfaces de Tock Studio : Interface g\u00e9n\u00e9rale Le menu Configuration Le menu NLU Le menu NLU QA Le menu Build Le menu Test Le menu Monitoring Voir aussi : Construire un mod\u00e8le conversationnel Cr\u00e9er un bot multicanal (connecteurs) Cr\u00e9er un bot multilingue (internationalisation) Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Tock Studio"},{"location":"utilisateur/studio/#les-interfaces-tock-studio","text":"Tock Studio regroupe l'ensemble des interfaces utilisateur, techniques et m\u00e9tier, permettant de concevoir les mod\u00e8les conversationnels, cr\u00e9er des parcours et des r\u00e9ponses, suivre les conversations, analyser les tendances, etc. Dans cette section, vous trouverez la description de chaque vue mais aussi des pages d\u00e9di\u00e9es \u00e0 des th\u00e8mes ou des fonctionnalit\u00e9s particuli\u00e8res : Les interfaces de Tock Studio : Interface g\u00e9n\u00e9rale Le menu Configuration Le menu NLU Le menu NLU QA Le menu Build Le menu Test Le menu Monitoring Voir aussi : Construire un mod\u00e8le conversationnel Cr\u00e9er un bot multicanal (connecteurs) Cr\u00e9er un bot multilingue (internationalisation) Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Les interfaces Tock Studio"},{"location":"utilisateur/studio/build-model/","text":"Construire les mod\u00e8les conversationnels \u00b6 La documentation Tock Studio peut \u00eatre parcourue \u00e9cran par \u00e9cran, notamment les menus NLU et NLU QA pour la gestion des mod\u00e8les conversationnels. N'h\u00e9sitez pas \u00e0 vous y r\u00e9f\u00e9rer si vous avez une question sur un onglet / une option en particulier. Cette page pr\u00e9sente la construction des mod\u00e8les en se focalisant plus sur l'usage et l'apprentissage, s'autorisant \u00e0 passer d'un \u00e9cran \u00e0 un autre sans d\u00e9tailler exhaustivement chaque fonctionnalit\u00e9 de la plateforme. Notez qu'il est possible de d\u00e9ployer la plateforme Tock NLU seule, dans ce cas les interfaces graphiques Tock se limitent aux menus Configuration , NLU et NLU QA . Cette page peut donc servir de tutoriel pour une utilisation de Tock restreinte au NLU , par exemple pour un usage comme l' Internet des objets . Rendez-vous dans la section NLU \u00b6 Le menu NLU renvoie sur l'onglet Inbox par d\u00e9faut. Au d\u00e9part vous n'avez pas de phrases si personne n'a encore parl\u00e9 au bot : Ajoutez et qualifiez des phrases \u00b6 Ajoutez une phrase \u00b6 Rendez-vous dans l'\u00e9cran Try it Saisissez une phrase Cr\u00e9ez une nouvelle intention \u00b6 Attribuez \u00e0 la phrase une nouvelle intention en s\u00e9lectionnant Create a New Intent dans la liste de s\u00e9lection Intent . Sp\u00e9cifiez des entit\u00e9s \u00b6 Selon ce \u00e0 quoi est destin\u00e9e l'intention, vous pouvez sp\u00e9cifier les entit\u00e9s que vous souhaitez que votre mod\u00e8le reconnaisse dans la phrase : S\u00e9lectionnez une portion de phrase correspondant \u00e0 l'entit\u00e9 (ie. un groupe de mots \u00e0 s\u00e9lectionner avec la souris) Cliquez sur Add New Entity qui vient d'appara\u00eetre Choisissez un type d'entit\u00e9 existant ou cr\u00e9ez-en un nouveau Donnez un r\u00f4le \u00e0 cette entit\u00e9 Exemple : dans la phrase \"je veux aller de Paris \u00e0 New York\", probablement que Paris et New York sont deux entit\u00e9s du m\u00eame type (localit\u00e9) mais n'ont pas le m\u00eame r\u00f4le dans l'intention (origine et destination). Il est bien s\u00fbr possible d'avoir plusieurs occurrences du m\u00eame role, ou d'un r\u00f4le diff\u00e9rent dans la m\u00eame phrase. Tirez parti des entit\u00e9s pr\u00e9d\u00e9finies \u00b6 Par d\u00e9faut, Tock propose un certain nombre de types d' entit\u00e9s pr\u00e9d\u00e9finies , notamment les types support\u00e9s par la biblioth\u00e8que Duckling : montants, dates, etc. Si vous s\u00e9lectionnez ces types d'entit\u00e9s, celles-ci seront automatiquement reconnues et valoris\u00e9es. Validez la phrase \u00b6 Lorsque l'intention et les entit\u00e9s sont correctes, terminez la qualification de la phrase en cliquant sur Validate . Qualifiez d'autres phrases \u00b6 Apr\u00e8s deux ou trois phrases pour une intention donn\u00e9e, il est courant que le mod\u00e8le commence \u00e0 reconna\u00eetre les phrases suivantes et d\u00e9tectent bien l'intention (avec un score grandissant, du moment que les phrases sont relativement proches / en rapport avec l'intention bien s\u00fbr) : Si une phrase n'est pas bien qualifi\u00e9e, changez l'intention / les entit\u00e9s puis faites Validate pour appliquer la correction. Si la phrase \u00e9tait bien qualifi\u00e9e, faites directement Validate . Dans les deux cas, vous alimentez ainsi le mod\u00e8le, qui se reconstruit, et devient plus pertinent pour les pharses suivantes. Vous \u00eates en train de construire votre mod\u00e8le conversationnel ! C'est le d\u00e9but de l' apprentissage pour votre bot ou votre application conversationnelle. La qualification de phrases, leur nombre mais aussi leur vari\u00e9t\u00e9 (notamment dans le temps, car les utilisateurs d'aujourd'hui ne sont pas exactement les utilisateurs de demain) sont la base d'un mod\u00e8le pertinent et d'une bonne exp\u00e9rience conversationnelle pour les utilisateurs. Parcourez les phrases du mod\u00e8le \u00b6 L'onglet Search permet de parcourir l'ensemble des phrases du mod\u00e8le en utilisant un certain nombre de crit\u00e8res. Le plus utilis\u00e9 est la recherche texte simple pour lequel il est \u00e9galement possible d'utiliser des expressions r\u00e9guli\u00e8res. Chaque phrase \u00e0 un \u00e9tat Status qui peut \u00e9voluer au cours du temps : Inbox : La phrase n'a pas encore \u00e9t\u00e9 qualifi\u00e9e et ne fait pas partie du mod\u00e8le Validated : La phrase a \u00e9t\u00e9 valid\u00e9e mais n'est pas encore pris en compte dans les mod\u00e8les de NLP (cela peut prendre du temps dans le cas de mod\u00e8les de taille importante) Included in model : La phrase a \u00e9t\u00e9 valid\u00e9e et a \u00e9t\u00e9 prise en compte dans les mod\u00e8les de NLP Cet \u00e9cran permet donc de consulter les phrases faisant d\u00e9j\u00e0 partie du mod\u00e8le (autrement dit d\u00e9j\u00e0 qualifi\u00e9s), et de faire \u00e9voluer les qualifications de phrases au cours du temps. Il est notamment possible de re-qualifier tout un groupe de phrases. Par exemple, vous pourrez cr\u00e9er une nouvelle intention plus tard et d\u00e9cider que toutes les phrases remplissant un certain crit\u00e8re (mot-clef ou autre) devront dor\u00e9navant \u00eatre qualifi\u00e9es dans cette nouvelle intention. Modifiez les caract\u00e9ristiques avanc\u00e9es de l'application \u00b6 Le menu Applications donne acc\u00e8s \u00e0 la liste des applications/bots disponibles sur la plateforme : Avec le bouton de modification, plusieurs options sont disponibles, en particulier : La s\u00e9lection du moteur NLU \u00b6 Vous avez la possibilit\u00e9 de s\u00e9lectionner la biblioth\u00e8que NLU utilis\u00e9e par ce bot (\u00e0 condition que plusieurs moteurs soient pr\u00e9sents dans l'installation de la plateforme). L'activation des mod\u00e8les d'entit\u00e9s \u00b6 Cette option permet de r\u00e9utiliser des mod\u00e8les d'entit\u00e9s pr\u00e9-construits dans vos nouvelles intentions. Par exemple, si vous cr\u00e9ez une intention avec une entit\u00e9 duckling:datetime , les dates seront automatiquement reconnues pour cette intention dans tous les nouvelles phrases attribu\u00e9es \u00e0 cette intention. En interne, un arbitrage est effectu\u00e9 entre les informations provenant des mod\u00e8les d'entit\u00e9s pr\u00e9-construits et les informations tir\u00e9es de votre propre mod\u00e8le. Cette option est activ\u00e9e par d\u00e9faut. Il peut \u00eatre utile de la d\u00e9sactiver pour les mod\u00e8les de taille tr\u00e8s importante, pour lesquels la d\u00e9tection native sera sup\u00e9rieure dans quasiment tous les cas \u00e0 celle des mod\u00e8les d'entit\u00e9s. L'activation des sous-entit\u00e9s \u00b6 Si vous activez cette option, vous pourrez qualifier plusieurs niveaux d'entit\u00e9s : Le nombre de niveaux n'est pas limit\u00e9, mais il est conseill\u00e9 de ne pas en sp\u00e9cifier plus de 3 ou 4. Valeurs pr\u00e9definies d'entit\u00e9s \u00b6 Une entit\u00e9 donn\u00e9e peut avoir des valeurs pr\u00e9d\u00e9finies . Pour cela vous devez aller dans l'onglet Entities , selectionnez une entit\u00e9. L'ic\u00f4ne \u00e0 cot\u00e9 de l'ic\u00f4ne de suppression montre les types d'entit\u00e9s que vous pouvez modifier : Dans l'exemple ci-dessus, deux labels sont d\u00e9finis pour la valeur de semaine : Semaine hebdomadaire Continuer... \u00b6 Pour en savoir plus sur la gestion des entit\u00e9s, notamment dans des intentions cr\u00e9\u00e9es programmatiquement, out tout simplement pour continuer de parcourir le manuel utilisateur Tock, vous pouvez vous rendre dans le chapitre D\u00e9veloppement .","title":"Construire les mod\u00e8les conversationnels"},{"location":"utilisateur/studio/build-model/#construire-les-modeles-conversationnels","text":"La documentation Tock Studio peut \u00eatre parcourue \u00e9cran par \u00e9cran, notamment les menus NLU et NLU QA pour la gestion des mod\u00e8les conversationnels. N'h\u00e9sitez pas \u00e0 vous y r\u00e9f\u00e9rer si vous avez une question sur un onglet / une option en particulier. Cette page pr\u00e9sente la construction des mod\u00e8les en se focalisant plus sur l'usage et l'apprentissage, s'autorisant \u00e0 passer d'un \u00e9cran \u00e0 un autre sans d\u00e9tailler exhaustivement chaque fonctionnalit\u00e9 de la plateforme. Notez qu'il est possible de d\u00e9ployer la plateforme Tock NLU seule, dans ce cas les interfaces graphiques Tock se limitent aux menus Configuration , NLU et NLU QA . Cette page peut donc servir de tutoriel pour une utilisation de Tock restreinte au NLU , par exemple pour un usage comme l' Internet des objets .","title":"Construire les mod\u00e8les conversationnels"},{"location":"utilisateur/studio/build-model/#rendez-vous-dans-la-section-nlu","text":"Le menu NLU renvoie sur l'onglet Inbox par d\u00e9faut. Au d\u00e9part vous n'avez pas de phrases si personne n'a encore parl\u00e9 au bot :","title":"Rendez-vous dans la section NLU"},{"location":"utilisateur/studio/build-model/#ajoutez-et-qualifiez-des-phrases","text":"","title":"Ajoutez et qualifiez des phrases"},{"location":"utilisateur/studio/build-model/#ajoutez-une-phrase","text":"Rendez-vous dans l'\u00e9cran Try it Saisissez une phrase","title":"Ajoutez une phrase"},{"location":"utilisateur/studio/build-model/#creez-une-nouvelle-intention","text":"Attribuez \u00e0 la phrase une nouvelle intention en s\u00e9lectionnant Create a New Intent dans la liste de s\u00e9lection Intent .","title":"Cr\u00e9ez une nouvelle intention"},{"location":"utilisateur/studio/build-model/#specifiez-des-entites","text":"Selon ce \u00e0 quoi est destin\u00e9e l'intention, vous pouvez sp\u00e9cifier les entit\u00e9s que vous souhaitez que votre mod\u00e8le reconnaisse dans la phrase : S\u00e9lectionnez une portion de phrase correspondant \u00e0 l'entit\u00e9 (ie. un groupe de mots \u00e0 s\u00e9lectionner avec la souris) Cliquez sur Add New Entity qui vient d'appara\u00eetre Choisissez un type d'entit\u00e9 existant ou cr\u00e9ez-en un nouveau Donnez un r\u00f4le \u00e0 cette entit\u00e9 Exemple : dans la phrase \"je veux aller de Paris \u00e0 New York\", probablement que Paris et New York sont deux entit\u00e9s du m\u00eame type (localit\u00e9) mais n'ont pas le m\u00eame r\u00f4le dans l'intention (origine et destination). Il est bien s\u00fbr possible d'avoir plusieurs occurrences du m\u00eame role, ou d'un r\u00f4le diff\u00e9rent dans la m\u00eame phrase.","title":"Sp\u00e9cifiez des entit\u00e9s"},{"location":"utilisateur/studio/build-model/#tirez-parti-des-entites-predefinies","text":"Par d\u00e9faut, Tock propose un certain nombre de types d' entit\u00e9s pr\u00e9d\u00e9finies , notamment les types support\u00e9s par la biblioth\u00e8que Duckling : montants, dates, etc. Si vous s\u00e9lectionnez ces types d'entit\u00e9s, celles-ci seront automatiquement reconnues et valoris\u00e9es.","title":"Tirez parti des entit\u00e9s pr\u00e9d\u00e9finies"},{"location":"utilisateur/studio/build-model/#validez-la-phrase","text":"Lorsque l'intention et les entit\u00e9s sont correctes, terminez la qualification de la phrase en cliquant sur Validate .","title":"Validez la phrase"},{"location":"utilisateur/studio/build-model/#qualifiez-dautres-phrases","text":"Apr\u00e8s deux ou trois phrases pour une intention donn\u00e9e, il est courant que le mod\u00e8le commence \u00e0 reconna\u00eetre les phrases suivantes et d\u00e9tectent bien l'intention (avec un score grandissant, du moment que les phrases sont relativement proches / en rapport avec l'intention bien s\u00fbr) : Si une phrase n'est pas bien qualifi\u00e9e, changez l'intention / les entit\u00e9s puis faites Validate pour appliquer la correction. Si la phrase \u00e9tait bien qualifi\u00e9e, faites directement Validate . Dans les deux cas, vous alimentez ainsi le mod\u00e8le, qui se reconstruit, et devient plus pertinent pour les pharses suivantes. Vous \u00eates en train de construire votre mod\u00e8le conversationnel ! C'est le d\u00e9but de l' apprentissage pour votre bot ou votre application conversationnelle. La qualification de phrases, leur nombre mais aussi leur vari\u00e9t\u00e9 (notamment dans le temps, car les utilisateurs d'aujourd'hui ne sont pas exactement les utilisateurs de demain) sont la base d'un mod\u00e8le pertinent et d'une bonne exp\u00e9rience conversationnelle pour les utilisateurs.","title":"Qualifiez d'autres phrases"},{"location":"utilisateur/studio/build-model/#parcourez-les-phrases-du-modele","text":"L'onglet Search permet de parcourir l'ensemble des phrases du mod\u00e8le en utilisant un certain nombre de crit\u00e8res. Le plus utilis\u00e9 est la recherche texte simple pour lequel il est \u00e9galement possible d'utiliser des expressions r\u00e9guli\u00e8res. Chaque phrase \u00e0 un \u00e9tat Status qui peut \u00e9voluer au cours du temps : Inbox : La phrase n'a pas encore \u00e9t\u00e9 qualifi\u00e9e et ne fait pas partie du mod\u00e8le Validated : La phrase a \u00e9t\u00e9 valid\u00e9e mais n'est pas encore pris en compte dans les mod\u00e8les de NLP (cela peut prendre du temps dans le cas de mod\u00e8les de taille importante) Included in model : La phrase a \u00e9t\u00e9 valid\u00e9e et a \u00e9t\u00e9 prise en compte dans les mod\u00e8les de NLP Cet \u00e9cran permet donc de consulter les phrases faisant d\u00e9j\u00e0 partie du mod\u00e8le (autrement dit d\u00e9j\u00e0 qualifi\u00e9s), et de faire \u00e9voluer les qualifications de phrases au cours du temps. Il est notamment possible de re-qualifier tout un groupe de phrases. Par exemple, vous pourrez cr\u00e9er une nouvelle intention plus tard et d\u00e9cider que toutes les phrases remplissant un certain crit\u00e8re (mot-clef ou autre) devront dor\u00e9navant \u00eatre qualifi\u00e9es dans cette nouvelle intention.","title":"Parcourez les phrases du mod\u00e8le"},{"location":"utilisateur/studio/build-model/#modifiez-les-caracteristiques-avancees-de-lapplication","text":"Le menu Applications donne acc\u00e8s \u00e0 la liste des applications/bots disponibles sur la plateforme : Avec le bouton de modification, plusieurs options sont disponibles, en particulier :","title":"Modifiez les caract\u00e9ristiques avanc\u00e9es de l'application"},{"location":"utilisateur/studio/build-model/#la-selection-du-moteur-nlu","text":"Vous avez la possibilit\u00e9 de s\u00e9lectionner la biblioth\u00e8que NLU utilis\u00e9e par ce bot (\u00e0 condition que plusieurs moteurs soient pr\u00e9sents dans l'installation de la plateforme).","title":"La s\u00e9lection du moteur NLU"},{"location":"utilisateur/studio/build-model/#lactivation-des-modeles-dentites","text":"Cette option permet de r\u00e9utiliser des mod\u00e8les d'entit\u00e9s pr\u00e9-construits dans vos nouvelles intentions. Par exemple, si vous cr\u00e9ez une intention avec une entit\u00e9 duckling:datetime , les dates seront automatiquement reconnues pour cette intention dans tous les nouvelles phrases attribu\u00e9es \u00e0 cette intention. En interne, un arbitrage est effectu\u00e9 entre les informations provenant des mod\u00e8les d'entit\u00e9s pr\u00e9-construits et les informations tir\u00e9es de votre propre mod\u00e8le. Cette option est activ\u00e9e par d\u00e9faut. Il peut \u00eatre utile de la d\u00e9sactiver pour les mod\u00e8les de taille tr\u00e8s importante, pour lesquels la d\u00e9tection native sera sup\u00e9rieure dans quasiment tous les cas \u00e0 celle des mod\u00e8les d'entit\u00e9s.","title":"L'activation des mod\u00e8les d'entit\u00e9s"},{"location":"utilisateur/studio/build-model/#lactivation-des-sous-entites","text":"Si vous activez cette option, vous pourrez qualifier plusieurs niveaux d'entit\u00e9s : Le nombre de niveaux n'est pas limit\u00e9, mais il est conseill\u00e9 de ne pas en sp\u00e9cifier plus de 3 ou 4.","title":"L'activation des sous-entit\u00e9s"},{"location":"utilisateur/studio/build-model/#valeurs-predefinies-dentites","text":"Une entit\u00e9 donn\u00e9e peut avoir des valeurs pr\u00e9d\u00e9finies . Pour cela vous devez aller dans l'onglet Entities , selectionnez une entit\u00e9. L'ic\u00f4ne \u00e0 cot\u00e9 de l'ic\u00f4ne de suppression montre les types d'entit\u00e9s que vous pouvez modifier : Dans l'exemple ci-dessus, deux labels sont d\u00e9finis pour la valeur de semaine : Semaine hebdomadaire","title":"Valeurs pr\u00e9definies d'entit\u00e9s"},{"location":"utilisateur/studio/build-model/#continuer","text":"Pour en savoir plus sur la gestion des entit\u00e9s, notamment dans des intentions cr\u00e9\u00e9es programmatiquement, out tout simplement pour continuer de parcourir le manuel utilisateur Tock, vous pouvez vous rendre dans le chapitre D\u00e9veloppement .","title":"Continuer..."},{"location":"utilisateur/studio/build/","text":"Le menu Build \u00b6 Le menu Build permet de construire des parcours et des r\u00e9ponses aux phrases utilisateur. Dans cette page, le d\u00e9tail de chaque onglet est pr\u00e9sent\u00e9. Voir aussi Cr\u00e9er son premier bot avec Tock Studio pour un exemple de cr\u00e9ation de parcours ou Construire un bot multilingue pour l'utilisation de l'onglet i18n . L'onglet New Story \u00b6 Cr\u00e9er une r\u00e9ponse simple \u00b6 Le guide Cr\u00e9er son premier bot avec Tock Studio pr\u00e9sente un exemple de cr\u00e9ation de parcours avec une r\u00e9ponse simple via New Story . L'onglet Test > Test the bot permet ensuite de rapidement v\u00e9rifier le comportement du bot sur ce parcours. Cr\u00e9er des r\u00e9ponses complexes \u00b6 Il est possible d'indiquer plusieurs r\u00e9ponses et \u00e9galement des r\u00e9ponses \"riches\" appel\u00e9es Media Message . Cela permet, quel que soit le canal d'afficher des images, des titres, des sous-titres et des boutons d'action. Entit\u00e9s obligatoires \u00b6 Il est possible, avant d'afficher la r\u00e9ponse principale, de v\u00e9rifier si certaines entit\u00e9es sont renseign\u00e9es, et si ce n'est pas le cas, d'afficher la question ad\u00e9quate. L'option correspondante est appell\u00e9e Mandatory Entities . Par exemple, supposons que nous ayons besoin de conna\u00eetre la destination de l'utilisateur. Si il ne l'a pas d\u00e9j\u00e0 indiqu\u00e9e, le bot devrait lui demander \"Pour quelle destination ?\". Actions \u00b6 Les actions sont pr\u00e9sent\u00e9es comme des suggestions, quand le canal le permet. Il est possible de pr\u00e9senter une arborescence d'actions pour construire un arbre de d\u00e9cision. L'onglet Search Stories \u00b6 Cette \u00e9cran permet de parcourir et g\u00e9rer les parcours ou stories cr\u00e9\u00e9es. Il peut s'agir des parcours configur\u00e9s via Tock Studio (ie. avec l'onglet New Story ) mais aussi les parcours d\u00e9clar\u00e9s programmatiquement via Bot API . Pour voir ces derniers, d\u00e9cochez l'option Only Configured Stories . L'onglet Bot Flow \u00b6 Cet \u00e9cran permet d'analyser le flot des intentions et des conversations : Flot des intentions : analyse statique des parcours et arbres de d\u00e9cisions propos\u00e9s par le bot Flot des conversations : analyse dynamique des parcours r\u00e9ellement effectu\u00e9s par les utilisateurs TODO : \u00e0 d\u00e9tailler L'onglet i18n \u00b6 Cet onglet permet de modifier les r\u00e9ponses du bot, dynamiquement selon plusieurs crit\u00e8res possibles : La langue (c'est ce qu'on appelle internationalisation ou i18n ) Le canal (textuel ou vocal), c'est-\u00e0-dire en pratique le connecteur Selon un roulement : il est possible d'enregistrer plusieurs textes de r\u00e9ponse pour un m\u00eame label dans une m\u00eame langue sur un m\u00eame connecteur - le bot r\u00e9pondra alors al\u00e9atoirement l'un de ces textes, puis effectuera un roulement afin de ne pas toujours r\u00e9pondre la m\u00eame chose. Cela permet de rendre le bot plus agr\u00e9able en variant ses r\u00e9ponses. Voir aussi Construire un bot multilingue pour l'utilisation de l'onglet i18n mais aussi les aspects d\u00e9veloppement sur ce th\u00e8me. L'onglet Feature Flipping \u00b6 Cet section permet de g\u00e9rer des fonctions activables ou d\u00e9sactivables via l'interface ( Feature Flipping ). TODO : \u00e0 d\u00e9tailler. Continuer... \u00b6 Rendez-vous dans Menu Test pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Le menu _Build_"},{"location":"utilisateur/studio/build/#le-menu-build","text":"Le menu Build permet de construire des parcours et des r\u00e9ponses aux phrases utilisateur. Dans cette page, le d\u00e9tail de chaque onglet est pr\u00e9sent\u00e9. Voir aussi Cr\u00e9er son premier bot avec Tock Studio pour un exemple de cr\u00e9ation de parcours ou Construire un bot multilingue pour l'utilisation de l'onglet i18n .","title":"Le menu Build"},{"location":"utilisateur/studio/build/#longlet-new-story","text":"","title":"L'onglet New Story"},{"location":"utilisateur/studio/build/#creer-une-reponse-simple","text":"Le guide Cr\u00e9er son premier bot avec Tock Studio pr\u00e9sente un exemple de cr\u00e9ation de parcours avec une r\u00e9ponse simple via New Story . L'onglet Test > Test the bot permet ensuite de rapidement v\u00e9rifier le comportement du bot sur ce parcours.","title":"Cr\u00e9er une r\u00e9ponse simple"},{"location":"utilisateur/studio/build/#creer-des-reponses-complexes","text":"Il est possible d'indiquer plusieurs r\u00e9ponses et \u00e9galement des r\u00e9ponses \"riches\" appel\u00e9es Media Message . Cela permet, quel que soit le canal d'afficher des images, des titres, des sous-titres et des boutons d'action.","title":"Cr\u00e9er des r\u00e9ponses complexes"},{"location":"utilisateur/studio/build/#entites-obligatoires","text":"Il est possible, avant d'afficher la r\u00e9ponse principale, de v\u00e9rifier si certaines entit\u00e9es sont renseign\u00e9es, et si ce n'est pas le cas, d'afficher la question ad\u00e9quate. L'option correspondante est appell\u00e9e Mandatory Entities . Par exemple, supposons que nous ayons besoin de conna\u00eetre la destination de l'utilisateur. Si il ne l'a pas d\u00e9j\u00e0 indiqu\u00e9e, le bot devrait lui demander \"Pour quelle destination ?\".","title":"Entit\u00e9s obligatoires"},{"location":"utilisateur/studio/build/#actions","text":"Les actions sont pr\u00e9sent\u00e9es comme des suggestions, quand le canal le permet. Il est possible de pr\u00e9senter une arborescence d'actions pour construire un arbre de d\u00e9cision.","title":"Actions"},{"location":"utilisateur/studio/build/#longlet-search-stories","text":"Cette \u00e9cran permet de parcourir et g\u00e9rer les parcours ou stories cr\u00e9\u00e9es. Il peut s'agir des parcours configur\u00e9s via Tock Studio (ie. avec l'onglet New Story ) mais aussi les parcours d\u00e9clar\u00e9s programmatiquement via Bot API . Pour voir ces derniers, d\u00e9cochez l'option Only Configured Stories .","title":"L'onglet Search Stories"},{"location":"utilisateur/studio/build/#longlet-bot-flow","text":"Cet \u00e9cran permet d'analyser le flot des intentions et des conversations : Flot des intentions : analyse statique des parcours et arbres de d\u00e9cisions propos\u00e9s par le bot Flot des conversations : analyse dynamique des parcours r\u00e9ellement effectu\u00e9s par les utilisateurs TODO : \u00e0 d\u00e9tailler","title":"L'onglet Bot Flow"},{"location":"utilisateur/studio/build/#longlet-i18n","text":"Cet onglet permet de modifier les r\u00e9ponses du bot, dynamiquement selon plusieurs crit\u00e8res possibles : La langue (c'est ce qu'on appelle internationalisation ou i18n ) Le canal (textuel ou vocal), c'est-\u00e0-dire en pratique le connecteur Selon un roulement : il est possible d'enregistrer plusieurs textes de r\u00e9ponse pour un m\u00eame label dans une m\u00eame langue sur un m\u00eame connecteur - le bot r\u00e9pondra alors al\u00e9atoirement l'un de ces textes, puis effectuera un roulement afin de ne pas toujours r\u00e9pondre la m\u00eame chose. Cela permet de rendre le bot plus agr\u00e9able en variant ses r\u00e9ponses. Voir aussi Construire un bot multilingue pour l'utilisation de l'onglet i18n mais aussi les aspects d\u00e9veloppement sur ce th\u00e8me.","title":"L'onglet i18n"},{"location":"utilisateur/studio/build/#longlet-feature-flipping","text":"Cet section permet de g\u00e9rer des fonctions activables ou d\u00e9sactivables via l'interface ( Feature Flipping ). TODO : \u00e0 d\u00e9tailler.","title":"L'onglet Feature Flipping"},{"location":"utilisateur/studio/build/#continuer","text":"Rendez-vous dans Menu Test pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Continuer..."},{"location":"utilisateur/studio/configuration/","text":"Le menu Configuration \u00b6 Le menu Configuration permet de cr\u00e9er et param\u00e9trer les applications conversationnelles Tock (c'est-\u00e0-dire les mod\u00e8les / bots pouvant co-exister sur une plateforme). Plusieurs fonctions d'administration et de configuration des bots sont \u00e9galement disponibles via ce menu : importer/exporter une configuration, param\u00e9trer la langue, les connecteurs, etc. L'onglet NLU Applications \u00b6 Cet \u00e9cran permet de cr\u00e9er, modifier, supprimer des applications conversationnelles Tock. Lors de la premi\u00e8re connexion \u00e0 la plateforme de d\u00e9monstration , un assistant simplifi\u00e9 permet de cr\u00e9er la premi\u00e8re application (le premier bot). Par la suite, vous pouvez passer par cet \u00e9cran pour ajouter d'autres applications. Cr\u00e9er une application \u00b6 Pour ajouter une application, cliquez sur Create New Application : Saisissez un nom / identifiant pour l'application Choisissez si le mod\u00e8le pourra inclure des entit\u00e9s voire des sous-entit\u00e9s (cf Concepts pour en savoir plus) S\u00e9lectionnez une ou plusieurs langues (voir Construire un bot multilingue pour en savoir plus) S\u00e9lectionnez un moteur NLU ( Apache OpenNLP ou Stanford CoreNLP , voir Installation pour en savoir plus) Modifier, importer et exporter une application \u00b6 Pour chaque application d\u00e9j\u00e0 cr\u00e9\u00e9e, vous pouvez par la suite : Download an application dump : t\u00e9l\u00e9charger sa configuration au format JSON : langue, mod\u00e8le intentions/entit\u00e9s, etc. Download a sentences dump : t\u00e9l\u00e9charger ses phrases qualifi\u00e9es au format JSON Edit : modifier la configuration de l'application Un formulaire permet de modifier la configuraion initiale Une section Advanced options ajoute d'autres param\u00e8tres pour les utilisateurs avertis : Upload dump : charger une configuration ou des phrases qualifi\u00e9es \u00e0 partir d'un fichier au format JSON. Seules les nouvelles intentions/phrases seront ajout\u00e9es, cette fonction ne modifie pas / ne supprime pas les intentions/phrases existantes Trigger build : d\u00e9clencher/forcer la reconstruction du mod\u00e8le NLU Engine configuration : param\u00e9trer finement le moteur NLU sous-jacent (les param\u00e8tres d\u00e9pendant du moteur utilis\u00e9, Apache OpenNLP ou Stanford CoreNLP ) Alexa Export : exporter le mod\u00e8le Tock dans un format utilisable par Alexa La fonction Upload dump (voir ci-dessus) est \u00e9galement accessible directement en bas d'\u00e9cran, permettant : Soit de modifier une application (si l' application name existe) Soit d'en cr\u00e9er/importer une nouvelle L'onglet Bot Configurations \u00b6 Cet \u00e9cran permet d'acc\u00e9der aux connecteurs d'un bot, d'en ajouter, modifier ou supprimer. C'est aussi l\u00e0 que vous trouvez les informations pour se connecter programmatiquement. Se connecter programmatiquement au bot \u00b6 Le param\u00e9trage pour se connecter au bot programmatiquement (ie. via un programme / langage de programmation) se trouve dans cet \u00e9cran : L' API Key peut \u00eatre copi\u00e9e et embarqu\u00e9e dans le code client de la Bot API pour connecter des parcours programm\u00e9s en Kotlin ou dans un autre langage de programmation Une adresse / URL peut \u00eatre configur\u00e9e pour utiliser le mode WebHook de Bot API Pour en savoir plus sur ces param\u00e8tres et le d\u00e9veloppement de parcours, voir Bot API . G\u00e9rer les connecteurs \u00b6 La liste des connecteurs du bot est affich\u00e9e sous la clef d'API. Pour ajouter un connecteur au bot, cliquez sur Create a new Configuration . Tous les connecteurs poss\u00e8dent la configuration suivante : Configuration name : le nom/identifiant du bot Connector type : le type de canal (par exemple Messenger, Slack, etc.) Connector identifier : un identifiant pour le connecteur, unique pour le bot Relative REST path : un chemin relatif unique pour la plateforme, pour communiquer avec le bot sur ce canal. Par d\u00e9faut, le chemin est de la forme /io/{organisation}/{application}/{canal} ce qui le rend unique sur la plateforme (\u00e0 moins que deux connecteurs du m\u00eame type soient d\u00e9clar\u00e9s pour le m\u00eame bot). Chaque connecteur poss\u00e8de \u00e9galement une configuration suppl\u00e9mentaire sp\u00e9cifique \u00e0 ce type de connecteur. Ces param\u00e8tres sont dans Connector Custom Configuration . Ces param\u00e8tres sp\u00e9cifiques sont document\u00e9s avec chaque type de connecteur/canal, voir Les connecteurs . Connecteurs de test \u00b6 Pour chaque connecteur ajout\u00e9 au bot, un connecteur de test est aussi cr\u00e9\u00e9 et configur\u00e9. Il sert \u00e0 \"simuler\" le connecteur lorsqu'on teste le bot directement dans l'interface Tock Studio (menu Test > Test the bot ). Par d\u00e9faut, les connecteurs de test ne sont pas affich\u00e9s dans l'\u00e9cran Bot Configurations . Cliquez sur Display test configurations pour les voir et \u00e9ventuellement les modifier. En particulier, si vous obtenez des messages d'erreur de connexion dans la page Test the bot , n'h\u00e9sitez pas \u00e0 v\u00e9rfier la configuration de test notamment l'adresse Application base url (pour une plateforme d\u00e9ploy\u00e9e avec Docker Compose par d\u00e9faut, ce devrait \u00eatre http://bot_api:8080 avec le nom du conteneur et le port d\u00e9clar\u00e9s dans le descripteur docker-compose-bot.yml ). Continuer... \u00b6 Rendez-vous dans Menu NLU pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Le menu _Configuration_"},{"location":"utilisateur/studio/configuration/#le-menu-configuration","text":"Le menu Configuration permet de cr\u00e9er et param\u00e9trer les applications conversationnelles Tock (c'est-\u00e0-dire les mod\u00e8les / bots pouvant co-exister sur une plateforme). Plusieurs fonctions d'administration et de configuration des bots sont \u00e9galement disponibles via ce menu : importer/exporter une configuration, param\u00e9trer la langue, les connecteurs, etc.","title":"Le menu Configuration"},{"location":"utilisateur/studio/configuration/#longlet-nlu-applications","text":"Cet \u00e9cran permet de cr\u00e9er, modifier, supprimer des applications conversationnelles Tock. Lors de la premi\u00e8re connexion \u00e0 la plateforme de d\u00e9monstration , un assistant simplifi\u00e9 permet de cr\u00e9er la premi\u00e8re application (le premier bot). Par la suite, vous pouvez passer par cet \u00e9cran pour ajouter d'autres applications.","title":"L'onglet NLU Applications"},{"location":"utilisateur/studio/configuration/#creer-une-application","text":"Pour ajouter une application, cliquez sur Create New Application : Saisissez un nom / identifiant pour l'application Choisissez si le mod\u00e8le pourra inclure des entit\u00e9s voire des sous-entit\u00e9s (cf Concepts pour en savoir plus) S\u00e9lectionnez une ou plusieurs langues (voir Construire un bot multilingue pour en savoir plus) S\u00e9lectionnez un moteur NLU ( Apache OpenNLP ou Stanford CoreNLP , voir Installation pour en savoir plus)","title":"Cr\u00e9er une application"},{"location":"utilisateur/studio/configuration/#modifier-importer-et-exporter-une-application","text":"Pour chaque application d\u00e9j\u00e0 cr\u00e9\u00e9e, vous pouvez par la suite : Download an application dump : t\u00e9l\u00e9charger sa configuration au format JSON : langue, mod\u00e8le intentions/entit\u00e9s, etc. Download a sentences dump : t\u00e9l\u00e9charger ses phrases qualifi\u00e9es au format JSON Edit : modifier la configuration de l'application Un formulaire permet de modifier la configuraion initiale Une section Advanced options ajoute d'autres param\u00e8tres pour les utilisateurs avertis : Upload dump : charger une configuration ou des phrases qualifi\u00e9es \u00e0 partir d'un fichier au format JSON. Seules les nouvelles intentions/phrases seront ajout\u00e9es, cette fonction ne modifie pas / ne supprime pas les intentions/phrases existantes Trigger build : d\u00e9clencher/forcer la reconstruction du mod\u00e8le NLU Engine configuration : param\u00e9trer finement le moteur NLU sous-jacent (les param\u00e8tres d\u00e9pendant du moteur utilis\u00e9, Apache OpenNLP ou Stanford CoreNLP ) Alexa Export : exporter le mod\u00e8le Tock dans un format utilisable par Alexa La fonction Upload dump (voir ci-dessus) est \u00e9galement accessible directement en bas d'\u00e9cran, permettant : Soit de modifier une application (si l' application name existe) Soit d'en cr\u00e9er/importer une nouvelle","title":"Modifier, importer et exporter une application"},{"location":"utilisateur/studio/configuration/#longlet-bot-configurations","text":"Cet \u00e9cran permet d'acc\u00e9der aux connecteurs d'un bot, d'en ajouter, modifier ou supprimer. C'est aussi l\u00e0 que vous trouvez les informations pour se connecter programmatiquement.","title":"L'onglet Bot Configurations"},{"location":"utilisateur/studio/configuration/#se-connecter-programmatiquement-au-bot","text":"Le param\u00e9trage pour se connecter au bot programmatiquement (ie. via un programme / langage de programmation) se trouve dans cet \u00e9cran : L' API Key peut \u00eatre copi\u00e9e et embarqu\u00e9e dans le code client de la Bot API pour connecter des parcours programm\u00e9s en Kotlin ou dans un autre langage de programmation Une adresse / URL peut \u00eatre configur\u00e9e pour utiliser le mode WebHook de Bot API Pour en savoir plus sur ces param\u00e8tres et le d\u00e9veloppement de parcours, voir Bot API .","title":"Se connecter programmatiquement au bot"},{"location":"utilisateur/studio/configuration/#gerer-les-connecteurs","text":"La liste des connecteurs du bot est affich\u00e9e sous la clef d'API. Pour ajouter un connecteur au bot, cliquez sur Create a new Configuration . Tous les connecteurs poss\u00e8dent la configuration suivante : Configuration name : le nom/identifiant du bot Connector type : le type de canal (par exemple Messenger, Slack, etc.) Connector identifier : un identifiant pour le connecteur, unique pour le bot Relative REST path : un chemin relatif unique pour la plateforme, pour communiquer avec le bot sur ce canal. Par d\u00e9faut, le chemin est de la forme /io/{organisation}/{application}/{canal} ce qui le rend unique sur la plateforme (\u00e0 moins que deux connecteurs du m\u00eame type soient d\u00e9clar\u00e9s pour le m\u00eame bot). Chaque connecteur poss\u00e8de \u00e9galement une configuration suppl\u00e9mentaire sp\u00e9cifique \u00e0 ce type de connecteur. Ces param\u00e8tres sont dans Connector Custom Configuration . Ces param\u00e8tres sp\u00e9cifiques sont document\u00e9s avec chaque type de connecteur/canal, voir Les connecteurs .","title":"G\u00e9rer les connecteurs"},{"location":"utilisateur/studio/configuration/#connecteurs-de-test","text":"Pour chaque connecteur ajout\u00e9 au bot, un connecteur de test est aussi cr\u00e9\u00e9 et configur\u00e9. Il sert \u00e0 \"simuler\" le connecteur lorsqu'on teste le bot directement dans l'interface Tock Studio (menu Test > Test the bot ). Par d\u00e9faut, les connecteurs de test ne sont pas affich\u00e9s dans l'\u00e9cran Bot Configurations . Cliquez sur Display test configurations pour les voir et \u00e9ventuellement les modifier. En particulier, si vous obtenez des messages d'erreur de connexion dans la page Test the bot , n'h\u00e9sitez pas \u00e0 v\u00e9rfier la configuration de test notamment l'adresse Application base url (pour une plateforme d\u00e9ploy\u00e9e avec Docker Compose par d\u00e9faut, ce devrait \u00eatre http://bot_api:8080 avec le nom du conteneur et le port d\u00e9clar\u00e9s dans le descripteur docker-compose-bot.yml ).","title":"Connecteurs de test"},{"location":"utilisateur/studio/configuration/#continuer","text":"Rendez-vous dans Menu NLU pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Continuer..."},{"location":"utilisateur/studio/general/","text":"L'interface Tock Studio \u00b6 Cette page pr\u00e9sente les caract\u00e9ristiques g\u00e9n\u00e9rales de Tock Studio . Les pages suivantes couvrent les diff\u00e9rents menus de l'application et diff\u00e9rentes fonctionnalit\u00e9s. Connexion \u00e0 l'application \u00b6 Un navigateur standard suffit pour acc\u00e9der \u00e0 Tock Studio . L'utilisateur est invit\u00e9 \u00e0 s'authentifier : Sur la plateforme Tock de d\u00e9monstration , l'utilisateur est invit\u00e9 \u00e0 s'authentifier via son compte GitHub. Celui-ci doit alors accepter que Tock acc\u00e8de \u00e0 son compte - seul l'identifiant du compte GitHub est lu par Tock. Sur une plateforme Tock par d\u00e9faut, les identifiants sont admin@app.com / password . Les identifiants par d\u00e9faut sont d\u00e9finis dans fichier source bot/admin/web/src/environments/environment.ts et il est recommand\u00e9 de les modifier. Il est aussi possible, en alternative, d'utiliser un m\u00e9canisme d'authentification en amont de l'application, par exemple via un service Apache HTTPd ou un service cloud comme AWS Cognito d'une part et un annuaire type LDAP d'autre part. Le bandeau applicatif \u00b6 En haut \u00e0 gauche de l'interface se trouvent : Un bouton permettant d'afficher (ou de masquer) les diff\u00e9rents menus Tock Studio Le nom de l'interface En haut \u00e0 droite de l'interface se trouvent : L'application / le bot couramment s\u00e9lectionn\u00e9 (utile lorsque plusieurs bots co-existent sur la plateforme) La langue couramment s\u00e9lectionn\u00e9e (utile pour tester un bot multilingue) Un lien pour se d\u00e9connecter Continuer... \u00b6 Rendez-vous dans Menu Configuration pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"L'interface _Tock Studio_"},{"location":"utilisateur/studio/general/#linterface-tock-studio","text":"Cette page pr\u00e9sente les caract\u00e9ristiques g\u00e9n\u00e9rales de Tock Studio . Les pages suivantes couvrent les diff\u00e9rents menus de l'application et diff\u00e9rentes fonctionnalit\u00e9s.","title":"L'interface Tock Studio"},{"location":"utilisateur/studio/general/#connexion-a-lapplication","text":"Un navigateur standard suffit pour acc\u00e9der \u00e0 Tock Studio . L'utilisateur est invit\u00e9 \u00e0 s'authentifier : Sur la plateforme Tock de d\u00e9monstration , l'utilisateur est invit\u00e9 \u00e0 s'authentifier via son compte GitHub. Celui-ci doit alors accepter que Tock acc\u00e8de \u00e0 son compte - seul l'identifiant du compte GitHub est lu par Tock. Sur une plateforme Tock par d\u00e9faut, les identifiants sont admin@app.com / password . Les identifiants par d\u00e9faut sont d\u00e9finis dans fichier source bot/admin/web/src/environments/environment.ts et il est recommand\u00e9 de les modifier. Il est aussi possible, en alternative, d'utiliser un m\u00e9canisme d'authentification en amont de l'application, par exemple via un service Apache HTTPd ou un service cloud comme AWS Cognito d'une part et un annuaire type LDAP d'autre part.","title":"Connexion \u00e0 l'application"},{"location":"utilisateur/studio/general/#le-bandeau-applicatif","text":"En haut \u00e0 gauche de l'interface se trouvent : Un bouton permettant d'afficher (ou de masquer) les diff\u00e9rents menus Tock Studio Le nom de l'interface En haut \u00e0 droite de l'interface se trouvent : L'application / le bot couramment s\u00e9lectionn\u00e9 (utile lorsque plusieurs bots co-existent sur la plateforme) La langue couramment s\u00e9lectionn\u00e9e (utile pour tester un bot multilingue) Un lien pour se d\u00e9connecter","title":"Le bandeau applicatif"},{"location":"utilisateur/studio/general/#continuer","text":"Rendez-vous dans Menu Configuration pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Continuer..."},{"location":"utilisateur/studio/monitoring/","text":"Le menu Monitoring \u00b6 Le menu Monitoring permet de suivre et observer les utilisateurs connect\u00e9s ainsi que les conversations. L'onglet Users \u00b6 Cet onglet vous permet de voir les derniers utilisateurs connect\u00e9s au bot : Nombre d'utilisateurs connect\u00e9s Date du dernier \u00e9change avec un utilisateur Dernier message envoy\u00e9 Etc. En cliquant sur Display dialog , vous pouvez voir la conversation de cet utilisateur. L'onglet Dialogs \u00b6 A l'instar de la vue Users , cette \u00e9cran permet d'observer les derni\u00e8res conversations. Il est possible de les filtrer par connecteur, intention, etc. Continuer... \u00b6 Rendez-vous dans Menu Monitoring pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Le menu _Monitoring_"},{"location":"utilisateur/studio/monitoring/#le-menu-monitoring","text":"Le menu Monitoring permet de suivre et observer les utilisateurs connect\u00e9s ainsi que les conversations.","title":"Le menu Monitoring"},{"location":"utilisateur/studio/monitoring/#longlet-users","text":"Cet onglet vous permet de voir les derniers utilisateurs connect\u00e9s au bot : Nombre d'utilisateurs connect\u00e9s Date du dernier \u00e9change avec un utilisateur Dernier message envoy\u00e9 Etc. En cliquant sur Display dialog , vous pouvez voir la conversation de cet utilisateur.","title":"L'onglet Users"},{"location":"utilisateur/studio/monitoring/#longlet-dialogs","text":"A l'instar de la vue Users , cette \u00e9cran permet d'observer les derni\u00e8res conversations. Il est possible de les filtrer par connecteur, intention, etc.","title":"L'onglet Dialogs"},{"location":"utilisateur/studio/monitoring/#continuer","text":"Rendez-vous dans Menu Monitoring pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Continuer..."},{"location":"utilisateur/studio/nlu-qa/","text":"Le menu NLU QA \u00b6 Le menu NLU QA permet d'\u00e9valuer et de suivre dans le temps la qualit\u00e9/pertinence/performance des mod\u00e8les conversationnels. L'onglet Stats \u00b6 Cet \u00e9cran pr\u00e9sente des graphes pour suivre l'\u00e9volution de plusieurs indicateurs de la qualit\u00e9 du mod\u00e8le conversationnel : Pertinence : les scores des algorithmes de d\u00e9tection sur les intentions ( Intent average probability ) et sur les entit\u00e9s ( Entity average probability ) Trafic / erreurs : le nombre de sollicitations du mod\u00e8le ( Calls ) et le nombre d'erreurs ( Errors ) Performance : le temps de r\u00e9ponse du mod\u00e8le ( Average call duration ) L'onglet Intent distance \u00b6 TODO L'onglet Model Builds \u00b6 Cet \u00e9cran pr\u00e9sente des statistiques sur les derni\u00e8res reconstructions du mod\u00e8le. Il s'agit donc d'indications sur la performance du mod\u00e8le. L'onglet Tests Trend \u00b6 Les tests partiels de mod\u00e8le constituent un moyen classique de d\u00e9tecter les erreurs de qualification, ou les probl\u00e8mes de proximit\u00e9 des intentions (ou entit\u00e9s) entre elles. Il s'agit de prendre une partie du mod\u00e8le actuelle au hasard (par exemple 90% des phrases du mod\u00e8le) afin de construire un mod\u00e8le l\u00e9g\u00e8rement moins pertinent, puis de tester les 10% restant avec ce nouveau mod\u00e8le. Le principe pos\u00e9, il ne reste plus qu'\u00e0 r\u00e9p\u00e9ter le processus un certain nombre de fois pour que les erreurs les plus fr\u00e9quentes soient pr\u00e9sent\u00e9es \u00e0 un correcteur manuel. Pr\u00e9cision que ces tests ne pr\u00e9sentent une utilit\u00e9 qu'avec des mod\u00e8les d\u00e9j\u00e0 cons\u00e9quents. Cet onglet donne l'\u00e9volution de la pertinence des tests partiels de mod\u00e8le. Par d\u00e9faut, les tests sont programm\u00e9s pour \u00eatre lanc\u00e9s de minuit \u00e0 5h du matin, toutes les 10 minutes. Il est possible de configurer ce comportement avec la propri\u00e9t\u00e9 tock_test_model_timeframe (par d\u00e9faut : 0,5 ). L'onglet Intent Test Errors \u00b6 Cet \u00e9cran pr\u00e9sente les r\u00e9sultats des tests partiels de d\u00e9tection d'intentions (voir ci-dessus), avec le d\u00e9tails des phrases/expressions reconnues diff\u00e9remment du mod\u00e8le r\u00e9el. Dans cet exemple, aucune \"vraie\" erreur n'a \u00e9t\u00e9 d\u00e9tect\u00e9e. On peut toutefois constater que dans certains cas le mod\u00e8le se trompe syst\u00e9matiquement, avec une probabilit\u00e9 \u00e9lev\u00e9e. Pour chaque phrase il est possible via la colonne Actions de confirmer que le mod\u00e8le de base est correct (avec Validate Intent ) ou de corriger l'erreur d\u00e9tect\u00e9e ( Change The Intent ). Il est int\u00e9ressant d'analyser p\u00e9riodiquement ces \u00e9carts, certaines diff\u00e9rences s'expliquant bien, \u00e9tant m\u00eame parfois \"assum\u00e9es\" (faux n\u00e9gatifs), d'autres pouvant r\u00e9veler un probl\u00e8me dans le mod\u00e8le. L'onglet Entity Test Errors \u00b6 A l'instar de Intent Test Errors pour les entit\u00e9s, cet \u00e9cran pr\u00e9sente les r\u00e9sultats des tests partiels de d\u00e9tection des entit\u00e9s. Il est int\u00e9ressant d'analyser p\u00e9riodiquement ces \u00e9carts, certaines diff\u00e9rences s'expliquant bien, \u00e9tant m\u00eame parfois \"assum\u00e9es\" (faux n\u00e9gatifs), d'autres pouvant r\u00e9veler un probl\u00e8me dans le mod\u00e8le. Continuer... \u00b6 Rendez-vous dans Menu Build pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Le menu _NLU QA_"},{"location":"utilisateur/studio/nlu-qa/#le-menu-nlu-qa","text":"Le menu NLU QA permet d'\u00e9valuer et de suivre dans le temps la qualit\u00e9/pertinence/performance des mod\u00e8les conversationnels.","title":"Le menu NLU QA"},{"location":"utilisateur/studio/nlu-qa/#longlet-stats","text":"Cet \u00e9cran pr\u00e9sente des graphes pour suivre l'\u00e9volution de plusieurs indicateurs de la qualit\u00e9 du mod\u00e8le conversationnel : Pertinence : les scores des algorithmes de d\u00e9tection sur les intentions ( Intent average probability ) et sur les entit\u00e9s ( Entity average probability ) Trafic / erreurs : le nombre de sollicitations du mod\u00e8le ( Calls ) et le nombre d'erreurs ( Errors ) Performance : le temps de r\u00e9ponse du mod\u00e8le ( Average call duration )","title":"L'onglet Stats"},{"location":"utilisateur/studio/nlu-qa/#longlet-intent-distance","text":"TODO","title":"L'onglet Intent distance"},{"location":"utilisateur/studio/nlu-qa/#longlet-model-builds","text":"Cet \u00e9cran pr\u00e9sente des statistiques sur les derni\u00e8res reconstructions du mod\u00e8le. Il s'agit donc d'indications sur la performance du mod\u00e8le.","title":"L'onglet Model Builds"},{"location":"utilisateur/studio/nlu-qa/#longlet-tests-trend","text":"Les tests partiels de mod\u00e8le constituent un moyen classique de d\u00e9tecter les erreurs de qualification, ou les probl\u00e8mes de proximit\u00e9 des intentions (ou entit\u00e9s) entre elles. Il s'agit de prendre une partie du mod\u00e8le actuelle au hasard (par exemple 90% des phrases du mod\u00e8le) afin de construire un mod\u00e8le l\u00e9g\u00e8rement moins pertinent, puis de tester les 10% restant avec ce nouveau mod\u00e8le. Le principe pos\u00e9, il ne reste plus qu'\u00e0 r\u00e9p\u00e9ter le processus un certain nombre de fois pour que les erreurs les plus fr\u00e9quentes soient pr\u00e9sent\u00e9es \u00e0 un correcteur manuel. Pr\u00e9cision que ces tests ne pr\u00e9sentent une utilit\u00e9 qu'avec des mod\u00e8les d\u00e9j\u00e0 cons\u00e9quents. Cet onglet donne l'\u00e9volution de la pertinence des tests partiels de mod\u00e8le. Par d\u00e9faut, les tests sont programm\u00e9s pour \u00eatre lanc\u00e9s de minuit \u00e0 5h du matin, toutes les 10 minutes. Il est possible de configurer ce comportement avec la propri\u00e9t\u00e9 tock_test_model_timeframe (par d\u00e9faut : 0,5 ).","title":"L'onglet Tests Trend"},{"location":"utilisateur/studio/nlu-qa/#longlet-intent-test-errors","text":"Cet \u00e9cran pr\u00e9sente les r\u00e9sultats des tests partiels de d\u00e9tection d'intentions (voir ci-dessus), avec le d\u00e9tails des phrases/expressions reconnues diff\u00e9remment du mod\u00e8le r\u00e9el. Dans cet exemple, aucune \"vraie\" erreur n'a \u00e9t\u00e9 d\u00e9tect\u00e9e. On peut toutefois constater que dans certains cas le mod\u00e8le se trompe syst\u00e9matiquement, avec une probabilit\u00e9 \u00e9lev\u00e9e. Pour chaque phrase il est possible via la colonne Actions de confirmer que le mod\u00e8le de base est correct (avec Validate Intent ) ou de corriger l'erreur d\u00e9tect\u00e9e ( Change The Intent ). Il est int\u00e9ressant d'analyser p\u00e9riodiquement ces \u00e9carts, certaines diff\u00e9rences s'expliquant bien, \u00e9tant m\u00eame parfois \"assum\u00e9es\" (faux n\u00e9gatifs), d'autres pouvant r\u00e9veler un probl\u00e8me dans le mod\u00e8le.","title":"L'onglet Intent Test Errors"},{"location":"utilisateur/studio/nlu-qa/#longlet-entity-test-errors","text":"A l'instar de Intent Test Errors pour les entit\u00e9s, cet \u00e9cran pr\u00e9sente les r\u00e9sultats des tests partiels de d\u00e9tection des entit\u00e9s. Il est int\u00e9ressant d'analyser p\u00e9riodiquement ces \u00e9carts, certaines diff\u00e9rences s'expliquant bien, \u00e9tant m\u00eame parfois \"assum\u00e9es\" (faux n\u00e9gatifs), d'autres pouvant r\u00e9veler un probl\u00e8me dans le mod\u00e8le.","title":"L'onglet Entity Test Errors"},{"location":"utilisateur/studio/nlu-qa/#continuer","text":"Rendez-vous dans Menu Build pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Continuer..."},{"location":"utilisateur/studio/nlu/","text":"Le menu NLU \u00b6 Le menu NLU (Natural Language Understanding) permet de cr\u00e9er, modifier, enrichir les mod\u00e8les conversationnels : d\u00e9clarer des intentions et des entit\u00e9s , qualifier des phrases, etc. (voir Concepts pour en savoir plus). Dans cette page, le d\u00e9tail de chaque onglet est pr\u00e9sent\u00e9. Voir aussi Construire les mod\u00e8les conversationnels pour une pr\u00e9sentation plus guid\u00e9e par l'usage. L'onglet Try it \u00b6 Cet \u00e9cran permet d'entrer des phrases et et de v\u00e9rifier quelle intention/entit\u00e9s sont d\u00e9tect\u00e9es. Saisissez une phrase et validez pour voir la d\u00e9tection r\u00e9sultant du mod\u00e8le conversationnel (en pratique : comment le bot interpr\u00e8te la phrase). S'affichent alors : Intent : l'intention reconnue Language : la langue d\u00e9tect\u00e9e Le(s) score(s) retourn\u00e9(s) par les algorithmes (selon leur niveau de confiance sur l'intention et sur les \u00e9ventuelles entit\u00e9s) Le cas \u00e9ch\u00e9ant, chaque entit\u00e9 d\u00e9tect\u00e9e avec son r\u00f4le/type et son score Il est possible de modifier tous les \u00e9l\u00e9ments d\u00e9tect\u00e9s depuis cet \u00e9cran : Pour modifier l'intention (voire en cr\u00e9er une nouvelle \u00e0 la vol\u00e9e) ou la langue d\u00e9tect\u00e9es, utilisez les champs / listes de s\u00e9lection sous la phrase Pour supprimer une entit\u00e9, utilisez le bouton \u00e0 c\u00f4t\u00e9 du score de l'entit\u00e9 Pour ajouter une entit\u00e9, s\u00e9lectionnez avec la souris un bloc de mots dansla phrase puis pr\u00e9cisez son r\u00f4le/type. Remarque : si vous avez activ\u00e9 cette option au niveau de l'application/bot, il est possible de d\u00e9clarer des sous-entit\u00e9s . Vous en apprendrez plus dans Construire les mod\u00e8les conversationnels . Les boutons et commandes suivantes sont disponibles pour la phrase dans sa globalit\u00e9 : Delete : supprime la phrase Unknown : qualifier la phrase en intention inconnue (r\u00e9ponse par d\u00e9faut) Validate : confirmer l'intention/entit\u00e9s d\u00e9tect\u00e9es et enregistrer la phrase dans le mod\u00e8le (provoquant in fine une reconstruction du mod\u00e8le, son corpus \u00e9tant enrichi de cette phrase) D'autres liens sont accessibles pour afficher les conversations contenant cette phrase, copier le contenu de la phrase, cr\u00e9er un parcours \u00e0 partir de cette phrase. L'onglet Inbox \u00b6 Cet onglet montre (avec de la pagination et quelques options d'affichage) l'ensemble des phrases re\u00e7ues par le mod\u00e8le NLU avec les intentions/entit\u00e9s/langue/scores d\u00e9tect\u00e9s. Ces phrases peuvent provenir de v\u00e9ritables utilisateurs quelques soient les canaux, d'une saisie dans l'onglet Try it ou encore d'une conversation via la page Test the bot dans Tock Studio . Lorsque vous faites des tests depuis un canal externe, n'h\u00e9sitez pas \u00e0 cliquer sur le bouton Refresh (en haut \u00e0 gauche de l'\u00e9cran) pour rafra\u00eechir la liste des phrases. Les boutons et commandes sous chaque phrase sont identiques \u00e0 ceux de l'onglet Try it (voir ci-dessus). L'onglet Unknown \u00b6 Cet \u00e9cran permet de parcourir les phrases dont l'intention n'a pas \u00e9t\u00e9 reconnue (intention unknown ). L'onglet Search \u00b6 Cet \u00e9cran permet de faire des recherches dans l'ensemble des phrases : Inbox mais aussi phrases qualifi\u00e9es enregistr\u00e9es dans le mod\u00e8le. L'onglet Intents \u00b6 Cet \u00e9cran permet de g\u00e9rer les intentions. L'onglet Entities \u00b6 Cet \u00e9cran permet de g\u00e9rer les entit\u00e9s, notamment les notions d'entit\u00e9s partag\u00e9es. L'onglet Logs \u00b6 Cet \u00e9cran pr\u00e9sente le journal complet des phrases re\u00e7ues et permet de remonter aux conversations (ie. l'ensemble des phrases re\u00e7ues et r\u00e9ponses du bot pour un utilisateur). Remarque : contrairement \u00e0 la vue Inbox , les Logs montrent les phrases re\u00e7ues m\u00eame lorsqu'elles existent d\u00e9j\u00e0 \u00e0 l'identique dans le mod\u00e8le (dans ce cas, le mod\u00e8le et les algorithmes ne sont m\u00eame pas interrog\u00e9s, la r\u00e9ponse \u00e9tant connue). Continuer... \u00b6 Rendez-vous dans Menu NLU QA pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Le menu _NLU_"},{"location":"utilisateur/studio/nlu/#le-menu-nlu","text":"Le menu NLU (Natural Language Understanding) permet de cr\u00e9er, modifier, enrichir les mod\u00e8les conversationnels : d\u00e9clarer des intentions et des entit\u00e9s , qualifier des phrases, etc. (voir Concepts pour en savoir plus). Dans cette page, le d\u00e9tail de chaque onglet est pr\u00e9sent\u00e9. Voir aussi Construire les mod\u00e8les conversationnels pour une pr\u00e9sentation plus guid\u00e9e par l'usage.","title":"Le menu NLU"},{"location":"utilisateur/studio/nlu/#longlet-try-it","text":"Cet \u00e9cran permet d'entrer des phrases et et de v\u00e9rifier quelle intention/entit\u00e9s sont d\u00e9tect\u00e9es. Saisissez une phrase et validez pour voir la d\u00e9tection r\u00e9sultant du mod\u00e8le conversationnel (en pratique : comment le bot interpr\u00e8te la phrase). S'affichent alors : Intent : l'intention reconnue Language : la langue d\u00e9tect\u00e9e Le(s) score(s) retourn\u00e9(s) par les algorithmes (selon leur niveau de confiance sur l'intention et sur les \u00e9ventuelles entit\u00e9s) Le cas \u00e9ch\u00e9ant, chaque entit\u00e9 d\u00e9tect\u00e9e avec son r\u00f4le/type et son score Il est possible de modifier tous les \u00e9l\u00e9ments d\u00e9tect\u00e9s depuis cet \u00e9cran : Pour modifier l'intention (voire en cr\u00e9er une nouvelle \u00e0 la vol\u00e9e) ou la langue d\u00e9tect\u00e9es, utilisez les champs / listes de s\u00e9lection sous la phrase Pour supprimer une entit\u00e9, utilisez le bouton \u00e0 c\u00f4t\u00e9 du score de l'entit\u00e9 Pour ajouter une entit\u00e9, s\u00e9lectionnez avec la souris un bloc de mots dansla phrase puis pr\u00e9cisez son r\u00f4le/type. Remarque : si vous avez activ\u00e9 cette option au niveau de l'application/bot, il est possible de d\u00e9clarer des sous-entit\u00e9s . Vous en apprendrez plus dans Construire les mod\u00e8les conversationnels . Les boutons et commandes suivantes sont disponibles pour la phrase dans sa globalit\u00e9 : Delete : supprime la phrase Unknown : qualifier la phrase en intention inconnue (r\u00e9ponse par d\u00e9faut) Validate : confirmer l'intention/entit\u00e9s d\u00e9tect\u00e9es et enregistrer la phrase dans le mod\u00e8le (provoquant in fine une reconstruction du mod\u00e8le, son corpus \u00e9tant enrichi de cette phrase) D'autres liens sont accessibles pour afficher les conversations contenant cette phrase, copier le contenu de la phrase, cr\u00e9er un parcours \u00e0 partir de cette phrase.","title":"L'onglet Try it"},{"location":"utilisateur/studio/nlu/#longlet-inbox","text":"Cet onglet montre (avec de la pagination et quelques options d'affichage) l'ensemble des phrases re\u00e7ues par le mod\u00e8le NLU avec les intentions/entit\u00e9s/langue/scores d\u00e9tect\u00e9s. Ces phrases peuvent provenir de v\u00e9ritables utilisateurs quelques soient les canaux, d'une saisie dans l'onglet Try it ou encore d'une conversation via la page Test the bot dans Tock Studio . Lorsque vous faites des tests depuis un canal externe, n'h\u00e9sitez pas \u00e0 cliquer sur le bouton Refresh (en haut \u00e0 gauche de l'\u00e9cran) pour rafra\u00eechir la liste des phrases. Les boutons et commandes sous chaque phrase sont identiques \u00e0 ceux de l'onglet Try it (voir ci-dessus).","title":"L'onglet Inbox"},{"location":"utilisateur/studio/nlu/#longlet-unknown","text":"Cet \u00e9cran permet de parcourir les phrases dont l'intention n'a pas \u00e9t\u00e9 reconnue (intention unknown ).","title":"L'onglet Unknown"},{"location":"utilisateur/studio/nlu/#longlet-search","text":"Cet \u00e9cran permet de faire des recherches dans l'ensemble des phrases : Inbox mais aussi phrases qualifi\u00e9es enregistr\u00e9es dans le mod\u00e8le.","title":"L'onglet Search"},{"location":"utilisateur/studio/nlu/#longlet-intents","text":"Cet \u00e9cran permet de g\u00e9rer les intentions.","title":"L'onglet Intents"},{"location":"utilisateur/studio/nlu/#longlet-entities","text":"Cet \u00e9cran permet de g\u00e9rer les entit\u00e9s, notamment les notions d'entit\u00e9s partag\u00e9es.","title":"L'onglet Entities"},{"location":"utilisateur/studio/nlu/#longlet-logs","text":"Cet \u00e9cran pr\u00e9sente le journal complet des phrases re\u00e7ues et permet de remonter aux conversations (ie. l'ensemble des phrases re\u00e7ues et r\u00e9ponses du bot pour un utilisateur). Remarque : contrairement \u00e0 la vue Inbox , les Logs montrent les phrases re\u00e7ues m\u00eame lorsqu'elles existent d\u00e9j\u00e0 \u00e0 l'identique dans le mod\u00e8le (dans ce cas, le mod\u00e8le et les algorithmes ne sont m\u00eame pas interrog\u00e9s, la r\u00e9ponse \u00e9tant connue).","title":"L'onglet Logs"},{"location":"utilisateur/studio/nlu/#continuer","text":"Rendez-vous dans Menu NLU QA pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Continuer..."},{"location":"utilisateur/studio/test/","text":"Le menu Test \u00b6 Le menu Test permet de tester un bot directement dans l'interface Tock Studio , ainsi que de g\u00e9rer des plans de tests automatiques. L'onglet Test the bot \u00b6 Via ce menu, vous pouvez parler directement au bot en simulant diff\u00e9rentes langues et connecteurs. Cela permet de tester rapidement et simplement un bot dans l'interface Tock Studio , sans avoir \u00e0 utiliser de logiciels et canaux externes. L'interface reste minimale car l'objectif est de tester rapidement le bot, pas d'obtenir une v\u00e9ritable interface utilisateur ni m\u00eame un rendu identique \u00e0 celui de tel ou tel connecteur. Selon le type de messages renvoy\u00e9s par le bot et selon le connecteur utilis\u00e9, il se peut que le rendu dans l'\u00e9cran Test the bot ne soit pas satisfaisant. En effet, pour une compatibilit\u00e9 parfaite avec cet \u00e9cran, les connecteurs doivent respecter certaines r\u00e8gles d'impl\u00e9mentation. Si vous constatez qu'un certain type de message pour un connecteur donn\u00e9 n'est pas bien g\u00e9r\u00e9 dans cette interface, n'h\u00e9sitez pas \u00e0 remonter une issue GitHub . Pour parler \u00e0 un bot dans l'interface, une fois dans Test > Test the bot : V\u00e9rifiez la langue (en haut \u00e0 droite de l'interface) S\u00e9lectionnez une application/un bot S\u00e9lectionnez un connecteur \u00e0 \u00e9muler Commencez \u00e0 saisir des phrases... Voici un autre exemple avec une conversation comprenant des composants riches du connecteur Messenger, avec leur rendu dans l'interface g\u00e9n\u00e9rique Tock Studio : Pour chaque \u00e9change de messages avec le bot, la langue d\u00e9tect\u00e9e est indiqu\u00e9e. En cliquant sur View Nlp Stats vous pouvez voir le d\u00e9tail de la r\u00e9ponse du mod\u00e8le : intention, entit\u00e9s, scores, etc. L'onglet Test Plans \u00b6 TODO Continuer... \u00b6 Rendez-vous dans Menu Monitoring pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Le menu _Test_"},{"location":"utilisateur/studio/test/#le-menu-test","text":"Le menu Test permet de tester un bot directement dans l'interface Tock Studio , ainsi que de g\u00e9rer des plans de tests automatiques.","title":"Le menu Test"},{"location":"utilisateur/studio/test/#longlet-test-the-bot","text":"Via ce menu, vous pouvez parler directement au bot en simulant diff\u00e9rentes langues et connecteurs. Cela permet de tester rapidement et simplement un bot dans l'interface Tock Studio , sans avoir \u00e0 utiliser de logiciels et canaux externes. L'interface reste minimale car l'objectif est de tester rapidement le bot, pas d'obtenir une v\u00e9ritable interface utilisateur ni m\u00eame un rendu identique \u00e0 celui de tel ou tel connecteur. Selon le type de messages renvoy\u00e9s par le bot et selon le connecteur utilis\u00e9, il se peut que le rendu dans l'\u00e9cran Test the bot ne soit pas satisfaisant. En effet, pour une compatibilit\u00e9 parfaite avec cet \u00e9cran, les connecteurs doivent respecter certaines r\u00e8gles d'impl\u00e9mentation. Si vous constatez qu'un certain type de message pour un connecteur donn\u00e9 n'est pas bien g\u00e9r\u00e9 dans cette interface, n'h\u00e9sitez pas \u00e0 remonter une issue GitHub . Pour parler \u00e0 un bot dans l'interface, une fois dans Test > Test the bot : V\u00e9rifiez la langue (en haut \u00e0 droite de l'interface) S\u00e9lectionnez une application/un bot S\u00e9lectionnez un connecteur \u00e0 \u00e9muler Commencez \u00e0 saisir des phrases... Voici un autre exemple avec une conversation comprenant des composants riches du connecteur Messenger, avec leur rendu dans l'interface g\u00e9n\u00e9rique Tock Studio : Pour chaque \u00e9change de messages avec le bot, la langue d\u00e9tect\u00e9e est indiqu\u00e9e. En cliquant sur View Nlp Stats vous pouvez voir le d\u00e9tail de la r\u00e9ponse du mod\u00e8le : intention, entit\u00e9s, scores, etc.","title":"L'onglet Test the bot"},{"location":"utilisateur/studio/test/#longlet-test-plans","text":"TODO","title":"L'onglet Test Plans"},{"location":"utilisateur/studio/test/#continuer","text":"Rendez-vous dans Menu Monitoring pour la suite du manuel utilisateur. Vous pouvez aussi passer directement au chapitre suivant : D\u00e9veloppement .","title":"Continuer..."}]}