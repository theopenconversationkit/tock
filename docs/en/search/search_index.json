{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Tock - open conversational platform Tock ( The Open Conversation Kit ) is a complete and open platform to build conversational agents - also known as bots . The Tock.ai site is a good starting point to learn about the solution and its growing community. Tock does not depend on 3rd-party APIs, although it is possible to integrate with them. Users choose which components to embed and decide to keep (or share) ownership of conversational data and models. Tock has been used in production for several years by OUI.sncf to propose various assistants over its own channels (Web, mobile), social networks, as well as smart speakers. The platform source code is available on GitHub under the Apache License, version 2.0 . To find out more about AlloCovid (built with Tock) please visit www.allocovid.com . Available by phone, on the Web and WhatsApp, the bot informs and guides French population about the Covid-19, thanks to experts, partners and volunteers. This page gives technical details and links to the sources. Features Standalone bots or integrated with Web sites, mobile apps, social networks, smart speakers. Full-featured NLU (Natural Language Understanding) platform, compatible with algorithms such as OpenNLP , Stanford CoreNLP , Duckling , can be deployed alone (for use cases like the Internet Of Things for instance) Tock Studio user interfaces: Models management, bot training Conversational no-code story builder Internationalization ( i18n ) support for multilingual bots Conversations, performance et model errors monitoring Interactive trends / users flow analytics ( Bot Flow ) Frameworks available to develop complex stories and integrate with 3rd-party services: Kotlin DSL plus any-language API Numerous connectors to Messenger , WhatsApp , Google Assistant / Home , Twitter , Alexa , Business Chat / iMessage , Teams , Slack ... (see connectors ) Cloud or on-premise setups, with or without Docker , \"embedded\" bots without Internet Technologies Tock runs on JVM platforms. The reference language is Kotlin , but other programming languages can be leveraged through the available APIs. Tock relies on Vert.x and MongoDB . Various NLU libraries and algorithms can be used, such as Apache OpenNLP or Stanford CoreNLP , but Tock does not depend on them directly. Graphical interfaces (Tock Studio) are made with Angular in Typescript . Getting started... Read Tutorial and start using the demo/sandbox platform","title":"Overview"},{"location":"#welcome-to-tock-open-conversational-platform","text":"Tock ( The Open Conversation Kit ) is a complete and open platform to build conversational agents - also known as bots . The Tock.ai site is a good starting point to learn about the solution and its growing community. Tock does not depend on 3rd-party APIs, although it is possible to integrate with them. Users choose which components to embed and decide to keep (or share) ownership of conversational data and models. Tock has been used in production for several years by OUI.sncf to propose various assistants over its own channels (Web, mobile), social networks, as well as smart speakers. The platform source code is available on GitHub under the Apache License, version 2.0 . To find out more about AlloCovid (built with Tock) please visit www.allocovid.com . Available by phone, on the Web and WhatsApp, the bot informs and guides French population about the Covid-19, thanks to experts, partners and volunteers. This page gives technical details and links to the sources.","title":"Welcome to Tock - open conversational platform"},{"location":"#features","text":"Standalone bots or integrated with Web sites, mobile apps, social networks, smart speakers. Full-featured NLU (Natural Language Understanding) platform, compatible with algorithms such as OpenNLP , Stanford CoreNLP , Duckling , can be deployed alone (for use cases like the Internet Of Things for instance) Tock Studio user interfaces: Models management, bot training Conversational no-code story builder Internationalization ( i18n ) support for multilingual bots Conversations, performance et model errors monitoring Interactive trends / users flow analytics ( Bot Flow ) Frameworks available to develop complex stories and integrate with 3rd-party services: Kotlin DSL plus any-language API Numerous connectors to Messenger , WhatsApp , Google Assistant / Home , Twitter , Alexa , Business Chat / iMessage , Teams , Slack ... (see connectors ) Cloud or on-premise setups, with or without Docker , \"embedded\" bots without Internet","title":"Features"},{"location":"#technologies","text":"Tock runs on JVM platforms. The reference language is Kotlin , but other programming languages can be leveraged through the available APIs. Tock relies on Vert.x and MongoDB . Various NLU libraries and algorithms can be used, such as Apache OpenNLP or Stanford CoreNLP , but Tock does not depend on them directly. Graphical interfaces (Tock Studio) are made with Angular in Typescript .","title":"Technologies"},{"location":"#getting-started","text":"Read Tutorial and start using the demo/sandbox platform","title":"Getting started..."},{"location":"api/","text":"Tock documented APIs Tock Web Connector API The Tock Web Connector allows to interact with a bot using a REST API. API documentation is available at /api/web-connector . Tock Web Connector API To test a model via the Tock NLU API, see /api . It is also possible to run the provided Docker images and open http://localhost/doc/index.html Tock Studio / Admin API Tock Studio Admin API (to manage the models) is documented: /api/admin It is also possible to run the provided Docker images and open http://localhost/doc/admin.html . Tock Bot Definition API This API allows to create bots and stories with any programing language. Tock bots can be composed of configured stories (using Tock Studio builder) and programatic stories, possibly implementing complex rules or leveraging other external APIs. This API is used by provided Kotlin clients in WebHook or WebSocket mode, as well as the tock-node component in Javascript. The API is under development, it will soon be documented. To know more about the Bot API development framework, see this page .","title":"API documentation"},{"location":"api/#tock-documented-apis","text":"","title":"Tock documented APIs"},{"location":"api/#tock-web-connector-api","text":"The Tock Web Connector allows to interact with a bot using a REST API. API documentation is available at /api/web-connector .","title":"Tock Web Connector API"},{"location":"api/#tock-web-connector-api_1","text":"To test a model via the Tock NLU API, see /api . It is also possible to run the provided Docker images and open http://localhost/doc/index.html","title":"Tock Web Connector API"},{"location":"api/#tock-studio-admin-api","text":"Tock Studio Admin API (to manage the models) is documented: /api/admin It is also possible to run the provided Docker images and open http://localhost/doc/admin.html .","title":"Tock Studio / Admin API"},{"location":"api/#tock-bot-definition-api","text":"This API allows to create bots and stories with any programing language. Tock bots can be composed of configured stories (using Tock Studio builder) and programatic stories, possibly implementing complex rules or leveraging other external APIs. This API is used by provided Kotlin clients in WebHook or WebSocket mode, as well as the tock-node component in Javascript. The API is under development, it will soon be documented. To know more about the Bot API development framework, see this page .","title":"Tock Bot Definition API"},{"location":"build-nlp-model/","text":"Build a New NLU (Natural Language Understanding) Model Overview Seven tabs are available: Try it : add (or test) a new sentence Inbox : not yet qualified sentences Archive : the set of archived sentences, i. e. marked as not yet recognized by the model. Search : an advanced search interface that lets you search for sentences, whether or not they are qualified. Intents : the list of the model's intentions Entities : the list of model entities Logs : the last queries requested via the NLP API The user is redirected by default to Inbox . Add and Qualify Sentences Add a New Sentence Click on the Try It menu and enter the new sentence. The add a new user intent by selecting \"Create a New Intent\" in the \"Intent\" selection list. Declaring Entities If necessary, you can specify the entities of this new intent, by selecting the text of these entities, and then clicking on the \"Add New Entity\" button that has just appeared. It's up to you to choose an existing entity type, or create a new one, and then give that entity a role. Built-in Entities In the window \"Add Entity\", you can see that there are already pre-existing entities (prefixed by duckling ). These are the entities recognized by the eponymous library. These entities will be recognized and valued automatically if you specify them in at least one sentence of the intent. Validate a Sentence If you think that the sentence is qualified correctly, you just have to click on \"Validate\" to confirm that the sentence is ok. If this is not the case, it's up to you to correct the meaning before validating it. You are building your first model! Explore the Model The Search Tab The Search tab allows you to browse all the sentences of the model. The most used criterion is the full text search input (regular expressions are allowed). You can then consult the sentences that are part of your model, and also change the qualifications of these sentences over time. States of a Sentence Each sentence has a state: Inbox : The sentence has not been qualified yet and is not included in the model Validated : The sentence has been validated but is not yet included in the NLP model (this can take some time for large models) Included in model : The sentence has been validated and is included in the model Advanced Features By clicking on the \"Applications\"menu, you get the list of existing applications. Then click of the edit button of the application you want to configure. Nlp Engine Selection You can select the NLP library used by this application with the \"NLP engine\" radio button: Use Built-in Entity Models This option allows you to reuse built-in entity models (ie duckling) in your new intent. For example, if you create an intent with a duckling:datetime entity, the dates will automatically be recognized for that intent in all new sentences assigned to that intent (Internally, a merge is performed between the info given by the built-in entity models and the info of your own model). This option is enabled by default, it can be useful to disable it for very large models, for which the NER detection will perform better in almost all cases. Use sub-entities If you enable this option, you will be able to qualify multiple levels of entities: The number of levels is not limited, but it is advisable not to specify more than 3 or 4. Use predefined values An entity can have predefined values : you just have to click on \"Entities\" tab, and select an entity. A small icon next to the delete icon shows the types of entities you can edit as shown in the picture below:","title":"Build NLP models"},{"location":"build-nlp-model/#build-a-new-nlu-natural-language-understanding-model","text":"","title":"Build a New NLU (Natural Language Understanding) Model"},{"location":"build-nlp-model/#overview","text":"Seven tabs are available: Try it : add (or test) a new sentence Inbox : not yet qualified sentences Archive : the set of archived sentences, i. e. marked as not yet recognized by the model. Search : an advanced search interface that lets you search for sentences, whether or not they are qualified. Intents : the list of the model's intentions Entities : the list of model entities Logs : the last queries requested via the NLP API The user is redirected by default to Inbox .","title":"Overview"},{"location":"build-nlp-model/#add-and-qualify-sentences","text":"","title":"Add and Qualify Sentences"},{"location":"build-nlp-model/#add-a-new-sentence","text":"Click on the Try It menu and enter the new sentence. The add a new user intent by selecting \"Create a New Intent\" in the \"Intent\" selection list.","title":"Add a New Sentence"},{"location":"build-nlp-model/#declaring-entities","text":"If necessary, you can specify the entities of this new intent, by selecting the text of these entities, and then clicking on the \"Add New Entity\" button that has just appeared. It's up to you to choose an existing entity type, or create a new one, and then give that entity a role.","title":"Declaring Entities"},{"location":"build-nlp-model/#built-in-entities","text":"In the window \"Add Entity\", you can see that there are already pre-existing entities (prefixed by duckling ). These are the entities recognized by the eponymous library. These entities will be recognized and valued automatically if you specify them in at least one sentence of the intent.","title":"Built-in Entities"},{"location":"build-nlp-model/#validate-a-sentence","text":"If you think that the sentence is qualified correctly, you just have to click on \"Validate\" to confirm that the sentence is ok. If this is not the case, it's up to you to correct the meaning before validating it. You are building your first model!","title":"Validate a Sentence"},{"location":"build-nlp-model/#explore-the-model","text":"","title":"Explore the Model"},{"location":"build-nlp-model/#the-search-tab","text":"The Search tab allows you to browse all the sentences of the model. The most used criterion is the full text search input (regular expressions are allowed). You can then consult the sentences that are part of your model, and also change the qualifications of these sentences over time.","title":"The Search Tab"},{"location":"build-nlp-model/#states-of-a-sentence","text":"Each sentence has a state: Inbox : The sentence has not been qualified yet and is not included in the model Validated : The sentence has been validated but is not yet included in the NLP model (this can take some time for large models) Included in model : The sentence has been validated and is included in the model","title":"States of a Sentence"},{"location":"build-nlp-model/#advanced-features","text":"By clicking on the \"Applications\"menu, you get the list of existing applications. Then click of the edit button of the application you want to configure.","title":"Advanced Features"},{"location":"build-nlp-model/#nlp-engine-selection","text":"You can select the NLP library used by this application with the \"NLP engine\" radio button:","title":"Nlp Engine Selection"},{"location":"build-nlp-model/#use-built-in-entity-models","text":"This option allows you to reuse built-in entity models (ie duckling) in your new intent. For example, if you create an intent with a duckling:datetime entity, the dates will automatically be recognized for that intent in all new sentences assigned to that intent (Internally, a merge is performed between the info given by the built-in entity models and the info of your own model). This option is enabled by default, it can be useful to disable it for very large models, for which the NER detection will perform better in almost all cases.","title":"Use Built-in Entity Models"},{"location":"build-nlp-model/#use-sub-entities","text":"If you enable this option, you will be able to qualify multiple levels of entities: The number of levels is not limited, but it is advisable not to specify more than 3 or 4.","title":"Use sub-entities"},{"location":"build-nlp-model/#use-predefined-values","text":"An entity can have predefined values : you just have to click on \"Entities\" tab, and select an entity. A small icon next to the delete icon shows the types of entities you can edit as shown in the picture below:","title":"Use predefined values"},{"location":"evaluate-the-model/","text":"Evaluate the relevance of a NLP model Tabs Five tabs are used to control the relevance of the model: Stats : Monitores model perfomance in production: self-evaluation of the model about its relevance in terms of recognition of intent and entities number of calls and errors average execution time Model Builds : the cimplete list of model builds Test Trend : evolution of the relevance of model tests Intent Errors : the list of intent errors found with model tests Entity Errors : the list of entity errors found with model tests Model Tests Model tests are used to detect qualifications errors. Temporarily models are built from a random part of the whole sentence set of the model (90% for example) and then tested against the remaining sentences. The process is repeated a number of times and the most frequent errors are pushed to an admin user. Model tests are useful only with large models. Intent errors Click on the Intent Errors tab: Since the picture above is built from a very simple model, no real error has been detected. We can nevertheless note that in some cases the model is systematically wrong with a high probability. Entity errors These errors can be viewed via the Entity Errors tab.","title":"Monitor NLP models"},{"location":"evaluate-the-model/#evaluate-the-relevance-of-a-nlp-model","text":"","title":"Evaluate the relevance of a NLP model"},{"location":"evaluate-the-model/#tabs","text":"Five tabs are used to control the relevance of the model: Stats : Monitores model perfomance in production: self-evaluation of the model about its relevance in terms of recognition of intent and entities number of calls and errors average execution time Model Builds : the cimplete list of model builds Test Trend : evolution of the relevance of model tests Intent Errors : the list of intent errors found with model tests Entity Errors : the list of entity errors found with model tests","title":"Tabs"},{"location":"evaluate-the-model/#model-tests","text":"Model tests are used to detect qualifications errors. Temporarily models are built from a random part of the whole sentence set of the model (90% for example) and then tested against the remaining sentences. The process is repeated a number of times and the most frequent errors are pushed to an admin user. Model tests are useful only with large models.","title":"Model Tests"},{"location":"evaluate-the-model/#intent-errors","text":"Click on the Intent Errors tab: Since the picture above is built from a very simple model, no real error has been detected. We can nevertheless note that in some cases the model is systematically wrong with a high probability.","title":"Intent errors"},{"location":"evaluate-the-model/#entity-errors","text":"These errors can be viewed via the Entity Errors tab.","title":"Entity errors"},{"location":"getting-started/","text":"TLDR; Deploy the Open Data Bot example with Docker. A Sample Bot The sample bot using Tock Integrated mode : https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit. Docker Images Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker . Start the NLP stack #get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password . Sample bot based on Open Data APIs A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images . Administration Interface Menu The Configuration menu allows you to create new models and configure them. The NLP and NLP QA menus are dedicated to building NLP models. The Build , Test and Monitoring menus are used for building bots or assistants.","title":"TLDR;"},{"location":"getting-started/#tldr","text":"Deploy the Open Data Bot example with Docker.","title":"TLDR;"},{"location":"getting-started/#a-sample-bot","text":"The sample bot using Tock Integrated mode : https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit.","title":"A Sample Bot"},{"location":"getting-started/#docker-images","text":"Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker .","title":"Docker Images"},{"location":"getting-started/#start-the-nlp-stack","text":"#get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password .","title":"Start the NLP stack"},{"location":"getting-started/#sample-bot-based-on-open-data-apis","text":"A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images .","title":"Sample bot based on Open Data APIs"},{"location":"getting-started/#administration-interface-menu","text":"The Configuration menu allows you to create new models and configure them. The NLP and NLP QA menus are dedicated to building NLP models. The Build , Test and Monitoring menus are used for building bots or assistants.","title":"Administration Interface Menu"},{"location":"kdoc/","text":"A KDoc documentation is provided .","title":"KDoc"},{"location":"test-the-bot/","text":"Use the Test Framework Tock provides extensions in order to help writing better unit tests. To use them, you need to add the bot-test dependency to your project. With Maven : dependency groupId ai.tock /groupId artifactId bot-test /artifactId version 20.3.1 /version scope test /scope /dependency With Gradle : testCompile ai.tock:bot-test:20.3.1 This framework is documented in KDoc format [here]https://doc.tock.ai/tock/dokka/tock/ai.tock.bot.test). Write a Simple Test In the next samples, JUnit5 is used as test engine. A dedicated extension for Tock is available . @RegisterExtension @JvmField val ext = TockJUnit5Extension () To test the greetings story of the Open Data bot, just use the ext.send() method: @Test fun `greetings story displays welcome message` () { ext . send { firstAnswer . assertText ( Welcome to the Tock Open Data Bot! :) ) secondAnswer . assertText ( This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock ) } } As the default connector is Messenger, it is possible to test the message specific to Messenger in the same way: @Test fun `greetings story displays welcome message with Messenger dedicated message` () { ext . send { lastAnswer . assertMessage ( buttonsTemplate ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , postbackButton ( Itineraries , search ), postbackButton ( Departures , Departures ), postbackButton ( Arrivals , Arrivals ) ) ) } } To test the message specific to Google Assistant (or any other connector), you need to indicate the connector to be tested: @Test fun `greetings story displays welcome message with GA dedicated message WHEN context contains GA connector` () { ext . send ( connectorType = gaConnectorType ) { firstAnswer . assertText ( Welcome to the Tock Open Data Bot! :) ) secondAnswer . assertText ( This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock ) lastAnswer . assertMessage ( gaMessage ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , Itineraries , Departures , Arrivals ) ) } } Test a specific Story In the previous examples, it was useless to specify the story to test ( greetings being the default story). Suppose you want to test the search story, then you need to indicate the story to test as follows: @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search ) { firstAnswer . assertText ( For which destination? ) } } Test a Conversation You can simulate a whole conversation. For example, here the user indicates the destination, then the origin: @Test fun `search story asks for origin WHEN there is a destination BUT no origin in context` () { ext . send ( I would like to find a train , search ) { firstAnswer . assertText ( For which destination? ) } ext . send ( Lille , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( For which origin? ) } ext . send ( Paris , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( When? ) } } The first text parameter of the send method is merely indicative, to help understanding the tests. The others parameters defines how the NLP engine has analysed the text. For example : private val lille = PlaceValue ( SncfPlace ( stop_area , 90 , Lille Europe , Lille Europe (Lille) , stop_area:OCE:SA:87223263 , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( Lille , indicate_location , locationEntity setTo lille ) indicate that the phrase \"Lille\" is categorized as an indicate_location intent with a value lille for the entity location . Finally it is possible to modify all the values of the mocked bus at initialization. In the following example, the use of the secondary intent indicate_location is simulated to indicate the origin: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( Search , search ) { destination = lille origin = paris run () firstAnswer . assertText ( When? ) } } The destination and origin variables are updated, then a call to the bus is simulated with the function run() .","title":"Use the Test Framework"},{"location":"test-the-bot/#use-the-test-framework","text":"Tock provides extensions in order to help writing better unit tests. To use them, you need to add the bot-test dependency to your project. With Maven : dependency groupId ai.tock /groupId artifactId bot-test /artifactId version 20.3.1 /version scope test /scope /dependency With Gradle : testCompile ai.tock:bot-test:20.3.1 This framework is documented in KDoc format [here]https://doc.tock.ai/tock/dokka/tock/ai.tock.bot.test).","title":"Use the Test Framework"},{"location":"test-the-bot/#write-a-simple-test","text":"In the next samples, JUnit5 is used as test engine. A dedicated extension for Tock is available . @RegisterExtension @JvmField val ext = TockJUnit5Extension () To test the greetings story of the Open Data bot, just use the ext.send() method: @Test fun `greetings story displays welcome message` () { ext . send { firstAnswer . assertText ( Welcome to the Tock Open Data Bot! :) ) secondAnswer . assertText ( This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock ) } } As the default connector is Messenger, it is possible to test the message specific to Messenger in the same way: @Test fun `greetings story displays welcome message with Messenger dedicated message` () { ext . send { lastAnswer . assertMessage ( buttonsTemplate ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , postbackButton ( Itineraries , search ), postbackButton ( Departures , Departures ), postbackButton ( Arrivals , Arrivals ) ) ) } } To test the message specific to Google Assistant (or any other connector), you need to indicate the connector to be tested: @Test fun `greetings story displays welcome message with GA dedicated message WHEN context contains GA connector` () { ext . send ( connectorType = gaConnectorType ) { firstAnswer . assertText ( Welcome to the Tock Open Data Bot! :) ) secondAnswer . assertText ( This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock ) lastAnswer . assertMessage ( gaMessage ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , Itineraries , Departures , Arrivals ) ) } }","title":"Write a Simple Test"},{"location":"test-the-bot/#test-a-specific-story","text":"In the previous examples, it was useless to specify the story to test ( greetings being the default story). Suppose you want to test the search story, then you need to indicate the story to test as follows: @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search ) { firstAnswer . assertText ( For which destination? ) } }","title":"Test a specific Story"},{"location":"test-the-bot/#test-a-conversation","text":"You can simulate a whole conversation. For example, here the user indicates the destination, then the origin: @Test fun `search story asks for origin WHEN there is a destination BUT no origin in context` () { ext . send ( I would like to find a train , search ) { firstAnswer . assertText ( For which destination? ) } ext . send ( Lille , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( For which origin? ) } ext . send ( Paris , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( When? ) } } The first text parameter of the send method is merely indicative, to help understanding the tests. The others parameters defines how the NLP engine has analysed the text. For example : private val lille = PlaceValue ( SncfPlace ( stop_area , 90 , Lille Europe , Lille Europe (Lille) , stop_area:OCE:SA:87223263 , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( Lille , indicate_location , locationEntity setTo lille ) indicate that the phrase \"Lille\" is categorized as an indicate_location intent with a value lille for the entity location . Finally it is possible to modify all the values of the mocked bus at initialization. In the following example, the use of the secondary intent indicate_location is simulated to indicate the origin: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( Search , search ) { destination = lille origin = paris run () firstAnswer . assertText ( When? ) } } The destination and origin variables are updated, then a call to the bus is simulated with the function run() .","title":"Test a Conversation"},{"location":"the-open-data-bot/","text":"The Open Data Bot example An integrated bot sample is available: the Open Data Bot . The Open Data Bot A good starting point is the source code of the Open Data Bot Follow the instructions of the README file of the project, to start the bot in the IDE (do not configure Messenger or Google Assistant at this point), then connect to the administration interface. The bot is already testable. The Test Tab Go to this tab, and test the bot: This is a test mode, so the interface is minimal. The real goal is to have your users interact with the bot via channels like Messenger, Google Assistant ... or your sites or applications. The Monitoring Tab It is then possible to consult the discussion that you just had with the bot via the Monitoring tab: In this sample, this dialog has the Messenger flag, as it was tested for this channel. The Build Tab Add a new answer With the category Add new Answer , it is possible to add directly a new answer: Then test the new intention and its answer: Modify the Answers and Internationalization Finally it is possible to modify each answer of the bot, by type of interface (chat / voice), by type of connector and by language with the i18n tab. The ability to add alternative answers (a response from the list will be chosen each time at random) is also provided (with the \"plus\" button).","title":"Code Samples"},{"location":"the-open-data-bot/#the-open-data-bot-example","text":"An integrated bot sample is available: the Open Data Bot .","title":"The Open Data Bot example"},{"location":"the-open-data-bot/#the-open-data-bot","text":"A good starting point is the source code of the Open Data Bot Follow the instructions of the README file of the project, to start the bot in the IDE (do not configure Messenger or Google Assistant at this point), then connect to the administration interface. The bot is already testable.","title":"The Open Data Bot"},{"location":"the-open-data-bot/#the-test-tab","text":"Go to this tab, and test the bot: This is a test mode, so the interface is minimal. The real goal is to have your users interact with the bot via channels like Messenger, Google Assistant ... or your sites or applications.","title":"The Test Tab"},{"location":"the-open-data-bot/#the-monitoring-tab","text":"It is then possible to consult the discussion that you just had with the bot via the Monitoring tab: In this sample, this dialog has the Messenger flag, as it was tested for this channel.","title":"The Monitoring Tab"},{"location":"the-open-data-bot/#the-build-tab","text":"","title":"The Build Tab"},{"location":"the-open-data-bot/#add-a-new-answer","text":"With the category Add new Answer , it is possible to add directly a new answer: Then test the new intention and its answer:","title":"Add a new answer"},{"location":"the-open-data-bot/#modify-the-answers-and-internationalization","text":"Finally it is possible to modify each answer of the bot, by type of interface (chat / voice), by type of connector and by language with the i18n tab. The ability to add alternative answers (a response from the list will be chosen each time at random) is also provided (with the \"plus\" button).","title":"Modify the Answers and Internationalization"},{"location":"toc/","text":"Tock documentation Overview Table of contents Try Tock : Create your first bot with Tock Studio Configure your bot for Slack Configure your bot for Messenger Program stories using the Bot API mode Deploy a standalone Tock platform with Docker Use Tock : Conversational concepts for Tock Tock Studio interfaces : General interface The Configuration menu The NLU menu The NLU QA menu The Build menu The Test menu The Monitoring menu Build your conversational model Create a multichannel bot (connectors) Create a multilingual bot (internationalization) Develop with Tock : Available modes Tock Bot API Tock Integrated Bot Unit Tests Connectors Internationalization ( i18n ) Tock APIs Code samples Run administrate Tock : Functional and technical architecture Installation Security High Availability Monitoring Cloud About Tock : Why Tock Showcase Resources press kit Contact us Community Contribute Jobs","title":"Tock documentation"},{"location":"toc/#tock-documentation","text":"Overview Table of contents Try Tock : Create your first bot with Tock Studio Configure your bot for Slack Configure your bot for Messenger Program stories using the Bot API mode Deploy a standalone Tock platform with Docker Use Tock : Conversational concepts for Tock Tock Studio interfaces : General interface The Configuration menu The NLU menu The NLU QA menu The Build menu The Test menu The Monitoring menu Build your conversational model Create a multichannel bot (connectors) Create a multilingual bot (internationalization) Develop with Tock : Available modes Tock Bot API Tock Integrated Bot Unit Tests Connectors Internationalization ( i18n ) Tock APIs Code samples Run administrate Tock : Functional and technical architecture Installation Security High Availability Monitoring Cloud About Tock : Why Tock Showcase Resources press kit Contact us Community Contribute Jobs","title":"Tock documentation"},{"location":"about/community/","text":"Community Tock has been designed to remain an open platform shared with the community. To know more, see why Tock . Next events / Meetup This lists the next planed events related to Tock, as well as groups identified to share with the community: November: SNCF sets up an open Hackathon event in Paris the 21-22 of November around conversational AI with Tock December: A talk at the Paris Open Source Summit , titled \"Conversational AI Open Source\" , is scheduled the 11th of December (16:30). SNCF as well as Botfront.io will present their shared convictions about open platforms for conversational AI TOSIT association The Tock solution is currently being assessed by the TOSIT (The Open Source I Trust) , an association dedicated to support Open Source and Free Software, as part of the Chatbots Work Group. Founded by Carrefour, EDF, Enedis, Orange, P\u00f4le Emploi and SNCF, TOSIT now gathers other important members, such as the (French) Minist\u00e8re des Arm\u00e9es, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale or MAIF. Several TOSIT members, including SNCF, already use or experiment Tock. To know more about TOSIT, please visit http://tosit.fr/ GitHub Gitter The Tock platform and tools are available on https://github.com/theopenconversationkit/tock under the Apache 2 license . Sources License Versions Issues Contributors Gitter Demo To know more about repository structure, coding conventions, etc. refer to the contribute to Tock section. Help Feel free to contact us .","title":"Community"},{"location":"about/community/#community","text":"Tock has been designed to remain an open platform shared with the community. To know more, see why Tock .","title":"Community"},{"location":"about/community/#next-events-meetup","text":"This lists the next planed events related to Tock, as well as groups identified to share with the community: November: SNCF sets up an open Hackathon event in Paris the 21-22 of November around conversational AI with Tock December: A talk at the Paris Open Source Summit , titled \"Conversational AI Open Source\" , is scheduled the 11th of December (16:30). SNCF as well as Botfront.io will present their shared convictions about open platforms for conversational AI","title":"Next events / Meetup"},{"location":"about/community/#tosit-association","text":"The Tock solution is currently being assessed by the TOSIT (The Open Source I Trust) , an association dedicated to support Open Source and Free Software, as part of the Chatbots Work Group. Founded by Carrefour, EDF, Enedis, Orange, P\u00f4le Emploi and SNCF, TOSIT now gathers other important members, such as the (French) Minist\u00e8re des Arm\u00e9es, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale or MAIF. Several TOSIT members, including SNCF, already use or experiment Tock. To know more about TOSIT, please visit http://tosit.fr/","title":"TOSIT association"},{"location":"about/community/#github-gitter","text":"The Tock platform and tools are available on https://github.com/theopenconversationkit/tock under the Apache 2 license . Sources License Versions Issues Contributors Gitter Demo To know more about repository structure, coding conventions, etc. refer to the contribute to Tock section.","title":"GitHub &amp; Gitter"},{"location":"about/community/#help","text":"Feel free to contact us .","title":"Help"},{"location":"about/contact/","text":"Contact us Developers, users and curious people are more than welcome to share about Tock with both its creators and the community. Don't hesitate to join us on Gitter (the instant messaging service for GitHub): https://gitter.im/tockchat/Lobby GitHub issues can be used to keep track of bugs, enhancements or feature requests: https://github.com/theopenconversationkit/tock/issues","title":"Contact us"},{"location":"about/contact/#contact-us","text":"Developers, users and curious people are more than welcome to share about Tock with both its creators and the community. Don't hesitate to join us on Gitter (the instant messaging service for GitHub): https://gitter.im/tockchat/Lobby GitHub issues can be used to keep track of bugs, enhancements or feature requests: https://github.com/theopenconversationkit/tock/issues","title":"Contact us"},{"location":"about/contribute/","text":"Contribute to Tock The Tock project is open to contribution and any feedback is welcome! This page details the source structure and coding conventions for the platform. Main technologies The applicative platform is the JVM . The reference language is Kotlin , but other programming languages can be used through the provided API. Tock leverages Vert.x and MongoDB . Graphical interfaces (namely Tock Studio ) are powered by Angular in Typescript . Source structure Repositories tock : main source repository, including the framework and platform components under the Apache 2 license . tock-corenlp : optional module, leveraging a dependency to Stanford CoreNLP (instead of Apache OpenNLP ), under GPL license . tock-docker : Docker and Docker Compose images/descriptors, for platform hands-on and fast deployment of various configuations. tock-bot-samples : code samples, in particular the WebHook and WebSocket modes examples from Tock programing guides . tock-bot-open-data : a bot example, based on the SNCF Open Data API , also implementing basic internationalization ( i18n ) mecanisms with two distinct languages. The tock repository TODO : detail modules and repo structure Le tock-docker repository TODO : detail modules and repo structure, how Maven and Docker builds work, etc. Build Tock from sources Tock (core) Tock is built with Maven , including the Web modules leveraging NPM et Angular : $ mvn package Continuous integration build jobs are available on Travis . Docker images Tock Docker images can be rebuilt from sources, included in repository tock-docker . One can use Maven to trigger the Docker build: $ mvn docker:build Docker containers can then be instantiated from images, or Docker Compose stacks from the various descriptors at the root of the repository. Run in IDE To run Tock using Docker Compose outside the IDE, rather see Deploy Tock with Docker . Tock components (NLU, Studio, bot...) can run in an IDE, such as IntelliJ , Eclipse or Visual Studio Code for instance. Beside the Docker images , IntelliJ configurations are provided with Tock sources: The Tock Studio interfaces/server: BotAdmin The alternative standalone NLU interfaces/server: Admin The NLU service: NlpService The Duckling entity-recognition service: Duckling The NLU model-builder service: BuildWorker The script compilation service: KotlinCompilerServer The OpenDataBot example also has a run configuration available: OpenDataBot To start the Tock Studio interfaces, please refer to the commands described in the following pages: Full Tock Studio server commands Standalone NLU server commands Conventions Kotlin Code Conventions are used to develop Tock. Contact us To contribute to the project or to known more about the implementation, feel free to contact us . Ideas and feedback is more than welcome.","title":"Contribute"},{"location":"about/contribute/#contribute-to-tock","text":"The Tock project is open to contribution and any feedback is welcome! This page details the source structure and coding conventions for the platform.","title":"Contribute to Tock"},{"location":"about/contribute/#main-technologies","text":"The applicative platform is the JVM . The reference language is Kotlin , but other programming languages can be used through the provided API. Tock leverages Vert.x and MongoDB . Graphical interfaces (namely Tock Studio ) are powered by Angular in Typescript .","title":"Main technologies"},{"location":"about/contribute/#source-structure","text":"","title":"Source structure"},{"location":"about/contribute/#repositories","text":"tock : main source repository, including the framework and platform components under the Apache 2 license . tock-corenlp : optional module, leveraging a dependency to Stanford CoreNLP (instead of Apache OpenNLP ), under GPL license . tock-docker : Docker and Docker Compose images/descriptors, for platform hands-on and fast deployment of various configuations. tock-bot-samples : code samples, in particular the WebHook and WebSocket modes examples from Tock programing guides . tock-bot-open-data : a bot example, based on the SNCF Open Data API , also implementing basic internationalization ( i18n ) mecanisms with two distinct languages.","title":"Repositories"},{"location":"about/contribute/#the-tock-repository","text":"TODO : detail modules and repo structure","title":"The tock repository"},{"location":"about/contribute/#le-tock-docker-repository","text":"TODO : detail modules and repo structure, how Maven and Docker builds work, etc.","title":"Le tock-docker repository"},{"location":"about/contribute/#build-tock-from-sources","text":"","title":"Build Tock from sources"},{"location":"about/contribute/#tock-core","text":"Tock is built with Maven , including the Web modules leveraging NPM et Angular : $ mvn package Continuous integration build jobs are available on Travis .","title":"Tock (core)"},{"location":"about/contribute/#docker-images","text":"Tock Docker images can be rebuilt from sources, included in repository tock-docker . One can use Maven to trigger the Docker build: $ mvn docker:build Docker containers can then be instantiated from images, or Docker Compose stacks from the various descriptors at the root of the repository.","title":"Docker images"},{"location":"about/contribute/#run-in-ide","text":"To run Tock using Docker Compose outside the IDE, rather see Deploy Tock with Docker . Tock components (NLU, Studio, bot...) can run in an IDE, such as IntelliJ , Eclipse or Visual Studio Code for instance. Beside the Docker images , IntelliJ configurations are provided with Tock sources: The Tock Studio interfaces/server: BotAdmin The alternative standalone NLU interfaces/server: Admin The NLU service: NlpService The Duckling entity-recognition service: Duckling The NLU model-builder service: BuildWorker The script compilation service: KotlinCompilerServer The OpenDataBot example also has a run configuration available: OpenDataBot To start the Tock Studio interfaces, please refer to the commands described in the following pages: Full Tock Studio server commands Standalone NLU server commands","title":"Run in IDE"},{"location":"about/contribute/#conventions","text":"Kotlin Code Conventions are used to develop Tock.","title":"Conventions"},{"location":"about/contribute/#contact-us","text":"To contribute to the project or to known more about the implementation, feel free to contact us . Ideas and feedback is more than welcome.","title":"Contact us"},{"location":"about/jobs/","text":"Tock jobs Interested in working with Tock and contribute to the platform? This page lists companies and organizations, proposing job offers in the field of conversational AI with Tock: e.Voyageurs SNCF (Tock creators) recruit various profiles to build conversational assistants with Tock. To known more, check offers on Gitter or https://jobs.oui.sncf/ . Do you leverage Tock and offer conversational jobs? Don't hesitate to tell us and expand the list.","title":"Jobs"},{"location":"about/jobs/#tock-jobs","text":"Interested in working with Tock and contribute to the platform? This page lists companies and organizations, proposing job offers in the field of conversational AI with Tock: e.Voyageurs SNCF (Tock creators) recruit various profiles to build conversational assistants with Tock. To known more, check offers on Gitter or https://jobs.oui.sncf/ . Do you leverage Tock and offer conversational jobs? Don't hesitate to tell us and expand the list.","title":"Tock jobs"},{"location":"about/resources/","text":"Tock resources This page lists various presentations of Tock, giving an overview of the solution in addition to the main documentation and demo instance. Conferences / video (in French) Code a bot for Messenger and Google Assistant in 30 minutes @ Devoxx France 2018 (live coding \"tools in action\" 30 min) Meetup / Slides (in French) Tock - The Open Conversation Kit @ Meetup Open Transport (2019) Tock - The Open Conversation Kit @ CRiP OpenSource Co-d\u00e9veloppement (2017) Don't hesitate to share with us more slides, documents and links about Tock. Press kit Tock logos are provided under the Apache 2 license . Tock logo - default colors / transparent ( download ) : Tock logo - blue / transparent ( download ) : Tock logo - black / transparent ( download ) : Tock logo - white / transparent ( download ) :","title":"Resources"},{"location":"about/resources/#tock-resources","text":"This page lists various presentations of Tock, giving an overview of the solution in addition to the main documentation and demo instance.","title":"Tock resources"},{"location":"about/resources/#conferences-video-in-french","text":"Code a bot for Messenger and Google Assistant in 30 minutes @ Devoxx France 2018 (live coding \"tools in action\" 30 min)","title":"Conferences / video (in French)"},{"location":"about/resources/#meetup-slides-in-french","text":"Tock - The Open Conversation Kit @ Meetup Open Transport (2019) Tock - The Open Conversation Kit @ CRiP OpenSource Co-d\u00e9veloppement (2017) Don't hesitate to share with us more slides, documents and links about Tock.","title":"Meetup / Slides (in French)"},{"location":"about/resources/#press-kit","text":"Tock logos are provided under the Apache 2 license . Tock logo - default colors / transparent ( download ) : Tock logo - blue / transparent ( download ) : Tock logo - black / transparent ( download ) : Tock logo - white / transparent ( download ) :","title":"Press kit"},{"location":"about/showcase/","text":"User showcase Since its creation for OUI.sncf in 2016, Tock has been used by more and more teams to build conversational bots dedicated to various use cases : business to customer and business to business e-commerce, transactions, payment assistance, care, help desks FAQ and decision trees This page presents various assistants and products built and powered by Tock. AlloCovid The AlloCovid conversational service informs and guides French population about the Covid-19. It results from the collaboration of numerous French experts, tech partners and volunteers. To find out more about the project, the team and partners, how the bot works, etc. visit www.allocovid.com . Available by phone, on the Web and WhatsApp, AlloCovid builds around a Tock bot and integrates with additional technologies such as Allo-Media and Voxygen voice solutions. The AlloCovid bot is powered by open source technologies (Tock) and open source itself: its sources are available on repository allocovid . The source repository also includes the Allo-Media connector , technical details about the bot and its functional specification . Name: AlloCovid Date of birth: in production since spring 2020 Field: health information and guidance Channels: text voice, by phone, on WhatsApp and Website OUIbot , the OUI.sncf bot OUIbot is the conversational assistant from OUI.sncf. Available since 2016 on Facebook Messenger, OUIbot was built along with the first versions of Tock. With OUIbot, booking a train ticket has never been easier! It assists you in the preparation of your trips, allows you to make a complete reservation quickly and easily, from research to purchase (payment included), and accompanies you during your trip. Thanks to the numerous connectors, OUIbot is now available on multiple conversational channels, such as the company Website www.oui.sncf , social networks, voice assistants, smart display and even SmartBrics with JCDecaux devices. In 2019, OUIbot answers approximately 10.000 users a day. It has been awarded Best Robot Experience for the second year in a row. Name: OUIbot Date of birth: in production since 2016 Field: e-commerce/travel, transactions (booking, payment), alerts push notifications, push messages to an agent Channels: text voice, on the company Website, Messenger, WhatsApp, Business Chat (Messages), Google Assistant, Google Home, Alexa, JCDecaux SmartBrics L'Assistant SNCF L' Assistant SNCF is the mobile application for SNCF passengers on Android and iOS, covering both trains and other modes of transport. With L' Assistant (the SNCF Assistant), you can plan your itinerary, stay informed in real time, buy your transport tickets directly or book a taxi ride. More features are yet to come. Accessible via the \"microphone\" in the mobile application, le SNCF Assistant's conversational bot is built with Tock plus the speech-to-text Android and iOS functions. Name: L' Assistant SNCF Date of birth: in production, featuring Tock voice function since 2019 Field: travel transport (multi-modal route research, etc.) Channels: voice, on the SNCF mobile application for Android and iOS Tilien , the Transilien chatbot Tilien is the Transilien chatbot on Messenger. Designed as a personal and friendly travel companion, it informs you about upcoming departures, the service status, current and future works, itineraries and much more (route plans, timetables, etc.) on the entire Ile-De-France rail network: Metro, RER, Transilien, Tram. Powered by Tock, the chatbot is waiting for you on Facebook Messenger. Name: Tilien Date of birth: in production, since 2018 with Tock Field: transport assistance (route research, route plans, traffic conditions, etc.) Channels: text, on Messenger ( botsncftransilien ) Mon Assistant TGV INOUI Mon Assistant advises customers and travellers of the TGV INOUI brand before, during and after their journey. The chatbot can tell you all about the service status, train departure platforms, customer seats, onboard services (bar, electrical outlets, etc.). It also allows you to talk with a SNCF agents while remaining in the same conversation. Located on the TGV INOUI Facebook page, the assistant based on Tock is also accessible from the E-Ticket reminder SMS or directly from the application. Name: Mon Assistant TGV INOUI Date of birth: in production since 2019 Field: assistance passenger information (dock information, current travel information, on-board services), relay to an agent Channels: text, on Messenger ( TGV INOUI ) L' Agent virtuel SNCF L' Agent virtuel SNCF (SNCF Virtual Assistant) presents passenger information and any disruptions on all trains (TGV, Intercites, TER, Eurostar, etc.) in a conversational manner. Query the bot by train number, passenger file, next departures, etc. to get the latest information and traffic status. Accessible via the SNCF Facebook page, the Agent virtuel is based on Tock. Name: Agent virtuel SNCF Date of birth: in production since 2019 Field: travel transport (traffic situation, works, next departures), relay to an agent Channels: text, on Messenger ( SNCFOFFICIEL ) and Twitter ( @sncf ) Eve , the e-voyageurs internal assistant Eve is the internal assistant of e-voyageurs SNCF employees. The chatbot answers common questions, refers to the right interlocutors and collaborative tools of the company, automates common requests to IT Support, General Services, Legal Department, etc. DevOps teams can also ask it for production status, next planned operations, or even to manage certain operations directly for greater simplicity and reactivity. Eve is always listening to the employees, both within the offices and on-the-go using Teams applications with Tock. Name: Eve Date of birth: in production since 2019 Field: internal B2B support (FAQ, IT Support, HR, Legal), DevOps automation (monitoring, deployments, production management, etc.) Channels: text voice, internally within the offices and on-the-go via Teams What about you? As a generic platform, Tock enables numerous use cases and integration of internal as well as external channels. Please feel free to contact us in case of doubts or questions about Tock features or possibilities for a new project of your own. And don't hesitate to share your achievements with the community! \ud83d\ude42","title":"Showcase"},{"location":"about/showcase/#user-showcase","text":"Since its creation for OUI.sncf in 2016, Tock has been used by more and more teams to build conversational bots dedicated to various use cases : business to customer and business to business e-commerce, transactions, payment assistance, care, help desks FAQ and decision trees This page presents various assistants and products built and powered by Tock.","title":"User showcase"},{"location":"about/showcase/#allocovid","text":"The AlloCovid conversational service informs and guides French population about the Covid-19. It results from the collaboration of numerous French experts, tech partners and volunteers. To find out more about the project, the team and partners, how the bot works, etc. visit www.allocovid.com . Available by phone, on the Web and WhatsApp, AlloCovid builds around a Tock bot and integrates with additional technologies such as Allo-Media and Voxygen voice solutions. The AlloCovid bot is powered by open source technologies (Tock) and open source itself: its sources are available on repository allocovid . The source repository also includes the Allo-Media connector , technical details about the bot and its functional specification . Name: AlloCovid Date of birth: in production since spring 2020 Field: health information and guidance Channels: text voice, by phone, on WhatsApp and Website","title":"AlloCovid"},{"location":"about/showcase/#ouibot-the-ouisncf-bot","text":"OUIbot is the conversational assistant from OUI.sncf. Available since 2016 on Facebook Messenger, OUIbot was built along with the first versions of Tock. With OUIbot, booking a train ticket has never been easier! It assists you in the preparation of your trips, allows you to make a complete reservation quickly and easily, from research to purchase (payment included), and accompanies you during your trip. Thanks to the numerous connectors, OUIbot is now available on multiple conversational channels, such as the company Website www.oui.sncf , social networks, voice assistants, smart display and even SmartBrics with JCDecaux devices. In 2019, OUIbot answers approximately 10.000 users a day. It has been awarded Best Robot Experience for the second year in a row. Name: OUIbot Date of birth: in production since 2016 Field: e-commerce/travel, transactions (booking, payment), alerts push notifications, push messages to an agent Channels: text voice, on the company Website, Messenger, WhatsApp, Business Chat (Messages), Google Assistant, Google Home, Alexa, JCDecaux SmartBrics","title":"OUIbot, the OUI.sncf bot"},{"location":"about/showcase/#lassistant-sncf","text":"L' Assistant SNCF is the mobile application for SNCF passengers on Android and iOS, covering both trains and other modes of transport. With L' Assistant (the SNCF Assistant), you can plan your itinerary, stay informed in real time, buy your transport tickets directly or book a taxi ride. More features are yet to come. Accessible via the \"microphone\" in the mobile application, le SNCF Assistant's conversational bot is built with Tock plus the speech-to-text Android and iOS functions. Name: L' Assistant SNCF Date of birth: in production, featuring Tock voice function since 2019 Field: travel transport (multi-modal route research, etc.) Channels: voice, on the SNCF mobile application for Android and iOS","title":"L'Assistant SNCF"},{"location":"about/showcase/#tilien-the-transilien-chatbot","text":"Tilien is the Transilien chatbot on Messenger. Designed as a personal and friendly travel companion, it informs you about upcoming departures, the service status, current and future works, itineraries and much more (route plans, timetables, etc.) on the entire Ile-De-France rail network: Metro, RER, Transilien, Tram. Powered by Tock, the chatbot is waiting for you on Facebook Messenger. Name: Tilien Date of birth: in production, since 2018 with Tock Field: transport assistance (route research, route plans, traffic conditions, etc.) Channels: text, on Messenger ( botsncftransilien )","title":"Tilien, the Transilien chatbot"},{"location":"about/showcase/#mon-assistant-tgv-inoui","text":"Mon Assistant advises customers and travellers of the TGV INOUI brand before, during and after their journey. The chatbot can tell you all about the service status, train departure platforms, customer seats, onboard services (bar, electrical outlets, etc.). It also allows you to talk with a SNCF agents while remaining in the same conversation. Located on the TGV INOUI Facebook page, the assistant based on Tock is also accessible from the E-Ticket reminder SMS or directly from the application. Name: Mon Assistant TGV INOUI Date of birth: in production since 2019 Field: assistance passenger information (dock information, current travel information, on-board services), relay to an agent Channels: text, on Messenger ( TGV INOUI )","title":"Mon Assistant TGV INOUI"},{"location":"about/showcase/#l-agent-virtuel-sncf","text":"L' Agent virtuel SNCF (SNCF Virtual Assistant) presents passenger information and any disruptions on all trains (TGV, Intercites, TER, Eurostar, etc.) in a conversational manner. Query the bot by train number, passenger file, next departures, etc. to get the latest information and traffic status. Accessible via the SNCF Facebook page, the Agent virtuel is based on Tock. Name: Agent virtuel SNCF Date of birth: in production since 2019 Field: travel transport (traffic situation, works, next departures), relay to an agent Channels: text, on Messenger ( SNCFOFFICIEL ) and Twitter ( @sncf )","title":"L' Agent virtuel SNCF"},{"location":"about/showcase/#eve-the-e-voyageurs-internal-assistant","text":"Eve is the internal assistant of e-voyageurs SNCF employees. The chatbot answers common questions, refers to the right interlocutors and collaborative tools of the company, automates common requests to IT Support, General Services, Legal Department, etc. DevOps teams can also ask it for production status, next planned operations, or even to manage certain operations directly for greater simplicity and reactivity. Eve is always listening to the employees, both within the offices and on-the-go using Teams applications with Tock. Name: Eve Date of birth: in production since 2019 Field: internal B2B support (FAQ, IT Support, HR, Legal), DevOps automation (monitoring, deployments, production management, etc.) Channels: text voice, internally within the offices and on-the-go via Teams","title":"Eve, the e-voyageurs internal assistant"},{"location":"about/showcase/#what-about-you","text":"As a generic platform, Tock enables numerous use cases and integration of internal as well as external channels. Please feel free to contact us in case of doubts or questions about Tock features or possibilities for a new project of your own. And don't hesitate to share your achievements with the community! \ud83d\ude42","title":"What about you?"},{"location":"about/why/","text":"Why Tock? Created in 2016 by the OUI.sncf Innovation team to implement voice-command on its mobile applications , the framework has then been used to create the Messenger chatbot , before being extended to support numerous channels and other bots with more use cases. At first the platform showed results, similar to other available solutions on the market, while keeping the code in control (relying on opensource libraries and academic solutions) and preventing \"black box\" effects (eg. debugging conversational models) for more reactive agility. Since then, the team behind OUIbot as well as other teams, dedicated to various conversational assistants at SNCF (see the showcase ) use Tock every day in production and add new features and connectors to the platform on a regular basis. We are convinced there is a need for open AI and conversational platforms , enabling various technical and business cases while keeping the code in control and the ownership of models and data . More and more partners and third-parties, small and big companies in France and worldwide, share this vision and requirement for their own projects. The complete Tock solution is shared with the community in order to federate and mutualize efforts from assistant builders.","title":"Why Tock"},{"location":"about/why/#why-tock","text":"Created in 2016 by the OUI.sncf Innovation team to implement voice-command on its mobile applications , the framework has then been used to create the Messenger chatbot , before being extended to support numerous channels and other bots with more use cases. At first the platform showed results, similar to other available solutions on the market, while keeping the code in control (relying on opensource libraries and academic solutions) and preventing \"black box\" effects (eg. debugging conversational models) for more reactive agility. Since then, the team behind OUIbot as well as other teams, dedicated to various conversational assistants at SNCF (see the showcase ) use Tock every day in production and add new features and connectors to the platform on a regular basis. We are convinced there is a need for open AI and conversational platforms , enabling various technical and business cases while keeping the code in control and the ownership of models and data . More and more partners and third-parties, small and big companies in France and worldwide, share this vision and requirement for their own projects. The complete Tock solution is shared with the community in order to federate and mutualize efforts from assistant builders.","title":"Why Tock?"},{"location":"dev/bot-api/","text":"Tock Bot API Mode This is the recommended way to start to develop with Tock. You add custom answers using a REST API. Kotlin client and Node client are available. Connect to the demo platform Rather than deploying its own Tock platform, it is possible to test the WebSocket or Webhook modes directly on the Tock demo platform . Develop with Kotlin Enable WebSocket mode This is the preferred mode at startup. To use the websocket client, add the tock-bot-api-websocket dependency to your Kotlin application / project. Using Maven : dependency groupId ai.tock /groupId artifactId tock-bot-api-websocket /artifactId version 20.3.1 /version /dependency Or Gradle : compile ai.tock:tock-bot-api-websocket:20.3.1 Enable WebHook mode Alternatively, you can choose to use the WebHook client. Add the tock-bot-api-webhook dependency to your Kotlin application / project. Using Maven : dependency groupId ai.tock /groupId artifactId tock-bot-api-webhook /artifactId version 20.3.1 /version /dependency Or Gradle : compile ai.tock:tock-bot-api-webhook:20.3.1 In this case, unlike the WebSocket mode, the bot application must be reachable by the Tock platform and so has to expose a public URL (you can use ngrok in order to provide this URL). This URL must be specified in the webhook url field in the Configuration Bot Configurations view of Tock Studio . Set up the API key In Tock Studio , after configuring a bot, go to Configuration Bot Configurations and copy the API key of the bot to which you want to connect. You can enter / paste this key into the Kotlin code (see below). Create Stories The following formats are supported: Text with Buttons (Quick Replies) \"Card\" format \"Carousel\" format Specific channel formats like Messenger format, Slack format, etc. Here is a simple bot with a few stories: fun main () { startWithDemo ( newBot ( PUT-YOUR-TOCK-APP-API-KEY-HERE , // Get your app API key from Bot Configurations in Tock Studio newStory ( greetings ) { // Intent greetings end ( Hello! ) // Raw text answer }, newStory ( location ) { // Intent location end ( // Anwser with a card - including text, file(image, video,..) and user action suggestions newCard ( Card title , Card sub title , newAttachment ( https://url-image.png ), newAction ( Action 1 ), newAction ( Action 2 , http://redirection ) ) ) }, newStory ( goodbye ) { // Intent goodbye end { // Answer with Messenger-specific button/quick reply buttonsTemplate ( Are you sure ? , nlpQuickReply ( Stay here )) } }, // Fallback answer when the bot does find a correct response unknownStory { end ( Sorry I don t understand :( ) } ) ) } Please consult the full source code sample . Develop in another language Node Please consult the dedicated node client documentation. API It is possible to develop in the language of your choice by using directly the underlying REST API. Install Bot API on your own servers To use Tock's Bot API mode without the demo platform, a specific module must be deployed on your own server. Called bot-api in Docker Compose descriptors, this service: Expose the Bot API to the potential customers whatever their programming language are. Accept WebSocket connections and / or connections to the configured webhook. Compared to the \"demo mode\", The only required change in the code is to replace the startWithDemo method with the start one, specifying the bot-api target server address.","title":"Bot API mode"},{"location":"dev/bot-api/#tock-bot-api-mode","text":"This is the recommended way to start to develop with Tock. You add custom answers using a REST API. Kotlin client and Node client are available.","title":"Tock Bot API Mode"},{"location":"dev/bot-api/#connect-to-the-demo-platform","text":"Rather than deploying its own Tock platform, it is possible to test the WebSocket or Webhook modes directly on the Tock demo platform .","title":"Connect to the demo platform"},{"location":"dev/bot-api/#develop-with-kotlin","text":"","title":"Develop with Kotlin"},{"location":"dev/bot-api/#enable-websocket-mode","text":"This is the preferred mode at startup. To use the websocket client, add the tock-bot-api-websocket dependency to your Kotlin application / project. Using Maven : dependency groupId ai.tock /groupId artifactId tock-bot-api-websocket /artifactId version 20.3.1 /version /dependency Or Gradle : compile ai.tock:tock-bot-api-websocket:20.3.1","title":"Enable WebSocket mode"},{"location":"dev/bot-api/#enable-webhook-mode","text":"Alternatively, you can choose to use the WebHook client. Add the tock-bot-api-webhook dependency to your Kotlin application / project. Using Maven : dependency groupId ai.tock /groupId artifactId tock-bot-api-webhook /artifactId version 20.3.1 /version /dependency Or Gradle : compile ai.tock:tock-bot-api-webhook:20.3.1 In this case, unlike the WebSocket mode, the bot application must be reachable by the Tock platform and so has to expose a public URL (you can use ngrok in order to provide this URL). This URL must be specified in the webhook url field in the Configuration Bot Configurations view of Tock Studio .","title":"Enable WebHook mode"},{"location":"dev/bot-api/#set-up-the-api-key","text":"In Tock Studio , after configuring a bot, go to Configuration Bot Configurations and copy the API key of the bot to which you want to connect. You can enter / paste this key into the Kotlin code (see below).","title":"Set up the API key"},{"location":"dev/bot-api/#create-stories","text":"The following formats are supported: Text with Buttons (Quick Replies) \"Card\" format \"Carousel\" format Specific channel formats like Messenger format, Slack format, etc. Here is a simple bot with a few stories: fun main () { startWithDemo ( newBot ( PUT-YOUR-TOCK-APP-API-KEY-HERE , // Get your app API key from Bot Configurations in Tock Studio newStory ( greetings ) { // Intent greetings end ( Hello! ) // Raw text answer }, newStory ( location ) { // Intent location end ( // Anwser with a card - including text, file(image, video,..) and user action suggestions newCard ( Card title , Card sub title , newAttachment ( https://url-image.png ), newAction ( Action 1 ), newAction ( Action 2 , http://redirection ) ) ) }, newStory ( goodbye ) { // Intent goodbye end { // Answer with Messenger-specific button/quick reply buttonsTemplate ( Are you sure ? , nlpQuickReply ( Stay here )) } }, // Fallback answer when the bot does find a correct response unknownStory { end ( Sorry I don t understand :( ) } ) ) } Please consult the full source code sample .","title":"Create Stories"},{"location":"dev/bot-api/#develop-in-another-language","text":"","title":"Develop in another language"},{"location":"dev/bot-api/#node","text":"Please consult the dedicated node client documentation.","title":"Node"},{"location":"dev/bot-api/#api","text":"It is possible to develop in the language of your choice by using directly the underlying REST API.","title":"API"},{"location":"dev/bot-api/#install-bot-api-on-your-own-servers","text":"To use Tock's Bot API mode without the demo platform, a specific module must be deployed on your own server. Called bot-api in Docker Compose descriptors, this service: Expose the Bot API to the potential customers whatever their programming language are. Accept WebSocket connections and / or connections to the configured webhook. Compared to the \"demo mode\", The only required change in the code is to replace the startWithDemo method with the start one, specifying the bot-api target server address.","title":"Install Bot API on your own servers"},{"location":"dev/connectors/","text":"Tock Connectors Connectors provided with Tock Many connectors are provided with Tock for various types of text/voice external channels. New connectors are regularly added to the platform, depending on user project needs and availability of new messaging channels. Examples: Google Home arriving in France in 2017, Alexa in 2018, WhatsApp then Business Chat APIs opened in 2019, etc. To find, which bot leverages which connector in production, please refer to the Tock user showcase page. Messenger Channel : Facebook Messenger Type : text (+ voice through voice recording upload) Status : Tock connector in production since 2016 Please refer to connector-messenger for sources and README instructions. Slack Channel : Slack Type : text Status : Tock connector not used for production (no use case yet) Please refer to connector-slack for sources and README instructions. Google Assistant / Home Channel : Google Assistant / Google Home Type : text + voice Status : Tock connector in production since 2017 Please refer to connector-ga for sources and README instructions. Alexa / Echo Channel : Amazon Alexa / Amazon Echo Type : voice Status : Tock connector in production since 2018 Important : please note that the NLP model for Alexa is necessarily built and managed by Amazon online services. Only the conversational framework can be used from Tock. Please refer to connector-alexa for sources and README instructions. Rocket.Chat Channel : Rocket.Chat Type : text Status : to be precised Please refer to connector-rocketchat for sources and README instructions. WhatsApp Channel : WhatsApp from Facebook Type : text Status : Tock connector in production since 2019 Please refer to connector-whatsapp for sources and README instructions. Teams Channel : Microsoft Teams Type : text + voice Status : Tock connector in production since 2019 Please refer to connector-teams for sources and README instructions. Business Chat Channel : Apple Business Chat (Messages) Type : text Status : Tock connector in production since 2019 Please refer to connector-businesschat for sources and README instructions. Twitter Channel : Twitter (messages priv\u00e9s) Type : text Status : Tock connector in production since 2019 Please refer to connector-twitter for sources and README instructions. Allo-Media Channel : Allo-Media (t\u00e9l\u00e9phonie) Type : voice Status : Tock connector in production since 2020 This connector has been developped for the French AlloCovid bot. To know more, please check the AlloMediaConnector class and the bot sources also on GitHub. Web (generic) This generic connector integrates Tock bots with Web sites or applications: portals, dedicated sites, apps, REST clients, etc. The connector exposes a REST API to the bot, making it easy to integrate with any Website, mobile application or programming language. Note that React / Javascript developers can leverage the provided tock-react-kit to consume the Web API. Channel : Web (generic for any Web site or application) Type : text Status : Tock connector in production since 2020 Please refer to connector-web for sources and README instructions, including samples and the Swagger documentation for the REST API. Test (generic) This Tock-internal connector allows to talk to a bot directly from the Tock Studio interface ( Test Test the bot ) and emulates other connectors. Voice Technologies Tock bots merely process text sentences by default. Nevertheless, voice and speech technologies can be leveraged around the bot to achieve voice dialogs (namely voicebots and callbots): Translating Speech-To-Text before bot processing (ie. before NLU ) Translating Text-To-Speech after bot processing (ie. synthesis speech from bot answer) Some of the provided connectors integrate with external channels, capable of STT and TTS. More voice technologies have been integrated with Tock over time, even when no ready-to-use connector is provided. Google / Android Google Speech-To-Text and Text-To-Speech features are used by the Google Assistant / Home connector , the microphone feature from the Microsoft Teams app for Android compatible with the Teams connector , as well as the Android platform for mobile-native development. Technologie : Google / Android STT TTS Status : used with Tock in production (through Google Assistant / Home and Microsoft Teams connectors, as well as native Android for on-app mobile bots) Apple / iOS Apple Speech-To-Text and Text-To-Speech features are used by the Business Chat connector , as well as the iOS platform for mobile-native development. Technologie : Apple / iOS STT TTS Status : used with Tock in production (though Business Chat connector and native iOS for on-app mobile bots) Amazon / Alexa Technologie : Amazon / Alexa STT TTS Status : used with Tock in production (through Alexa connector) Allo-Media Voxygen To build the French AlloCovid bot, an Allo-Media connector has been developped, to integrate the Tock bot with Allo-Media services: Speech-To-Text (from phone speech) and Text-To-Speech (leveraging Voxygen synthesis voices). Technologie : Allo-Media Voxygen Status : used with Tock in production (though Allo-Media connector ) Nuance Nuance propose des solutions de reconnaissance vocale IA. Back in 2016 for voice command usages, Nuance was successfully integrated with Tock for its Speech-To-Text features. Technologie : Nuance Status : used with Tock in 2016 Define your own connector It is possible to develop its own connector. An example of custom connector can be seen in the Bot Open Data sample project . To develop your own, follow these steps: 1) Implement the interface Connector Here is an example of implementation: val testConnectorType = ConnectorType ( test ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router - //main API router . post ( $path/message ). blockingHandler { context - //ConnectorRequest is my business object passed by the front app val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //business object mapped to Tock event val event = readUserMessage ( message ) //we pass the Tock event to the framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //we record the action callback . actions . add ( event ) //if it s the last action to send, send the answer if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { unsupported event: $event } } } } // to retrieve all actions before sending class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList Action = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //we transform the list of Tock responses into a business response val response = mapper . writeValueAsString ( actions . map {...}) //then we send the answer context . response (). end ( response ) } } 2) Implement the interface ConnectorProvider Here is an example of implementation: object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Make this connector available via a Service Loader By placing a file META-INF/services/ai.tock.bot.connector.ConnectorProvider in the classpath, containing the class name : mypackage . TestConnectorProviderService 4) Add all classes and files created in the admin classpath and bot classpath The new connector must then be available in the \"Bot Configurations\" administration interface.","title":"Connectors"},{"location":"dev/connectors/#tock-connectors","text":"","title":"Tock Connectors"},{"location":"dev/connectors/#connectors-provided-with-tock","text":"Many connectors are provided with Tock for various types of text/voice external channels. New connectors are regularly added to the platform, depending on user project needs and availability of new messaging channels. Examples: Google Home arriving in France in 2017, Alexa in 2018, WhatsApp then Business Chat APIs opened in 2019, etc. To find, which bot leverages which connector in production, please refer to the Tock user showcase page.","title":"Connectors provided with Tock"},{"location":"dev/connectors/#messenger","text":"Channel : Facebook Messenger Type : text (+ voice through voice recording upload) Status : Tock connector in production since 2016 Please refer to connector-messenger for sources and README instructions.","title":"Messenger"},{"location":"dev/connectors/#slack","text":"Channel : Slack Type : text Status : Tock connector not used for production (no use case yet) Please refer to connector-slack for sources and README instructions.","title":"Slack"},{"location":"dev/connectors/#google-assistant-home","text":"Channel : Google Assistant / Google Home Type : text + voice Status : Tock connector in production since 2017 Please refer to connector-ga for sources and README instructions.","title":"Google Assistant / Home"},{"location":"dev/connectors/#alexa-echo","text":"Channel : Amazon Alexa / Amazon Echo Type : voice Status : Tock connector in production since 2018 Important : please note that the NLP model for Alexa is necessarily built and managed by Amazon online services. Only the conversational framework can be used from Tock. Please refer to connector-alexa for sources and README instructions.","title":"Alexa / Echo"},{"location":"dev/connectors/#rocketchat","text":"Channel : Rocket.Chat Type : text Status : to be precised Please refer to connector-rocketchat for sources and README instructions.","title":"Rocket.Chat"},{"location":"dev/connectors/#whatsapp","text":"Channel : WhatsApp from Facebook Type : text Status : Tock connector in production since 2019 Please refer to connector-whatsapp for sources and README instructions.","title":"WhatsApp"},{"location":"dev/connectors/#teams","text":"Channel : Microsoft Teams Type : text + voice Status : Tock connector in production since 2019 Please refer to connector-teams for sources and README instructions.","title":"Teams"},{"location":"dev/connectors/#business-chat","text":"Channel : Apple Business Chat (Messages) Type : text Status : Tock connector in production since 2019 Please refer to connector-businesschat for sources and README instructions.","title":"Business Chat"},{"location":"dev/connectors/#twitter","text":"Channel : Twitter (messages priv\u00e9s) Type : text Status : Tock connector in production since 2019 Please refer to connector-twitter for sources and README instructions.","title":"Twitter"},{"location":"dev/connectors/#allo-media","text":"Channel : Allo-Media (t\u00e9l\u00e9phonie) Type : voice Status : Tock connector in production since 2020 This connector has been developped for the French AlloCovid bot. To know more, please check the AlloMediaConnector class and the bot sources also on GitHub.","title":"Allo-Media"},{"location":"dev/connectors/#web-generic","text":"This generic connector integrates Tock bots with Web sites or applications: portals, dedicated sites, apps, REST clients, etc. The connector exposes a REST API to the bot, making it easy to integrate with any Website, mobile application or programming language. Note that React / Javascript developers can leverage the provided tock-react-kit to consume the Web API. Channel : Web (generic for any Web site or application) Type : text Status : Tock connector in production since 2020 Please refer to connector-web for sources and README instructions, including samples and the Swagger documentation for the REST API.","title":"Web (generic)"},{"location":"dev/connectors/#test-generic","text":"This Tock-internal connector allows to talk to a bot directly from the Tock Studio interface ( Test Test the bot ) and emulates other connectors.","title":"Test (generic)"},{"location":"dev/connectors/#voice-technologies","text":"Tock bots merely process text sentences by default. Nevertheless, voice and speech technologies can be leveraged around the bot to achieve voice dialogs (namely voicebots and callbots): Translating Speech-To-Text before bot processing (ie. before NLU ) Translating Text-To-Speech after bot processing (ie. synthesis speech from bot answer) Some of the provided connectors integrate with external channels, capable of STT and TTS. More voice technologies have been integrated with Tock over time, even when no ready-to-use connector is provided.","title":"Voice Technologies"},{"location":"dev/connectors/#google-android","text":"Google Speech-To-Text and Text-To-Speech features are used by the Google Assistant / Home connector , the microphone feature from the Microsoft Teams app for Android compatible with the Teams connector , as well as the Android platform for mobile-native development. Technologie : Google / Android STT TTS Status : used with Tock in production (through Google Assistant / Home and Microsoft Teams connectors, as well as native Android for on-app mobile bots)","title":"Google / Android"},{"location":"dev/connectors/#apple-ios","text":"Apple Speech-To-Text and Text-To-Speech features are used by the Business Chat connector , as well as the iOS platform for mobile-native development. Technologie : Apple / iOS STT TTS Status : used with Tock in production (though Business Chat connector and native iOS for on-app mobile bots)","title":"Apple / iOS"},{"location":"dev/connectors/#amazon-alexa","text":"Technologie : Amazon / Alexa STT TTS Status : used with Tock in production (through Alexa connector)","title":"Amazon / Alexa"},{"location":"dev/connectors/#allo-media-voxygen","text":"To build the French AlloCovid bot, an Allo-Media connector has been developped, to integrate the Tock bot with Allo-Media services: Speech-To-Text (from phone speech) and Text-To-Speech (leveraging Voxygen synthesis voices). Technologie : Allo-Media Voxygen Status : used with Tock in production (though Allo-Media connector )","title":"Allo-Media &amp; Voxygen"},{"location":"dev/connectors/#nuance","text":"Nuance propose des solutions de reconnaissance vocale IA. Back in 2016 for voice command usages, Nuance was successfully integrated with Tock for its Speech-To-Text features. Technologie : Nuance Status : used with Tock in 2016","title":"Nuance"},{"location":"dev/connectors/#define-your-own-connector","text":"It is possible to develop its own connector. An example of custom connector can be seen in the Bot Open Data sample project . To develop your own, follow these steps: 1) Implement the interface Connector Here is an example of implementation: val testConnectorType = ConnectorType ( test ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router - //main API router . post ( $path/message ). blockingHandler { context - //ConnectorRequest is my business object passed by the front app val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //business object mapped to Tock event val event = readUserMessage ( message ) //we pass the Tock event to the framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //we record the action callback . actions . add ( event ) //if it s the last action to send, send the answer if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { unsupported event: $event } } } } // to retrieve all actions before sending class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList Action = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //we transform the list of Tock responses into a business response val response = mapper . writeValueAsString ( actions . map {...}) //then we send the answer context . response (). end ( response ) } } 2) Implement the interface ConnectorProvider Here is an example of implementation: object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Make this connector available via a Service Loader By placing a file META-INF/services/ai.tock.bot.connector.ConnectorProvider in the classpath, containing the class name : mypackage . TestConnectorProviderService 4) Add all classes and files created in the admin classpath and bot classpath The new connector must then be available in the \"Bot Configurations\" administration interface.","title":"Define your own connector"},{"location":"dev/integrated-bot/","text":"Integrated Bot Mode To develop a bot or an assistant with Tock, you can also use the so called Integrated mode developed in Kotlin . You get then direct access to the MongoDb database. This mode is not available in the demo platform - you need to install the Tock docker images on your own servers. Sample Project A sample bot using Tock Integrated mode is provided: https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit. Docker Images Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker . Start the NLP stack #get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password . Sample bot based on Open Data APIs A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images . Develop a new Bot Add the bot-toolkit Dependency The bot-toolkit dependency is required: With Maven: dependency groupId ai.tock /groupId artifactId bot-toolkit /artifactId version 20.3.1 /version /dependency With Gradle: compile ai.tock:bot-toolkit:20.3.1 A Bot is a Set of Stories This is how the open data bot is defined: val openBot = bot ( bot_open_data , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) This bot has an unique identifier (required - \"bot_open_data\") and a list of \"Story\" . A Story is a functional subset that has a main intention and, optionally, one or more so-called \"secondary\" intentions. Here the bot defines 4 Stories , greetings, departures, arrivals and search. Greetings is also set ( hello = greetings ) as the default story used for a new dialog. A Simple Story How do you define a story? Here is a first simplified version of the story greetings : val greetings = story ( greetings ) { send ( Welcome to the Tock Open Data Bot! :) ) end ( This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock ) } Note that in the body of the function, this has a BotBus type. From which you can interact with the user, and which also allows you to access to all available contextual elements. When the intention greetings will be detected by the NLP model, the function above will be called by the Tock framework. The bot sends successively a first response sentence ( bus.send() ), then a second one indicating that it is the last sentence of his answer using a bus.end() . Here is the full version of greetings : val greetings = story ( greetings ) { //cleanup state resetDialogState () send ( Welcome to the Tock Open Data Bot! :) ) send ( This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock ) withMessenger { buttonsTemplate ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , postbackButton ( Itineraries , search ), postbackButton ( Departures , Departures ), postbackButton ( Arrivals , Arrivals ) ) } withGoogleAssistant { gaMessage ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , Itineraries , Departures , Arrivals ) } end () } Two notions have been added: resetDialogState() which cleanup the state (forgetting any previous context). the withMessenger{} and withGoogleAssistant{} methods that define specific responses for each connector - Here it's a text with buttons for Messenger, and a text with suggestions for Google Assistant. Start and Connect the Bot To start the bot, simply add the following call to your main function: registerAndInstallBot ( openBot ) where the openBot variable is the bot you originally defined. When the bot is started, you also need to specify which connectors are used in the web administration interface: Configuration - Bot Configurations - Create a new configuration See Connectors page for the list of available connectors. Advanced options Of course, the StoryHandler of greetings does not depend on the context: the answer is always the same. Secondary Intentions Here is the beginning of the definition of the search story : val search = storyDef SearchDef ( search , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } The story search defines a secondary starter intent ( indicate_origin ) and a simple secondary intent ( indicate_location ). A secondary starter intent is similar in every respect to the main intent: as soon as the intent is detected, if the current story does not contain indicate_origin as secondary intent, the story search is called. For a classic secondary intent, on the other hand, the story will be executed only if the current story of the context is already the search story. Different stories can therefore share the same secondary intents. Handle Entities To retrieve entity values, it is good practice to define Kotlin extensions . For example here is the code used to retrieve the destination entity: val destinationEntity = openBot . entity ( location , destination ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) An entity of type \"location\" and role \"destination\" is created. There is a corresponding entity in the NLP model. A variable destination is defined, which will simplify the handling of this entity in the conversational code. This variable contains the current value of the destination in the user context. Here's a full version of the search story that uses destination : val search = storyDef SearchDef ( search , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null - end ( For which destination? ) origin == null - end ( For which origin? ) departureDate == null - end ( When? ) } } If there is no value in the current context for the destination, the bot asks to specify the destination and stays there. Same behaviour for the origin or date of departure. If the 3 required values are specified, then the real answer developed in the SearchDef class is used. Here is the full version of this first part of the code: val search = storyDef SearchDef ( search , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null - end ( For which destination? ) origin == null - end ( For which origin? ) departureDate == null - end ( When? ) } } In the case where the detected intention is indicate_location , we do not know if the locality represents the origin or the destination. A simple rule is then used: If there is already in the context an origin and no destination, the new locality is actually the destination. Otherwise, it is the origin. HandlerDef In the search story above, you may have noted the generic SearchDef typing. Here is the code of this class: @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef SearchConnector ( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( From {0} to {1} , o , d ) send ( Departure on {0} , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( Sorry, no routes found :( ) } else { send ( Here is the first proposal: ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef extends HandlerDef which is an alias of a Tock framework class. It is usually here that the code of complex stories is defined. The code contains an additional abstraction: SearchConnector . SearchConnector is the class that defines the behavior specific to each connector, and the annotations @GAHandler (GASearchConnector::class) and @MessengerHandler (MessengerSearchConnector::class) indicate the corresponding implementations for the different supported connectors (respectively Google Assistant and Messenger). What would happen there is no connector for Google Assistant for example, and if a call from Google Assistant is answered? The connector?.sendFirstJourney(journeys.first()) method call would not send the final response, since connector would be null . ConnectorDef Here is a simplified version of SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef SearchDef ( context ) { fun Section . title (): CharSequence = i18n ( {0} - {1} , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List Section ): ConnectorMessage } And its Messenger implementation: class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List Section ): ConnectorMessage = flexibleListTemplate ( sections . map { section - with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } The code specific to each connector is thus decoupled correctly. The code common to each connector is present in SearchConnector and the behavior specific to each connector is specified in the dedicated classes. StoryStep Sometimes you need to remember the stage at which the user is in the current story. For this, Tock provides the concept of StoryStep . There are two types of StoryStep. SimpleStoryStep enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps MyStep ( intent ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } To modify the current step, two methods are available: Manually change the step val story = storyWithSteps MyStep ( intent ) { //(...) step = MyStep . a // the step will be persisted as long as we stay in this story } Use buttons or quick replies More details on this topic here . StorySteps with complex behavior In more complex cases, we want to be able to define a behavior for each step. enum class MySteps : StoryStep MyHandlerDef { //no specific behaviour display , select { // select step will be automatically selected if the select sub-intention is detected override val intent : IntentAware ? = SecondaryIntent . select override fun answer (): MyHandlerDef .() - Any ? = { end ( I don t know yet how to select something ) } }, disruption { override fun answer (): ScoreboardDef .() - Any ? = { end ( some perturbation ) } }; } More configuration options are available. Check out the description of StoryStep . Postback buttons quick replies Messenger provides this type of button, as most connectors with GUI. With Tock, you can easily define the action performed after clicking on these buttons. In the following example, the button will redirect to the \"search\" intent: buttonsTemplate ( The bot is very limited! Only itineraries are supported :) , postbackButton ( Itineraries , search ) ) It is also possible to define a * StoryStep * and dedicated parameters: //to define parameters, just extend the ParameterKey interface enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( The bot is very limited! Only itineraries are supported :) , postbackButton ( Itineraries , intent = search , //if no step is specified, the current step is used step = MyStep . a , parameters = //this parameter is stored as a string (hooks are used) nextResultDate [ nextDate ] + //this parameter is stored in json (parentheses are used) nextResultOrigin ( origin ) ) ) To retrieve the parameters of the button that was clicked: val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin )","title":"Integrated Bot mode"},{"location":"dev/integrated-bot/#integrated-bot-mode","text":"To develop a bot or an assistant with Tock, you can also use the so called Integrated mode developed in Kotlin . You get then direct access to the MongoDb database. This mode is not available in the demo platform - you need to install the Tock docker images on your own servers.","title":"Integrated Bot Mode"},{"location":"dev/integrated-bot/#sample-project","text":"A sample bot using Tock Integrated mode is provided: https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit.","title":"Sample Project"},{"location":"dev/integrated-bot/#docker-images","text":"Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker .","title":"Docker Images"},{"location":"dev/integrated-bot/#start-the-nlp-stack","text":"#get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password .","title":"Start the NLP stack"},{"location":"dev/integrated-bot/#sample-bot-based-on-open-data-apis","text":"A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images .","title":"Sample bot based on Open Data APIs"},{"location":"dev/integrated-bot/#develop-a-new-bot","text":"","title":"Develop a new Bot"},{"location":"dev/integrated-bot/#add-the-bot-toolkit-dependency","text":"The bot-toolkit dependency is required: With Maven: dependency groupId ai.tock /groupId artifactId bot-toolkit /artifactId version 20.3.1 /version /dependency With Gradle: compile ai.tock:bot-toolkit:20.3.1","title":"Add the bot-toolkit Dependency"},{"location":"dev/integrated-bot/#a-bot-is-a-set-of-stories","text":"This is how the open data bot is defined: val openBot = bot ( bot_open_data , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) This bot has an unique identifier (required - \"bot_open_data\") and a list of \"Story\" . A Story is a functional subset that has a main intention and, optionally, one or more so-called \"secondary\" intentions. Here the bot defines 4 Stories , greetings, departures, arrivals and search. Greetings is also set ( hello = greetings ) as the default story used for a new dialog.","title":"A Bot is a Set of Stories"},{"location":"dev/integrated-bot/#a-simple-story","text":"How do you define a story? Here is a first simplified version of the story greetings : val greetings = story ( greetings ) { send ( Welcome to the Tock Open Data Bot! :) ) end ( This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock ) } Note that in the body of the function, this has a BotBus type. From which you can interact with the user, and which also allows you to access to all available contextual elements. When the intention greetings will be detected by the NLP model, the function above will be called by the Tock framework. The bot sends successively a first response sentence ( bus.send() ), then a second one indicating that it is the last sentence of his answer using a bus.end() . Here is the full version of greetings : val greetings = story ( greetings ) { //cleanup state resetDialogState () send ( Welcome to the Tock Open Data Bot! :) ) send ( This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock ) withMessenger { buttonsTemplate ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , postbackButton ( Itineraries , search ), postbackButton ( Departures , Departures ), postbackButton ( Arrivals , Arrivals ) ) } withGoogleAssistant { gaMessage ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , Itineraries , Departures , Arrivals ) } end () } Two notions have been added: resetDialogState() which cleanup the state (forgetting any previous context). the withMessenger{} and withGoogleAssistant{} methods that define specific responses for each connector - Here it's a text with buttons for Messenger, and a text with suggestions for Google Assistant.","title":"A Simple Story"},{"location":"dev/integrated-bot/#start-and-connect-the-bot","text":"To start the bot, simply add the following call to your main function: registerAndInstallBot ( openBot ) where the openBot variable is the bot you originally defined. When the bot is started, you also need to specify which connectors are used in the web administration interface: Configuration - Bot Configurations - Create a new configuration See Connectors page for the list of available connectors.","title":"Start and Connect the Bot"},{"location":"dev/integrated-bot/#advanced-options","text":"Of course, the StoryHandler of greetings does not depend on the context: the answer is always the same.","title":"Advanced options"},{"location":"dev/integrated-bot/#secondary-intentions","text":"Here is the beginning of the definition of the search story : val search = storyDef SearchDef ( search , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } The story search defines a secondary starter intent ( indicate_origin ) and a simple secondary intent ( indicate_location ). A secondary starter intent is similar in every respect to the main intent: as soon as the intent is detected, if the current story does not contain indicate_origin as secondary intent, the story search is called. For a classic secondary intent, on the other hand, the story will be executed only if the current story of the context is already the search story. Different stories can therefore share the same secondary intents.","title":"Secondary Intentions"},{"location":"dev/integrated-bot/#handle-entities","text":"To retrieve entity values, it is good practice to define Kotlin extensions . For example here is the code used to retrieve the destination entity: val destinationEntity = openBot . entity ( location , destination ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) An entity of type \"location\" and role \"destination\" is created. There is a corresponding entity in the NLP model. A variable destination is defined, which will simplify the handling of this entity in the conversational code. This variable contains the current value of the destination in the user context. Here's a full version of the search story that uses destination : val search = storyDef SearchDef ( search , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null - end ( For which destination? ) origin == null - end ( For which origin? ) departureDate == null - end ( When? ) } } If there is no value in the current context for the destination, the bot asks to specify the destination and stays there. Same behaviour for the origin or date of departure. If the 3 required values are specified, then the real answer developed in the SearchDef class is used. Here is the full version of this first part of the code: val search = storyDef SearchDef ( search , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null - end ( For which destination? ) origin == null - end ( For which origin? ) departureDate == null - end ( When? ) } } In the case where the detected intention is indicate_location , we do not know if the locality represents the origin or the destination. A simple rule is then used: If there is already in the context an origin and no destination, the new locality is actually the destination. Otherwise, it is the origin.","title":"Handle Entities"},{"location":"dev/integrated-bot/#handlerdef","text":"In the search story above, you may have noted the generic SearchDef typing. Here is the code of this class: @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef SearchConnector ( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( From {0} to {1} , o , d ) send ( Departure on {0} , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( Sorry, no routes found :( ) } else { send ( Here is the first proposal: ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef extends HandlerDef which is an alias of a Tock framework class. It is usually here that the code of complex stories is defined. The code contains an additional abstraction: SearchConnector . SearchConnector is the class that defines the behavior specific to each connector, and the annotations @GAHandler (GASearchConnector::class) and @MessengerHandler (MessengerSearchConnector::class) indicate the corresponding implementations for the different supported connectors (respectively Google Assistant and Messenger). What would happen there is no connector for Google Assistant for example, and if a call from Google Assistant is answered? The connector?.sendFirstJourney(journeys.first()) method call would not send the final response, since connector would be null .","title":"HandlerDef"},{"location":"dev/integrated-bot/#connectordef","text":"Here is a simplified version of SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef SearchDef ( context ) { fun Section . title (): CharSequence = i18n ( {0} - {1} , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List Section ): ConnectorMessage } And its Messenger implementation: class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List Section ): ConnectorMessage = flexibleListTemplate ( sections . map { section - with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } The code specific to each connector is thus decoupled correctly. The code common to each connector is present in SearchConnector and the behavior specific to each connector is specified in the dedicated classes.","title":"ConnectorDef"},{"location":"dev/integrated-bot/#storystep","text":"Sometimes you need to remember the stage at which the user is in the current story. For this, Tock provides the concept of StoryStep . There are two types of StoryStep.","title":"StoryStep"},{"location":"dev/integrated-bot/#simplestorystep","text":"enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps MyStep ( intent ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } To modify the current step, two methods are available: Manually change the step val story = storyWithSteps MyStep ( intent ) { //(...) step = MyStep . a // the step will be persisted as long as we stay in this story } Use buttons or quick replies More details on this topic here .","title":"SimpleStoryStep"},{"location":"dev/integrated-bot/#storysteps-with-complex-behavior","text":"In more complex cases, we want to be able to define a behavior for each step. enum class MySteps : StoryStep MyHandlerDef { //no specific behaviour display , select { // select step will be automatically selected if the select sub-intention is detected override val intent : IntentAware ? = SecondaryIntent . select override fun answer (): MyHandlerDef .() - Any ? = { end ( I don t know yet how to select something ) } }, disruption { override fun answer (): ScoreboardDef .() - Any ? = { end ( some perturbation ) } }; } More configuration options are available. Check out the description of StoryStep .","title":"StorySteps with complex behavior"},{"location":"dev/integrated-bot/#postback-buttons-quick-replies","text":"Messenger provides this type of button, as most connectors with GUI. With Tock, you can easily define the action performed after clicking on these buttons. In the following example, the button will redirect to the \"search\" intent: buttonsTemplate ( The bot is very limited! Only itineraries are supported :) , postbackButton ( Itineraries , search ) ) It is also possible to define a * StoryStep * and dedicated parameters: //to define parameters, just extend the ParameterKey interface enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( The bot is very limited! Only itineraries are supported :) , postbackButton ( Itineraries , intent = search , //if no step is specified, the current step is used step = MyStep . a , parameters = //this parameter is stored as a string (hooks are used) nextResultDate [ nextDate ] + //this parameter is stored in json (parentheses are used) nextResultOrigin ( origin ) ) ) To retrieve the parameters of the button that was clicked: val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin )","title":"Postback buttons &amp; quick replies"},{"location":"guide/studio/","text":"Create your first bot with Tock Studio The best way to try Tock is probably to create a first conversational bot using Tock Studio (the graphical user interface provided with the platform). By connecting to the Tock demonstration platform , it is possible to both design and test a conversational assistant in a few minutes, without having to write code. What you will build An application and a connector on the Tock demo platform A story : user sentence / bot answer, testable through the Tock Studio interface An assistant who answers, when you say \"hello\"! \ud83d\ude42 What you need About 5 to 15 minutes (reading the additional notes) A GitHub account, to connect to the demo platform Connect to the demo platform Open https://demo.tock.ai/ to access the Tock demonstration platform. Important : this platform is not supposed to host bots in production. This is merely a sandbox instance, in order to try the Tock solution without installing it. A login dialog invites you to connect with GitHub. Only your account ID will be read from GitHub. Create a Tock application When accessing the demo platform for the first time, a wizard helps to create the first application : Enter a name for the application Select a language - other languages can be added later Validate to create the application The just-created application is now visible from the menu: Configuration NLU Applications . Once the first application has been created, you can create others using Create New Application . Add a connector To interact with the bot (through a communication channel), a connector must be used. Numerous connectors are provided with Tock: Messenger , WhatsApp , Google Assistant and Google Home , Twitter , Alexa , Business Chat , Teams , Slack , Rocket.Chat ... It is even possible to implement your own connectors to integrate with more channels. In this tutorial, you will configure a connector for Slack - the collaborative and instant messaging platform. It will be possible to try the bot using the Tock Studio interface - no need to use Slack or get an account. Create the first connector for your application: Go to Configuration Bot Configurations Create a new Configuration Select the connector type Slack Enter anything e.g. token in Token fields (for the moment) Create Note that an API Key is automatically generated for the application, once the first connector is created. This key is required to connect to the bot API, in order to leverage the WebHook or WebSocket modes. Clicking on Display test configurations , you can see another Test configuration has been created. This connector is used when the bot is tested directly through the Tock Studio interface. It allows to try the bot without having Slack, for instance. Create a story A conversational bot receives and understands user sentences, using natural-language techniques to identify an intent and possibly entities . Example: from the sentence \"What will the weather be like tomorrow?\", the Tock NLU (Natural Language Understanding) engine should detect a \"weather\" intent and a \"tomorrow\" date/time entity precising the question (like a kind of intent variable/parameter). In order to detect intents and entities, sentences must first be added and qualifieds. The Tock NLU menu allows to manage intents and entities, qualify sentences and supervise the bot training: the more qualified sentences, the more relevant is the bot . Nevertheless, let's leave intents and entities for now... The Tock Stories mode allows to create intents automatically in a few minutes, as well as the expected answers. You will now create a first template of a conversation, using the Tock Studio graphical tools: Go to Build New Story Enter a new user sentence - for instance \"hello\" A form now opens to configure the new story creation, the intent, the type of response, etc. In the Add new Answer field, enter the answer - for instance \"what a nice day!\" End with Create Story Test the bot It is time to try the bot and its first story! Go to Test Test the bot Say \"hello\", the bot answers Please check that the correct application and language are selected (in case there are more than one) when testing: they are visible in the top-right corner of the interface. Improve the understanding By entering various sentences through the Test the bot interface, you can see it does not understand much your phrases - even with sentences very similar to the one at story creation. The conversational model and the Tock NLU engine must be trained and improved by progressively adding user qualified sentences to feed underlying algorithms and give more and more relevant results. Although first tries can be deceiving, several qualified sentences (one or two dozens if necessary) usually make a difference and the bot gets more relevant. Go to NLU Inbox Here you can see the previously entered sentences, and more interestingly how the bot qualified them. For each sentence, Tock shows the detected intent, the language, as well as the scores (given by the algorithms according to their level of confidence for the sentence). Choose several sentences, for each one: select the correct intent then Validate Return to Test Test the bot Check the bot now understands these sentences correctly, as well as slightly-different ones you have never entered! Create more stories (optional) To go a little further with Tock stories , you could create more stories and test them directly from Tock Studio . Each bot response comes from the intent detected/triggered, without another form of navigation than the thread of YOUR sentences. Conversational is magic: natural language is the navigation, users are not forced to use traditional links and menus anymore (contrary to Websites and mobile apps). For curious users, let's have a word about managing numerous stories and the possible impact on understanding. If you take time and create many stories , you may experience unintended effects with how work NLU models and algorithms. As an example, numerous intents and entities can make detection difficult (or more random). A general recommendation is to create bots, dedicated to a limited functional perimeter. It makes it easier to train each bot and focus on the model for its own domain. Qualifying a lot of sentences generally improves the bot understanding, however too many sentences (or too similar) can over-train the model for an intent, resulting in degraded performance. As a conclusion, remember the design and maintenance of conversational models is complex, it requires training (the bot, as well as people building it), qualifying and adapting the models on a regular basis to user needs and language. Congratulations! You have just created your first conversational application with Tock. With a few minutes and no particular knowledge or skill, more importantly without writing or deploying code, you have been able to create a simple conversational workflow and test it online.","title":"Create your 1st bot"},{"location":"guide/studio/#create-your-first-bot-with-tock-studio","text":"The best way to try Tock is probably to create a first conversational bot using Tock Studio (the graphical user interface provided with the platform). By connecting to the Tock demonstration platform , it is possible to both design and test a conversational assistant in a few minutes, without having to write code.","title":"Create your first bot with Tock Studio"},{"location":"guide/studio/#what-you-will-build","text":"An application and a connector on the Tock demo platform A story : user sentence / bot answer, testable through the Tock Studio interface An assistant who answers, when you say \"hello\"! \ud83d\ude42","title":"What you will build"},{"location":"guide/studio/#what-you-need","text":"About 5 to 15 minutes (reading the additional notes) A GitHub account, to connect to the demo platform","title":"What you need"},{"location":"guide/studio/#connect-to-the-demo-platform","text":"Open https://demo.tock.ai/ to access the Tock demonstration platform. Important : this platform is not supposed to host bots in production. This is merely a sandbox instance, in order to try the Tock solution without installing it. A login dialog invites you to connect with GitHub. Only your account ID will be read from GitHub.","title":"Connect to the demo platform"},{"location":"guide/studio/#create-a-tock-application","text":"When accessing the demo platform for the first time, a wizard helps to create the first application : Enter a name for the application Select a language - other languages can be added later Validate to create the application The just-created application is now visible from the menu: Configuration NLU Applications . Once the first application has been created, you can create others using Create New Application .","title":"Create a Tock application"},{"location":"guide/studio/#add-a-connector","text":"To interact with the bot (through a communication channel), a connector must be used. Numerous connectors are provided with Tock: Messenger , WhatsApp , Google Assistant and Google Home , Twitter , Alexa , Business Chat , Teams , Slack , Rocket.Chat ... It is even possible to implement your own connectors to integrate with more channels. In this tutorial, you will configure a connector for Slack - the collaborative and instant messaging platform. It will be possible to try the bot using the Tock Studio interface - no need to use Slack or get an account. Create the first connector for your application: Go to Configuration Bot Configurations Create a new Configuration Select the connector type Slack Enter anything e.g. token in Token fields (for the moment) Create Note that an API Key is automatically generated for the application, once the first connector is created. This key is required to connect to the bot API, in order to leverage the WebHook or WebSocket modes. Clicking on Display test configurations , you can see another Test configuration has been created. This connector is used when the bot is tested directly through the Tock Studio interface. It allows to try the bot without having Slack, for instance.","title":"Add a connector"},{"location":"guide/studio/#create-a-story","text":"A conversational bot receives and understands user sentences, using natural-language techniques to identify an intent and possibly entities . Example: from the sentence \"What will the weather be like tomorrow?\", the Tock NLU (Natural Language Understanding) engine should detect a \"weather\" intent and a \"tomorrow\" date/time entity precising the question (like a kind of intent variable/parameter). In order to detect intents and entities, sentences must first be added and qualifieds. The Tock NLU menu allows to manage intents and entities, qualify sentences and supervise the bot training: the more qualified sentences, the more relevant is the bot . Nevertheless, let's leave intents and entities for now... The Tock Stories mode allows to create intents automatically in a few minutes, as well as the expected answers. You will now create a first template of a conversation, using the Tock Studio graphical tools: Go to Build New Story Enter a new user sentence - for instance \"hello\" A form now opens to configure the new story creation, the intent, the type of response, etc. In the Add new Answer field, enter the answer - for instance \"what a nice day!\" End with Create Story","title":"Create a story"},{"location":"guide/studio/#test-the-bot","text":"It is time to try the bot and its first story! Go to Test Test the bot Say \"hello\", the bot answers Please check that the correct application and language are selected (in case there are more than one) when testing: they are visible in the top-right corner of the interface.","title":"Test the bot"},{"location":"guide/studio/#improve-the-understanding","text":"By entering various sentences through the Test the bot interface, you can see it does not understand much your phrases - even with sentences very similar to the one at story creation. The conversational model and the Tock NLU engine must be trained and improved by progressively adding user qualified sentences to feed underlying algorithms and give more and more relevant results. Although first tries can be deceiving, several qualified sentences (one or two dozens if necessary) usually make a difference and the bot gets more relevant. Go to NLU Inbox Here you can see the previously entered sentences, and more interestingly how the bot qualified them. For each sentence, Tock shows the detected intent, the language, as well as the scores (given by the algorithms according to their level of confidence for the sentence). Choose several sentences, for each one: select the correct intent then Validate Return to Test Test the bot Check the bot now understands these sentences correctly, as well as slightly-different ones you have never entered!","title":"Improve the understanding"},{"location":"guide/studio/#create-more-stories-optional","text":"To go a little further with Tock stories , you could create more stories and test them directly from Tock Studio . Each bot response comes from the intent detected/triggered, without another form of navigation than the thread of YOUR sentences. Conversational is magic: natural language is the navigation, users are not forced to use traditional links and menus anymore (contrary to Websites and mobile apps). For curious users, let's have a word about managing numerous stories and the possible impact on understanding. If you take time and create many stories , you may experience unintended effects with how work NLU models and algorithms. As an example, numerous intents and entities can make detection difficult (or more random). A general recommendation is to create bots, dedicated to a limited functional perimeter. It makes it easier to train each bot and focus on the model for its own domain. Qualifying a lot of sentences generally improves the bot understanding, however too many sentences (or too similar) can over-train the model for an intent, resulting in degraded performance. As a conclusion, remember the design and maintenance of conversational models is complex, it requires training (the bot, as well as people building it), qualifying and adapting the models on a regular basis to user needs and language.","title":"Create more stories (optional)"},{"location":"guide/studio/#congratulations","text":"You have just created your first conversational application with Tock. With a few minutes and no particular knowledge or skill, more importantly without writing or deploying code, you have been able to create a simple conversational workflow and test it online.","title":"Congratulations!"}]}