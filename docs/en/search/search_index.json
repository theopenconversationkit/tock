{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Tock, The Open Conversation Kit Introduction Tock is a toolkit for building conversational agents (or bots). Unlike other toolkits, it does not depend on third-party APIs (but can easily integrate with them if necessary), and is fully Open Source, so you get complete control over your data and algorithms. The source code is on github: https://github.com/voyages-sncf-technologies/tock under the Apache 2 license . Two major components are available: The NLP (Natural Language Processing) stack A conversational framework that uses NLP services and provides connectors (for Messenger, Google Assistant and Slack at this time). The NLP stack is independent of the conversational framework. It is therefore possible to use the NLP without having to masterize the complexity induced by the management of conversations and contexts. A Platform to Build NLP Models Administration Interface With the administration interface, you can qualify sentences in order to build NLP models: Quality Monitoring This interface also provides stats about realtime usage: Stanford CoreNLP or Apache OpenNLP The underlying NLP engine is based on one of these open-source solutions (you can select the engine via the admin interface). Tock provides a level of indirection that allows integration with other NLP libraries. The integration of SparkNLP is also planned. Duckling A date and simple types parsing tool based on the open-source Duckling library is also integrated by default, in order to find and evaluate entities. NLP API The models can be tested via the provided API . A Conversational Framework The Tock Conversational Framework provides all you need to create and manage dialogs. Kotlin is used as core language of the stack. The framework uses the Tock NLP stack via its API . Context and History Management Dialog contexts and conversation history management are supported. Advanced features like entity values merge are also provided. Third party connectors Connectors to Facebook Messenger, Google Assistant, WhatsApp, RocketChat, Twitter, Alexa, Teams and Slack are available. It is easy to create others, whether to connect to other channels (please contribute!) or for custom needs. Conversations monitoring You can also test the bots and follow the conversations of users directly in the admin interface. Genesis of the project The project was initiated in 2016 by the Innovation Team of oui.sncf as a first step to build voice commands feature in its mobile applications . The toolkit was then used to implement its Messenger Bot (fr only). Since, a dedicated team at oui.sncf maintains the stack. The oui.sncf Google Assistant is also based on Tock, as well as the web-based OUIbot (fr only for now). The tools were open-sourced in the hope they will be useful. Contributions are welcomed. Technologies The application platform is the JVM . The core language is Kotlin . Vert.x and MongoDB are also used internally. The administration interfaces are implemented in Angular4 / Typescript . Open-sourced projects The main project is under Apache 2 license . The source code is available on GitHub: https://github.com/voyages-sncf-technologies/tock However an optional dependency, Stanford CoreNLP , is under GPL license . The code using this dependency is therefore located in a separate project, under GPL license: https://github.com/voyages-sncf-technologies/tock-corenlp Finally two other projects are available: A project containing docker images: https://github.com/voyages-sncf-technologies/tock-docker A project containing an example of a bot implementation based on the Open Data SNCF APIs : https://github.com/voyages-sncf-technologies/tock-bot-open-data","title":"Introduction"},{"location":"#tock-the-open-conversation-kit","text":"","title":"Tock, The Open Conversation Kit"},{"location":"#introduction","text":"Tock is a toolkit for building conversational agents (or bots). Unlike other toolkits, it does not depend on third-party APIs (but can easily integrate with them if necessary), and is fully Open Source, so you get complete control over your data and algorithms. The source code is on github: https://github.com/voyages-sncf-technologies/tock under the Apache 2 license . Two major components are available: The NLP (Natural Language Processing) stack A conversational framework that uses NLP services and provides connectors (for Messenger, Google Assistant and Slack at this time). The NLP stack is independent of the conversational framework. It is therefore possible to use the NLP without having to masterize the complexity induced by the management of conversations and contexts.","title":"Introduction"},{"location":"#a-platform-to-build-nlp-models","text":"","title":"A Platform to Build NLP Models"},{"location":"#administration-interface","text":"With the administration interface, you can qualify sentences in order to build NLP models:","title":"Administration Interface"},{"location":"#quality-monitoring","text":"This interface also provides stats about realtime usage:","title":"Quality Monitoring"},{"location":"#stanford-corenlp-or-apache-opennlp","text":"The underlying NLP engine is based on one of these open-source solutions (you can select the engine via the admin interface). Tock provides a level of indirection that allows integration with other NLP libraries. The integration of SparkNLP is also planned.","title":"Stanford CoreNLP or Apache OpenNLP"},{"location":"#duckling","text":"A date and simple types parsing tool based on the open-source Duckling library is also integrated by default, in order to find and evaluate entities.","title":"Duckling"},{"location":"#nlp-api","text":"The models can be tested via the provided API .","title":"NLP API"},{"location":"#a-conversational-framework","text":"The Tock Conversational Framework provides all you need to create and manage dialogs. Kotlin is used as core language of the stack. The framework uses the Tock NLP stack via its API .","title":"A Conversational Framework"},{"location":"#context-and-history-management","text":"Dialog contexts and conversation history management are supported. Advanced features like entity values merge are also provided.","title":"Context and History Management"},{"location":"#third-party-connectors","text":"Connectors to Facebook Messenger, Google Assistant, WhatsApp, RocketChat, Twitter, Alexa, Teams and Slack are available. It is easy to create others, whether to connect to other channels (please contribute!) or for custom needs.","title":"Third party connectors"},{"location":"#conversations-monitoring","text":"You can also test the bots and follow the conversations of users directly in the admin interface.","title":"Conversations monitoring"},{"location":"#genesis-of-the-project","text":"The project was initiated in 2016 by the Innovation Team of oui.sncf as a first step to build voice commands feature in its mobile applications . The toolkit was then used to implement its Messenger Bot (fr only). Since, a dedicated team at oui.sncf maintains the stack. The oui.sncf Google Assistant is also based on Tock, as well as the web-based OUIbot (fr only for now). The tools were open-sourced in the hope they will be useful. Contributions are welcomed.","title":"Genesis of the project"},{"location":"#technologies","text":"The application platform is the JVM . The core language is Kotlin . Vert.x and MongoDB are also used internally. The administration interfaces are implemented in Angular4 / Typescript .","title":"Technologies"},{"location":"#open-sourced-projects","text":"The main project is under Apache 2 license . The source code is available on GitHub: https://github.com/voyages-sncf-technologies/tock However an optional dependency, Stanford CoreNLP , is under GPL license . The code using this dependency is therefore located in a separate project, under GPL license: https://github.com/voyages-sncf-technologies/tock-corenlp Finally two other projects are available: A project containing docker images: https://github.com/voyages-sncf-technologies/tock-docker A project containing an example of a bot implementation based on the Open Data SNCF APIs : https://github.com/voyages-sncf-technologies/tock-bot-open-data","title":"Open-sourced projects"},{"location":"api/","text":"You can test a model via the Tock NLP API. Please consult the documentation /api . If you want to test the API, run the docker images and open the url http://localhost/doc/index.html Also, Administration API (in order to manage the models) is documented: /api/admin If you want to test the Admin API, run the docker images and open the url http://localhost/doc/admin.html","title":"Tock APIs"},{"location":"build-nlp-model/","text":"Build a New NLU (Natural Language Understanding) Model Overview Seven tabs are available: Try it : add (or test) a new sentence Inbox : not yet qualified sentences Archive : the set of archived sentences, i. e. marked as not yet recognized by the model. Search : an advanced search interface that lets you search for sentences, whether or not they are qualified. Intents : the list of the model's intentions Entities : the list of model entities Logs : the last queries requested via the NLP API The user is redirected by default to Inbox . Add and Qualify Sentences Add a New Sentence Click on the Try It menu and enter the new sentence. The add a new user intent by selecting \"Create a New Intent\" in the \"Intent\" selection list. Declaring Entities If necessary, you can specify the entities of this new intent, by selecting the text of these entities, and then clicking on the \"Add New Entity\" button that has just appeared. It's up to you to choose an existing entity type, or create a new one, and then give that entity a role. Built-in Entities In the window \"Add Entity\", you can see that there are already pre-existing entities (prefixed by duckling ). These are the entities recognized by the eponymous library. These entities will be recognized and valued automatically if you specify them in at least one sentence of the intent. Validate a Sentence If you think that the sentence is qualified correctly, you just have to click on \"Validate\" to confirm that the sentence is ok. If this is not the case, it's up to you to correct the meaning before validating it. You are building your first model! Explore the Model The Search Tab The Search tab allows you to browse all the sentences of the model. The most used criterion is the full text search input (regular expressions are allowed). You can then consult the sentences that are part of your model, and also change the qualifications of these sentences over time. States of a Sentence Each sentence has a state: Inbox : The sentence has not been qualified yet and is not included in the model Validated : The sentence has been validated but is not yet included in the NLP model (this can take some time for large models) Included in model : The sentence has been validated and is included in the model Advanced Features By clicking on the \"Applications\"menu, you get the list of existing applications. Then click of the edit button of the application you want to configure. Nlp Engine Selection You can select the NLP library used by this application with the \"NLP engine\" radio button: Use Built-in Entity Models This option allows you to reuse built-in entity models (ie duckling) in your new intent. For example, if you create an intent with a duckling:datetime entity, the dates will automatically be recognized for that intent in all new sentences assigned to that intent (Internally, a merge is performed between the info given by the built-in entity models and the info of your own model). This option is enabled by default, it can be useful to disable it for very large models, for which the NER detection will perform better in almost all cases. Use sub-entities If you enable this option, you will be able to qualify multiple levels of entities: The number of levels is not limited, but it is advisable not to specify more than 3 or 4. Use predefined values An entity can have predefined values : you just have to click on \"Entities\" tab, and select an entity. A small icon next to the delete icon shows the types of entities you can edit as shown in the picture below:","title":"Build NLP model"},{"location":"build-nlp-model/#build-a-new-nlu-natural-language-understanding-model","text":"","title":"Build a New NLU (Natural Language Understanding) Model"},{"location":"build-nlp-model/#overview","text":"Seven tabs are available: Try it : add (or test) a new sentence Inbox : not yet qualified sentences Archive : the set of archived sentences, i. e. marked as not yet recognized by the model. Search : an advanced search interface that lets you search for sentences, whether or not they are qualified. Intents : the list of the model's intentions Entities : the list of model entities Logs : the last queries requested via the NLP API The user is redirected by default to Inbox .","title":"Overview"},{"location":"build-nlp-model/#add-and-qualify-sentences","text":"","title":"Add and Qualify Sentences"},{"location":"build-nlp-model/#add-a-new-sentence","text":"Click on the Try It menu and enter the new sentence. The add a new user intent by selecting \"Create a New Intent\" in the \"Intent\" selection list.","title":"Add a New Sentence"},{"location":"build-nlp-model/#declaring-entities","text":"If necessary, you can specify the entities of this new intent, by selecting the text of these entities, and then clicking on the \"Add New Entity\" button that has just appeared. It's up to you to choose an existing entity type, or create a new one, and then give that entity a role.","title":"Declaring Entities"},{"location":"build-nlp-model/#built-in-entities","text":"In the window \"Add Entity\", you can see that there are already pre-existing entities (prefixed by duckling ). These are the entities recognized by the eponymous library. These entities will be recognized and valued automatically if you specify them in at least one sentence of the intent.","title":"Built-in Entities"},{"location":"build-nlp-model/#validate-a-sentence","text":"If you think that the sentence is qualified correctly, you just have to click on \"Validate\" to confirm that the sentence is ok. If this is not the case, it's up to you to correct the meaning before validating it. You are building your first model!","title":"Validate a Sentence"},{"location":"build-nlp-model/#explore-the-model","text":"","title":"Explore the Model"},{"location":"build-nlp-model/#the-search-tab","text":"The Search tab allows you to browse all the sentences of the model. The most used criterion is the full text search input (regular expressions are allowed). You can then consult the sentences that are part of your model, and also change the qualifications of these sentences over time.","title":"The Search Tab"},{"location":"build-nlp-model/#states-of-a-sentence","text":"Each sentence has a state: Inbox : The sentence has not been qualified yet and is not included in the model Validated : The sentence has been validated but is not yet included in the NLP model (this can take some time for large models) Included in model : The sentence has been validated and is included in the model","title":"States of a Sentence"},{"location":"build-nlp-model/#advanced-features","text":"By clicking on the \"Applications\"menu, you get the list of existing applications. Then click of the edit button of the application you want to configure.","title":"Advanced Features"},{"location":"build-nlp-model/#nlp-engine-selection","text":"You can select the NLP library used by this application with the \"NLP engine\" radio button:","title":"Nlp Engine Selection"},{"location":"build-nlp-model/#use-built-in-entity-models","text":"This option allows you to reuse built-in entity models (ie duckling) in your new intent. For example, if you create an intent with a duckling:datetime entity, the dates will automatically be recognized for that intent in all new sentences assigned to that intent (Internally, a merge is performed between the info given by the built-in entity models and the info of your own model). This option is enabled by default, it can be useful to disable it for very large models, for which the NER detection will perform better in almost all cases.","title":"Use Built-in Entity Models"},{"location":"build-nlp-model/#use-sub-entities","text":"If you enable this option, you will be able to qualify multiple levels of entities: The number of levels is not limited, but it is advisable not to specify more than 3 or 4.","title":"Use sub-entities"},{"location":"build-nlp-model/#use-predefined-values","text":"An entity can have predefined values : you just have to click on \"Entities\" tab, and select an entity. A small icon next to the delete icon shows the types of entities you can edit as shown in the picture below:","title":"Use predefined values"},{"location":"code-a-bot/","text":"Tock's Conversationnal Language To develop a bot or an assistant with Tock, you can use its conversational DSL (Domain Specific Language) developed in Kotlin . Add the bot-toolkit Dependency The bot-toolkit dependency is required: With Maven: dependency groupId fr.vsct.tock /groupId artifactId bot-toolkit /artifactId version 19.3.3 /version /dependency With Gradle: compile fr.vsct.tock:bot-toolkit:19.3.3 A Bot is a Set of Stories This is how the open data bot is defined: val openBot = bot ( bot_open_data , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) This bot has an unique identifier (required - \"bot_open_data\") and a list of \"Story\" . A Story is a functional subset that has a main intention and, optionally, one or more so-called \"secondary\" intentions. Here the bot defines 4 Stories , greetings, departures, arrivals and search. Greetings is also set ( hello = greetings ) as the default story used for a new dialog. A Simple Story How do you define a story? Here is a first simplified version of the story greetings : val greetings = story ( greetings ) { send ( Welcome to the Tock Open Data Bot! :) ) end ( This is a Tock framework demonstration bot: https://github.com/voyages-sncf-technologies/tock ) } Note that in the body of the function, this has a BotBus type. From which you can interact with the user, and which also allows you to access to all available contextual elements. When the intention greetings will be detected by the NLP model, the function above will be called by the Tock framework. The bot sends successively a first response sentence ( bus.send() ), then a second one indicating that it is the last sentence of his answer using a bus.end() . Here is the full version of greetings : val greetings = story ( greetings ) { //cleanup state resetDialogState () send ( Welcome to the Tock Open Data Bot! :) ) send ( This is a Tock framework demonstration bot: https://github.com/voyages-sncf-technologies/tock ) withMessenger { buttonsTemplate ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , postbackButton ( Itineraries , search ), postbackButton ( Departures , Departures ), postbackButton ( Arrivals , Arrivals ) ) } withGoogleAssistant { gaMessage ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , Itineraries , Departures , Arrivals ) } end () } Two notions have been added: resetDialogState() which cleanup the state (forgetting any previous context). the withMessenger{} and withGoogleAssistant{} methods that define specific responses for each connector - Here it's a text with buttons for Messenger, and a text with suggestions for Google Assistant. Start and Connect the Bot To start the bot, simply add the following call to your main function: registerAndInstallBot ( openBot ) where the openBot variable is the bot you originally defined. When the bot is started, you also need to specify which connectors are used in the web administration interface: Configuration - Bot Configurations - Create a new configuration The documentation for each connector is in the README file of the corresponding sub-projects. Five are available by default: Messenger Google Assistant Slack RocketChat Twitter WhatsApp Teams Alexa - for Alexa, the NLP model is necessarily managed on Amazon side. So only the conversational framework of Tock can be used with this connector. Advanced options Of course, the StoryHandler of greetings does not depend on the context: the answer is always the same. Secondary Intentions Here is the beginning of the definition of the search story : val search = storyDef SearchDef ( search , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } The story search defines a secondary starter intent ( indicate_origin ) and a simple secondary intent ( indicate_location ). A secondary starter intent is similar in every respect to the main intent: as soon as the intent is detected, if the current story does not contain indicate_origin as secondary intent, the story search is called. For a classic secondary intent, on the other hand, the story will be executed only if the current story of the context is already the search story. Different stories can therefore share the same secondary intents. Handle Entities To retrieve entity values, it is good practice to define Kotlin extensions . For example here is the code used to retrieve the destination entity: val destinationEntity = openBot . entity ( location , destination ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) An entity of type \"location\" and role \"destination\" is created. There is a corresponding entity in the NLP model. A variable destination is defined, which will simplify the handling of this entity in the conversational code. This variable contains the current value of the destination in the user context. Here's a full version of the search story that uses destination : val search = storyDef SearchDef ( search , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null - end ( For which destination? ) origin == null - end ( For which origin? ) departureDate == null - end ( When? ) } } If there is no value in the current context for the destination, the bot asks to specify the destination and stays there. Same behaviour for the origin or date of departure. If the 3 required values are specified, then the real answer developed in the SearchDef class is used. Here is the full version of this first part of the code: val search = storyDef SearchDef ( search , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null - end ( For which destination? ) origin == null - end ( For which origin? ) departureDate == null - end ( When? ) } } In the case where the detected intention is indicate_location , we do not know if the locality represents the origin or the destination. A simple rule is then used: If there is already in the context an origin and no destination, the new locality is actually the destination. Otherwise, it is the origin. HandlerDef In the search story above, you may have noted the generic SearchDef typing. Here is the code of this class: @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef SearchConnector ( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( From {0} to {1} , o , d ) send ( Departure on {0} , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( Sorry, no routes found :( ) } else { send ( Here is the first proposal: ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef extends HandlerDef which is an alias of a Tock framework class. It is usually here that the code of complex stories is defined. The code contains an additional abstraction: SearchConnector . SearchConnector is the class that defines the behavior specific to each connector, and the annotations @GAHandler (GASearchConnector::class) and @MessengerHandler (MessengerSearchConnector::class) indicate the corresponding implementations for the different supported connectors (respectively Google Assistant and Messenger). What would happen there is no connector for Google Assistant for example, and if a call from Google Assistant is answered? The connector?.sendFirstJourney(journeys.first()) method call would not send the final response, since connector would be null . ConnectorDef Here is a simplified version of SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef SearchDef ( context ) { fun Section . title (): CharSequence = i18n ( {0} - {1} , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List Section ): ConnectorMessage } And its Messenger implementation: class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List Section ): ConnectorMessage = flexibleListTemplate ( sections . map { section - with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } The code specific to each connector is thus decoupled correctly. The code common to each connector is present in SearchConnector and the behavior specific to each connector is specified in the dedicated classes. StoryStep Sometimes you need to remember the stage at which the user is in the current story. For this, Tock provides the concept of StoryStep . There are two types of StoryStep. SimpleStoryStep enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps MyStep ( intent ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } To modify the current step, two methods are available: Manually change the step val story = storyWithSteps MyStep ( intent ) { //(...) step = MyStep . a // the step will be persisted as long as we stay in this story } Use buttons or quick replies More details on this topic here . StorySteps with complex behavior In more complex cases, we want to be able to define a behavior for each step. enum class MySteps : StoryStep MyHandlerDef { //no specific behaviour display , select { // select step will be automatically selected if the select sub-intention is detected override val intent : IntentAware ? = SecondaryIntent . select override fun answer (): MyHandlerDef .() - Any ? = { end ( I don t know yet how to select something ) } }, disruption { override fun answer (): ScoreboardDef .() - Any ? = { end ( some perturbation ) } }; } More configuration options are available. Check out the description of StoryStep . Postback buttons quick replies Messenger provides this type of button, as most connectors with GUI. With Tock, you can easily define the action performed after clicking on these buttons. In the following example, the button will redirect to the \"search\" intent: buttonsTemplate ( The bot is very limited! Only itineraries are supported :) , postbackButton ( Itineraries , search ) ) It is also possible to define a * StoryStep * and dedicated parameters: //to define parameters, just extend the ParameterKey interface enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( The bot is very limited! Only itineraries are supported :) , postbackButton ( Itineraries , intent = search , //if no step is specified, the current step is used step = MyStep . a , parameters = //this parameter is stored as a string (hooks are used) nextResultDate [ nextDate ] + //this parameter is stored in json (parentheses are used) nextResultOrigin ( origin ) ) ) To retrieve the parameters of the button that was clicked: val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin ) Define your own connector It is possible to develop its own connector. 1) Implement the interface Connector Here is an example of implementation: val testConnectorType = ConnectorType ( test ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router - //main API router . post ( $path/message ). blockingHandler { context - //ConnectorRequest is my business object passed by the front app val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //business object mapped to Tock event val event = readUserMessage ( message ) //we pass the Tock event to the framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //we record the action callback . actions . add ( event ) //if it s the last action to send, send the answer if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { unsupported event: $event } } } } // to retrieve all actions before sending class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList Action = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //we transform the list of Tock responses into a business response val response = mapper . writeValueAsString ( actions . map {...}) //then we send the answer context . response (). end ( response ) } } 2) Implement the interface ConnectorProvider Here is an example of implementation: object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Make this connector available via a Service Loader By placing a file META-INF/services/fr.vsct.tock.bot.connector.ConnectorProvider in the classpath, containing the class name : mypackage . TestConnectorProviderService 4) Add all classes and files created in the admin classpath and bot classpath The new connector must then be available in the \"Bot Configurations\" administration interface.","title":"Code a bot"},{"location":"code-a-bot/#tocks-conversationnal-language","text":"To develop a bot or an assistant with Tock, you can use its conversational DSL (Domain Specific Language) developed in Kotlin .","title":"Tock's Conversationnal Language"},{"location":"code-a-bot/#add-the-bot-toolkit-dependency","text":"The bot-toolkit dependency is required: With Maven: dependency groupId fr.vsct.tock /groupId artifactId bot-toolkit /artifactId version 19.3.3 /version /dependency With Gradle: compile fr.vsct.tock:bot-toolkit:19.3.3","title":"Add the bot-toolkit Dependency"},{"location":"code-a-bot/#a-bot-is-a-set-of-stories","text":"This is how the open data bot is defined: val openBot = bot ( bot_open_data , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) This bot has an unique identifier (required - \"bot_open_data\") and a list of \"Story\" . A Story is a functional subset that has a main intention and, optionally, one or more so-called \"secondary\" intentions. Here the bot defines 4 Stories , greetings, departures, arrivals and search. Greetings is also set ( hello = greetings ) as the default story used for a new dialog.","title":"A Bot is a Set of Stories"},{"location":"code-a-bot/#a-simple-story","text":"How do you define a story? Here is a first simplified version of the story greetings : val greetings = story ( greetings ) { send ( Welcome to the Tock Open Data Bot! :) ) end ( This is a Tock framework demonstration bot: https://github.com/voyages-sncf-technologies/tock ) } Note that in the body of the function, this has a BotBus type. From which you can interact with the user, and which also allows you to access to all available contextual elements. When the intention greetings will be detected by the NLP model, the function above will be called by the Tock framework. The bot sends successively a first response sentence ( bus.send() ), then a second one indicating that it is the last sentence of his answer using a bus.end() . Here is the full version of greetings : val greetings = story ( greetings ) { //cleanup state resetDialogState () send ( Welcome to the Tock Open Data Bot! :) ) send ( This is a Tock framework demonstration bot: https://github.com/voyages-sncf-technologies/tock ) withMessenger { buttonsTemplate ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , postbackButton ( Itineraries , search ), postbackButton ( Departures , Departures ), postbackButton ( Arrivals , Arrivals ) ) } withGoogleAssistant { gaMessage ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , Itineraries , Departures , Arrivals ) } end () } Two notions have been added: resetDialogState() which cleanup the state (forgetting any previous context). the withMessenger{} and withGoogleAssistant{} methods that define specific responses for each connector - Here it's a text with buttons for Messenger, and a text with suggestions for Google Assistant.","title":"A Simple Story"},{"location":"code-a-bot/#start-and-connect-the-bot","text":"To start the bot, simply add the following call to your main function: registerAndInstallBot ( openBot ) where the openBot variable is the bot you originally defined. When the bot is started, you also need to specify which connectors are used in the web administration interface: Configuration - Bot Configurations - Create a new configuration The documentation for each connector is in the README file of the corresponding sub-projects. Five are available by default: Messenger Google Assistant Slack RocketChat Twitter WhatsApp Teams Alexa - for Alexa, the NLP model is necessarily managed on Amazon side. So only the conversational framework of Tock can be used with this connector.","title":"Start and Connect the Bot"},{"location":"code-a-bot/#advanced-options","text":"Of course, the StoryHandler of greetings does not depend on the context: the answer is always the same.","title":"Advanced options"},{"location":"code-a-bot/#secondary-intentions","text":"Here is the beginning of the definition of the search story : val search = storyDef SearchDef ( search , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } The story search defines a secondary starter intent ( indicate_origin ) and a simple secondary intent ( indicate_location ). A secondary starter intent is similar in every respect to the main intent: as soon as the intent is detected, if the current story does not contain indicate_origin as secondary intent, the story search is called. For a classic secondary intent, on the other hand, the story will be executed only if the current story of the context is already the search story. Different stories can therefore share the same secondary intents.","title":"Secondary Intentions"},{"location":"code-a-bot/#handle-entities","text":"To retrieve entity values, it is good practice to define Kotlin extensions . For example here is the code used to retrieve the destination entity: val destinationEntity = openBot . entity ( location , destination ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) An entity of type \"location\" and role \"destination\" is created. There is a corresponding entity in the NLP model. A variable destination is defined, which will simplify the handling of this entity in the conversational code. This variable contains the current value of the destination in the user context. Here's a full version of the search story that uses destination : val search = storyDef SearchDef ( search , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null - end ( For which destination? ) origin == null - end ( For which origin? ) departureDate == null - end ( When? ) } } If there is no value in the current context for the destination, the bot asks to specify the destination and stays there. Same behaviour for the origin or date of departure. If the 3 required values are specified, then the real answer developed in the SearchDef class is used. Here is the full version of this first part of the code: val search = storyDef SearchDef ( search , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null - end ( For which destination? ) origin == null - end ( For which origin? ) departureDate == null - end ( When? ) } } In the case where the detected intention is indicate_location , we do not know if the locality represents the origin or the destination. A simple rule is then used: If there is already in the context an origin and no destination, the new locality is actually the destination. Otherwise, it is the origin.","title":"Handle Entities"},{"location":"code-a-bot/#handlerdef","text":"In the search story above, you may have noted the generic SearchDef typing. Here is the code of this class: @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef SearchConnector ( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( From {0} to {1} , o , d ) send ( Departure on {0} , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( Sorry, no routes found :( ) } else { send ( Here is the first proposal: ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef extends HandlerDef which is an alias of a Tock framework class. It is usually here that the code of complex stories is defined. The code contains an additional abstraction: SearchConnector . SearchConnector is the class that defines the behavior specific to each connector, and the annotations @GAHandler (GASearchConnector::class) and @MessengerHandler (MessengerSearchConnector::class) indicate the corresponding implementations for the different supported connectors (respectively Google Assistant and Messenger). What would happen there is no connector for Google Assistant for example, and if a call from Google Assistant is answered? The connector?.sendFirstJourney(journeys.first()) method call would not send the final response, since connector would be null .","title":"HandlerDef"},{"location":"code-a-bot/#connectordef","text":"Here is a simplified version of SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef SearchDef ( context ) { fun Section . title (): CharSequence = i18n ( {0} - {1} , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List Section ): ConnectorMessage } And its Messenger implementation: class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List Section ): ConnectorMessage = flexibleListTemplate ( sections . map { section - with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } The code specific to each connector is thus decoupled correctly. The code common to each connector is present in SearchConnector and the behavior specific to each connector is specified in the dedicated classes.","title":"ConnectorDef"},{"location":"code-a-bot/#storystep","text":"Sometimes you need to remember the stage at which the user is in the current story. For this, Tock provides the concept of StoryStep . There are two types of StoryStep.","title":"StoryStep"},{"location":"code-a-bot/#simplestorystep","text":"enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps MyStep ( intent ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } To modify the current step, two methods are available: Manually change the step val story = storyWithSteps MyStep ( intent ) { //(...) step = MyStep . a // the step will be persisted as long as we stay in this story } Use buttons or quick replies More details on this topic here .","title":"SimpleStoryStep"},{"location":"code-a-bot/#storysteps-with-complex-behavior","text":"In more complex cases, we want to be able to define a behavior for each step. enum class MySteps : StoryStep MyHandlerDef { //no specific behaviour display , select { // select step will be automatically selected if the select sub-intention is detected override val intent : IntentAware ? = SecondaryIntent . select override fun answer (): MyHandlerDef .() - Any ? = { end ( I don t know yet how to select something ) } }, disruption { override fun answer (): ScoreboardDef .() - Any ? = { end ( some perturbation ) } }; } More configuration options are available. Check out the description of StoryStep .","title":"StorySteps with complex behavior"},{"location":"code-a-bot/#postback-buttons-quick-replies","text":"Messenger provides this type of button, as most connectors with GUI. With Tock, you can easily define the action performed after clicking on these buttons. In the following example, the button will redirect to the \"search\" intent: buttonsTemplate ( The bot is very limited! Only itineraries are supported :) , postbackButton ( Itineraries , search ) ) It is also possible to define a * StoryStep * and dedicated parameters: //to define parameters, just extend the ParameterKey interface enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( The bot is very limited! Only itineraries are supported :) , postbackButton ( Itineraries , intent = search , //if no step is specified, the current step is used step = MyStep . a , parameters = //this parameter is stored as a string (hooks are used) nextResultDate [ nextDate ] + //this parameter is stored in json (parentheses are used) nextResultOrigin ( origin ) ) ) To retrieve the parameters of the button that was clicked: val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin )","title":"Postback buttons &amp; quick replies"},{"location":"code-a-bot/#define-your-own-connector","text":"It is possible to develop its own connector. 1) Implement the interface Connector Here is an example of implementation: val testConnectorType = ConnectorType ( test ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router - //main API router . post ( $path/message ). blockingHandler { context - //ConnectorRequest is my business object passed by the front app val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //business object mapped to Tock event val event = readUserMessage ( message ) //we pass the Tock event to the framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //we record the action callback . actions . add ( event ) //if it s the last action to send, send the answer if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { unsupported event: $event } } } } // to retrieve all actions before sending class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList Action = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //we transform the list of Tock responses into a business response val response = mapper . writeValueAsString ( actions . map {...}) //then we send the answer context . response (). end ( response ) } } 2) Implement the interface ConnectorProvider Here is an example of implementation: object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Make this connector available via a Service Loader By placing a file META-INF/services/fr.vsct.tock.bot.connector.ConnectorProvider in the classpath, containing the class name : mypackage . TestConnectorProviderService 4) Add all classes and files created in the admin classpath and bot classpath The new connector must then be available in the \"Bot Configurations\" administration interface.","title":"Define your own connector"},{"location":"contribute/","text":"Contribute to the Tock project Build the project The project uses Maven . mvn package A CI build is available on Travis . Start the project in the IDE In addition to docker images , the project provides IntelliJ configurations: The bot administration server: BotAdmin The NLP administration server only: Admin The NLP service: NlpService The Duckling service: Duckling Build engine for NLP models: BuildWorker To manage script compilation at runtime: KotlinCompilerServer And for the open data bot: OpenDataBot In order to launch the administration front interfaces, please consult the README files: For bot and NLP administration interface For NLP administration only Code conventions Conventions are described in Kotlin Code Conventions","title":"Contribute"},{"location":"contribute/#contribute-to-the-tock-project","text":"","title":"Contribute to the Tock project"},{"location":"contribute/#build-the-project","text":"The project uses Maven . mvn package A CI build is available on Travis .","title":"Build the project"},{"location":"contribute/#start-the-project-in-the-ide","text":"In addition to docker images , the project provides IntelliJ configurations: The bot administration server: BotAdmin The NLP administration server only: Admin The NLP service: NlpService The Duckling service: Duckling Build engine for NLP models: BuildWorker To manage script compilation at runtime: KotlinCompilerServer And for the open data bot: OpenDataBot In order to launch the administration front interfaces, please consult the README files: For bot and NLP administration interface For NLP administration only","title":"Start the project in the IDE"},{"location":"contribute/#code-conventions","text":"Conventions are described in Kotlin Code Conventions","title":"Code conventions"},{"location":"evaluate-the-model/","text":"Evaluate the relevance of a NLP model Tabs Five tabs are used to control the relevance of the model: Stats : Monitores model perfomance in production: self-evaluation of the model about its relevance in terms of recognition of intent and entities number of calls and errors average execution time Test Trend : evolution of the relevance of partial model tests Intent Errors : the list of intent errors found with partial model tests Entity Errors : the list of entity errors found with partial model tests Model Builds : the cimplete list of model builds Partial Model Tests Partial model tests is a way to detect qualifications errors. Temporarily models are built from a random part of the whole sentence set of the model (90% for example) and then tested against the remaining sentences. The process is repeated a number of times and the most frequent errors are pushed to an admin user. Partial model tests are useful only with large models. Intent errors Click on the Intent Errors tab: Since the picture above is built from a very simple model, no real error has been detected. We can nevertheless note that in some cases the model is systematically wrong with a high probability. Entity errors These errors can be viewed via the Entity Errors tab.","title":"Evaluate the model"},{"location":"evaluate-the-model/#evaluate-the-relevance-of-a-nlp-model","text":"","title":"Evaluate the relevance of a NLP model"},{"location":"evaluate-the-model/#tabs","text":"Five tabs are used to control the relevance of the model: Stats : Monitores model perfomance in production: self-evaluation of the model about its relevance in terms of recognition of intent and entities number of calls and errors average execution time Test Trend : evolution of the relevance of partial model tests Intent Errors : the list of intent errors found with partial model tests Entity Errors : the list of entity errors found with partial model tests Model Builds : the cimplete list of model builds","title":"Tabs"},{"location":"evaluate-the-model/#partial-model-tests","text":"Partial model tests is a way to detect qualifications errors. Temporarily models are built from a random part of the whole sentence set of the model (90% for example) and then tested against the remaining sentences. The process is repeated a number of times and the most frequent errors are pushed to an admin user. Partial model tests are useful only with large models.","title":"Partial Model Tests"},{"location":"evaluate-the-model/#intent-errors","text":"Click on the Intent Errors tab: Since the picture above is built from a very simple model, no real error has been detected. We can nevertheless note that in some cases the model is systematically wrong with a high probability.","title":"Intent errors"},{"location":"evaluate-the-model/#entity-errors","text":"These errors can be viewed via the Entity Errors tab.","title":"Entity errors"},{"location":"getting-started/","text":"Getting Started A Sample Bot A sample bot using Tock is available: https://github.com/voyages-sncf-technologies/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit. Docker Images Docker images are available in the Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the github repository https://github.com/voyages-sncf-technologies/tock-docker . Start the NLP stack #get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/voyages-sncf-technologies/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts curl -o scripts/setup.sh https://raw.githubusercontent.com/voyages-sncf-technologies/tock-docker/master/scripts/setup.sh chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/voyages-sncf-technologies/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80: http://localhost The default login is admin@app.com and the password is password . Sample bot based on Open Data APIs A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images . Administration Interface Menu The Configuration menu allows you to create new models and configure them. The NLP and NLP QA menus are dedicated to building NLP models. The Build , Test and Monitoring menus are used for building bots or assistants.","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#a-sample-bot","text":"A sample bot using Tock is available: https://github.com/voyages-sncf-technologies/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit.","title":"A Sample Bot"},{"location":"getting-started/#docker-images","text":"Docker images are available in the Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the github repository https://github.com/voyages-sncf-technologies/tock-docker .","title":"Docker Images"},{"location":"getting-started/#start-the-nlp-stack","text":"#get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/voyages-sncf-technologies/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts curl -o scripts/setup.sh https://raw.githubusercontent.com/voyages-sncf-technologies/tock-docker/master/scripts/setup.sh chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/voyages-sncf-technologies/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80: http://localhost The default login is admin@app.com and the password is password .","title":"Start the NLP stack"},{"location":"getting-started/#sample-bot-based-on-open-data-apis","text":"A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images .","title":"Sample bot based on Open Data APIs"},{"location":"getting-started/#administration-interface-menu","text":"The Configuration menu allows you to create new models and configure them. The NLP and NLP QA menus are dedicated to building NLP models. The Build , Test and Monitoring menus are used for building bots or assistants.","title":"Administration Interface Menu"},{"location":"i18n/","text":"Translate bot responses Activation The Tock framework provides an internationalization framework. It is disabled by default. To activate it, add this code when starting the bot: Translator . enabled = true or set the system property -Dtock_i18n_enabled=true . How to develop for more than one locale Let's Code The code does not change once the internationalization is activated. For example: send ( Arrival at {0} , time ) is a valid code whether the module is activated or not. On the other hand, at runtime, the behavior differs significantly. If internationalization is enabled, the following operations will be performed: A key will be generated from the text passed in parameter, according to the namespace (the organization of the creator of the bot) and the story in which this wording is requested. In the case above, it will look like app_arrivals_arrival_Arrival at {0} where app is the namespace and arrivals the main intention of the story. The framework checks if this key is already present. If this is the case, it uses the label present in the database for the requested locale to find the most appropriate translation (the connector or the type of interface can also be taken into account) Otherwise, a key is created with the default label (\"Arrival at {0}\" in our example) used for the current locale It is then possible to consult and modify this label in the administration interface: Supported format The supported format is the standard i18n java format used by MessageFormat and ChoiceFormat : send ( There {0,choice,0#are no files|1#is one file|1 are {0,number,integer} files}. , 2 ) In addition, Tock provides a by extension for dates that allows you to specify a dedicated format for the parameters: send ( Departure at {0} , departureDateTime by timeFormat ) User Locale When possible, the user locale is imported from the user account of the connector. For example, if the Messenger account is configured in French, French will be automatically used as the user locale by Tock. If there is no account locale, the defaultLocale value is taken into account. You can modify this default value with a system property: -Dtock_default_locale=fr Finally it is possible to modify the locale of the user in the bot itself: userPreferences . locale = Locale . FRENCH Points of attention Tock's internationalization module is effective, but some practices, yet intuitive in Kotlin, are to be banished. For example, this code works perfectly well with the disabled i18n module. send ( There are $nb files ) //DANGER!! but is problematic if i18n is enabled. A new label will be inserted for each different value of the nb variable! If it is necessary to send \"not to translate\" answers, use BotBus.sendRaw , BotBus.endRaw , or String.raw methods. send ( There are $nb files . raw ) //CORRECT send ( There are {0} files , nb ) //BETTER The risk of collision between two labels is low since the main intention of the story is part of the key. However, if you want to avoid any risk, you can use the i18nKey method: send ( i18nKey ( my_unique_key , There are {0} files , nb )) Test internationalization An example of an i18n test is available in the open data bot source code . You need to use a custom test extension to indicate the label translations . And the test looks like: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( Recherche , search , locale = Locale . FRENCH ) { destination = lille origin = paris run () firstAnswer . assertText ( Quand souhaitez-vous partir? ) } } Administration interface The different variants Each label has a default value for each language of the bot. It is also possible to indicate specific answers: by connector type (Messenger, Google Assistant, Slack, etc.) by type of interface (Text or voice) - this is useful for example in the case of Google Assistant to support the voice only use cases. Finally, you can specify alternatives . In this case, the bot uses one of the possible alternatives at random, each time it sends a response to the user. Import and export of data Labels import/export (json or csv format) is available. When importing, only labels indicated as validated are taken into account.","title":"i18n"},{"location":"i18n/#translate-bot-responses","text":"","title":"Translate bot responses"},{"location":"i18n/#activation","text":"The Tock framework provides an internationalization framework. It is disabled by default. To activate it, add this code when starting the bot: Translator . enabled = true or set the system property -Dtock_i18n_enabled=true .","title":"Activation"},{"location":"i18n/#how-to-develop-for-more-than-one-locale","text":"","title":"How to develop for more than one locale"},{"location":"i18n/#lets-code","text":"The code does not change once the internationalization is activated. For example: send ( Arrival at {0} , time ) is a valid code whether the module is activated or not. On the other hand, at runtime, the behavior differs significantly. If internationalization is enabled, the following operations will be performed: A key will be generated from the text passed in parameter, according to the namespace (the organization of the creator of the bot) and the story in which this wording is requested. In the case above, it will look like app_arrivals_arrival_Arrival at {0} where app is the namespace and arrivals the main intention of the story. The framework checks if this key is already present. If this is the case, it uses the label present in the database for the requested locale to find the most appropriate translation (the connector or the type of interface can also be taken into account) Otherwise, a key is created with the default label (\"Arrival at {0}\" in our example) used for the current locale It is then possible to consult and modify this label in the administration interface:","title":"Let's Code"},{"location":"i18n/#supported-format","text":"The supported format is the standard i18n java format used by MessageFormat and ChoiceFormat : send ( There {0,choice,0#are no files|1#is one file|1 are {0,number,integer} files}. , 2 ) In addition, Tock provides a by extension for dates that allows you to specify a dedicated format for the parameters: send ( Departure at {0} , departureDateTime by timeFormat )","title":"Supported format"},{"location":"i18n/#user-locale","text":"When possible, the user locale is imported from the user account of the connector. For example, if the Messenger account is configured in French, French will be automatically used as the user locale by Tock. If there is no account locale, the defaultLocale value is taken into account. You can modify this default value with a system property: -Dtock_default_locale=fr Finally it is possible to modify the locale of the user in the bot itself: userPreferences . locale = Locale . FRENCH","title":"User Locale"},{"location":"i18n/#points-of-attention","text":"Tock's internationalization module is effective, but some practices, yet intuitive in Kotlin, are to be banished. For example, this code works perfectly well with the disabled i18n module. send ( There are $nb files ) //DANGER!! but is problematic if i18n is enabled. A new label will be inserted for each different value of the nb variable! If it is necessary to send \"not to translate\" answers, use BotBus.sendRaw , BotBus.endRaw , or String.raw methods. send ( There are $nb files . raw ) //CORRECT send ( There are {0} files , nb ) //BETTER The risk of collision between two labels is low since the main intention of the story is part of the key. However, if you want to avoid any risk, you can use the i18nKey method: send ( i18nKey ( my_unique_key , There are {0} files , nb ))","title":"Points of attention"},{"location":"i18n/#test-internationalization","text":"An example of an i18n test is available in the open data bot source code . You need to use a custom test extension to indicate the label translations . And the test looks like: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( Recherche , search , locale = Locale . FRENCH ) { destination = lille origin = paris run () firstAnswer . assertText ( Quand souhaitez-vous partir? ) } }","title":"Test internationalization"},{"location":"i18n/#administration-interface","text":"","title":"Administration interface"},{"location":"i18n/#the-different-variants","text":"Each label has a default value for each language of the bot. It is also possible to indicate specific answers: by connector type (Messenger, Google Assistant, Slack, etc.) by type of interface (Text or voice) - this is useful for example in the case of Google Assistant to support the voice only use cases. Finally, you can specify alternatives . In this case, the bot uses one of the possible alternatives at random, each time it sends a response to the user.","title":"The different variants"},{"location":"i18n/#import-and-export-of-data","text":"Labels import/export (json or csv format) is available. When importing, only labels indicated as validated are taken into account.","title":"Import and export of data"},{"location":"kdoc/","text":"A KDoc documentation is provided .","title":"KDoc"},{"location":"test-the-bot/","text":"Use the Test Framework Tock provides extensions in order to help writing better unit tests. To use them, you need to add the bot-test dependency to your project. With Maven : dependency groupId fr.vsct.tock /groupId artifactId bot-test /artifactId version 19.3.3 /version scope test /scope /dependency With Gradle : testCompile fr.vsct.tock:bot-test:19.3.3 This framework is documented in KDoc format here . Write a Simple Test In the next samples, JUnit5 is used as test engine. A dedicated extension for Tock is available . @RegisterExtension @JvmField val ext = TockJUnit5Extension () To test the greetings story of the Open Data bot, just use the ext.send() method: @Test fun `greetings story displays welcome message` () { ext . send { firstAnswer . assertText ( Welcome to the Tock Open Data Bot! :) ) secondAnswer . assertText ( This is a Tock framework demonstration bot: https://github.com/voyages-sncf-technologies/tock ) } } As the default connector is Messenger, it is possible to test the message specific to Messenger in the same way: @Test fun `greetings story displays welcome message with Messenger dedicated message` () { ext . send { lastAnswer . assertMessage ( buttonsTemplate ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , postbackButton ( Itineraries , search ), postbackButton ( Departures , Departures ), postbackButton ( Arrivals , Arrivals ) ) ) } } To test the message specific to Google Assistant (or any other connector), you need to indicate the connector to be tested: @Test fun `greetings story displays welcome message with GA dedicated message WHEN context contains GA connector` () { ext . send ( connectorType = gaConnectorType ) { firstAnswer . assertText ( Welcome to the Tock Open Data Bot! :) ) secondAnswer . assertText ( This is a Tock framework demonstration bot: https://github.com/voyages-sncf-technologies/tock ) lastAnswer . assertMessage ( gaMessage ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , Itineraries , Departures , Arrivals ) ) } } Test a specific Story In the previous examples, it was useless to specify the story to test ( greetings being the default story). Suppose you want to test the search story, then you need to indicate the story to test as follows: @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search ) { firstAnswer . assertText ( For which destination? ) } } Test a Conversation You can simulate a whole conversation. For example, here the user indicates the destination, then the origin: @Test fun `search story asks for origin WHEN there is a destination BUT no origin in context` () { ext . send ( I would like to find a train , search ) { firstAnswer . assertText ( For which destination? ) } ext . send ( Lille , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( For which origin? ) } ext . send ( Paris , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( When? ) } } The first text parameter of the send method is merely indicative, to help understanding the tests. The others parameters defines how the NLP engine has analysed the text. For example : private val lille = PlaceValue ( SncfPlace ( stop_area , 90 , Lille Europe , Lille Europe (Lille) , stop_area:OCE:SA:87223263 , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( Lille , indicate_location , locationEntity setTo lille ) indicate that the phrase \"Lille\" is categorized as an indicate_location intent with a value lille for the entity location . Finally it is possible to modify all the values of the mocked bus at initialization. In the following example, the use of the secondary intent indicate_location is simulated to indicate the origin: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( Search , search ) { destination = lille origin = paris run () firstAnswer . assertText ( When? ) } } The destination and origin variables are updated, then a call to the bus is simulated with the function run() .","title":"Test the bot"},{"location":"test-the-bot/#use-the-test-framework","text":"Tock provides extensions in order to help writing better unit tests. To use them, you need to add the bot-test dependency to your project. With Maven : dependency groupId fr.vsct.tock /groupId artifactId bot-test /artifactId version 19.3.3 /version scope test /scope /dependency With Gradle : testCompile fr.vsct.tock:bot-test:19.3.3 This framework is documented in KDoc format here .","title":"Use the Test Framework"},{"location":"test-the-bot/#write-a-simple-test","text":"In the next samples, JUnit5 is used as test engine. A dedicated extension for Tock is available . @RegisterExtension @JvmField val ext = TockJUnit5Extension () To test the greetings story of the Open Data bot, just use the ext.send() method: @Test fun `greetings story displays welcome message` () { ext . send { firstAnswer . assertText ( Welcome to the Tock Open Data Bot! :) ) secondAnswer . assertText ( This is a Tock framework demonstration bot: https://github.com/voyages-sncf-technologies/tock ) } } As the default connector is Messenger, it is possible to test the message specific to Messenger in the same way: @Test fun `greetings story displays welcome message with Messenger dedicated message` () { ext . send { lastAnswer . assertMessage ( buttonsTemplate ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , postbackButton ( Itineraries , search ), postbackButton ( Departures , Departures ), postbackButton ( Arrivals , Arrivals ) ) ) } } To test the message specific to Google Assistant (or any other connector), you need to indicate the connector to be tested: @Test fun `greetings story displays welcome message with GA dedicated message WHEN context contains GA connector` () { ext . send ( connectorType = gaConnectorType ) { firstAnswer . assertText ( Welcome to the Tock Open Data Bot! :) ) secondAnswer . assertText ( This is a Tock framework demonstration bot: https://github.com/voyages-sncf-technologies/tock ) lastAnswer . assertMessage ( gaMessage ( The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :) , Itineraries , Departures , Arrivals ) ) } }","title":"Write a Simple Test"},{"location":"test-the-bot/#test-a-specific-story","text":"In the previous examples, it was useless to specify the story to test ( greetings being the default story). Suppose you want to test the search story, then you need to indicate the story to test as follows: @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search ) { firstAnswer . assertText ( For which destination? ) } }","title":"Test a specific Story"},{"location":"test-the-bot/#test-a-conversation","text":"You can simulate a whole conversation. For example, here the user indicates the destination, then the origin: @Test fun `search story asks for origin WHEN there is a destination BUT no origin in context` () { ext . send ( I would like to find a train , search ) { firstAnswer . assertText ( For which destination? ) } ext . send ( Lille , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( For which origin? ) } ext . send ( Paris , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( When? ) } } The first text parameter of the send method is merely indicative, to help understanding the tests. The others parameters defines how the NLP engine has analysed the text. For example : private val lille = PlaceValue ( SncfPlace ( stop_area , 90 , Lille Europe , Lille Europe (Lille) , stop_area:OCE:SA:87223263 , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( Lille , indicate_location , locationEntity setTo lille ) indicate that the phrase \"Lille\" is categorized as an indicate_location intent with a value lille for the entity location . Finally it is possible to modify all the values of the mocked bus at initialization. In the following example, the use of the secondary intent indicate_location is simulated to indicate the origin: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( Search , search ) { destination = lille origin = paris run () firstAnswer . assertText ( When? ) } } The destination and origin variables are updated, then a call to the bus is simulated with the function run() .","title":"Test a Conversation"},{"location":"the-open-data-bot/","text":"Getting Started with the Conversational Framework The Open Data Bot A good starting point is the source code of the Open Data Bot Follow the instructions of the README file of the project, to start the bot in the IDE (do not configure Messenger or Google Assistant at this point), then connect to the administration interface. The bot is already testable. The Test Tab Go to this tab, and test the bot: This is a test mode, so the interface is minimal. The real goal is to have your users interact with the bot via channels like Messenger, Google Assistant ... or your sites or applications. The Monitoring Tab It is then possible to consult the discussion that you just had with the bot via the Monitoring tab: In this sample, this dialog has the Messenger flag, as it was tested for this channel. The Build Tab Add a new answer With the category Add new Answer , it is possible to add directly a new answer: Then test the new intention and its answer: Modify the Answers and Internationalization Finally it is possible to modify each answer of the bot, by type of interface (chat / voice), by type of connector and by language with the i18n tab. The ability to add alternative answers (a response from the list will be chosen each time at random) is also provided (with the \"plus\" button).","title":"The Open Data Bot"},{"location":"the-open-data-bot/#getting-started-with-the-conversational-framework","text":"","title":"Getting Started with the Conversational Framework"},{"location":"the-open-data-bot/#the-open-data-bot","text":"A good starting point is the source code of the Open Data Bot Follow the instructions of the README file of the project, to start the bot in the IDE (do not configure Messenger or Google Assistant at this point), then connect to the administration interface. The bot is already testable.","title":"The Open Data Bot"},{"location":"the-open-data-bot/#the-test-tab","text":"Go to this tab, and test the bot: This is a test mode, so the interface is minimal. The real goal is to have your users interact with the bot via channels like Messenger, Google Assistant ... or your sites or applications.","title":"The Test Tab"},{"location":"the-open-data-bot/#the-monitoring-tab","text":"It is then possible to consult the discussion that you just had with the bot via the Monitoring tab: In this sample, this dialog has the Messenger flag, as it was tested for this channel.","title":"The Monitoring Tab"},{"location":"the-open-data-bot/#the-build-tab","text":"","title":"The Build Tab"},{"location":"the-open-data-bot/#add-a-new-answer","text":"With the category Add new Answer , it is possible to add directly a new answer: Then test the new intention and its answer:","title":"Add a new answer"},{"location":"the-open-data-bot/#modify-the-answers-and-internationalization","text":"Finally it is possible to modify each answer of the bot, by type of interface (chat / voice), by type of connector and by language with the i18n tab. The ability to add alternative answers (a response from the list will be chosen each time at random) is also provided (with the \"plus\" button).","title":"Modify the Answers and Internationalization"}]}