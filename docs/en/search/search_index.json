{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Tock - open conversational platform \u00b6 Tock ( The Open Conversation Kit ) is a complete and open platform to build conversational agents - also known as bots . Tock does not depend on 3rd-party APIs, although it is possible to integrate with them. Users choose which components to embed and decide to keep (or share) ownership of conversational data and models. Tock has been used in production for several years by OUI.sncf to propose various assistants over its own channels (Web, mobile), social networks, as well as smart speakers. The platform source code is available on GitHub under the Apache License, version 2.0 . Features \u00b6 Standalone bots or integrated with Web sites, mobile apps, social networks, smart speakers. Full-featured NLU (Natural Language Understanding) platform, compatible with algorithms such as OpenNLP , Stanford CoreNLP , Duckling , can be deployed alone (for use cases like the Internet Of Things for instance) Tock Studio user interfaces: Models management, bot training Conversational no-code story builder Internationalization ( i18n ) support for multilingual bots Conversations, performance et model errors monitoring Interactive trends / users flow analytics ( Bot Flow ) Frameworks available to develop complex stories and integrate with 3rd-party services: Kotlin DSL plus any-language API Numerous connectors to Messenger , WhatsApp , Google Assistant / Home , Twitter , Alexa , Business Chat / iMessage , Teams , Slack ... (see connectors ) Cloud or on-premise setups, with or without Docker , \"embedded\" bots without Internet Technologies \u00b6 Tock runs on JVM platforms. The reference language is Kotlin , but other programming languages can be leveraged through the available APIs. Tock relies on Vert.x and MongoDB . Various NLU libraries and algorithms can be used, such as Apache OpenNLP or Stanford CoreNLP , but Tock does not depend on them directly. Graphical interfaces (Tock Studio) are made with Angular in Typescript . Getting started... \u00b6 Read Tutorial and start using the demo/sandbox platform","title":"Overview"},{"location":"#welcome-to-tock-open-conversational-platform","text":"Tock ( The Open Conversation Kit ) is a complete and open platform to build conversational agents - also known as bots . Tock does not depend on 3rd-party APIs, although it is possible to integrate with them. Users choose which components to embed and decide to keep (or share) ownership of conversational data and models. Tock has been used in production for several years by OUI.sncf to propose various assistants over its own channels (Web, mobile), social networks, as well as smart speakers. The platform source code is available on GitHub under the Apache License, version 2.0 .","title":"Welcome to Tock - open conversational platform"},{"location":"#features","text":"Standalone bots or integrated with Web sites, mobile apps, social networks, smart speakers. Full-featured NLU (Natural Language Understanding) platform, compatible with algorithms such as OpenNLP , Stanford CoreNLP , Duckling , can be deployed alone (for use cases like the Internet Of Things for instance) Tock Studio user interfaces: Models management, bot training Conversational no-code story builder Internationalization ( i18n ) support for multilingual bots Conversations, performance et model errors monitoring Interactive trends / users flow analytics ( Bot Flow ) Frameworks available to develop complex stories and integrate with 3rd-party services: Kotlin DSL plus any-language API Numerous connectors to Messenger , WhatsApp , Google Assistant / Home , Twitter , Alexa , Business Chat / iMessage , Teams , Slack ... (see connectors ) Cloud or on-premise setups, with or without Docker , \"embedded\" bots without Internet","title":"Features"},{"location":"#technologies","text":"Tock runs on JVM platforms. The reference language is Kotlin , but other programming languages can be leveraged through the available APIs. Tock relies on Vert.x and MongoDB . Various NLU libraries and algorithms can be used, such as Apache OpenNLP or Stanford CoreNLP , but Tock does not depend on them directly. Graphical interfaces (Tock Studio) are made with Angular in Typescript .","title":"Technologies"},{"location":"#getting-started","text":"Read Tutorial and start using the demo/sandbox platform","title":"Getting started..."},{"location":"api/","text":"You can test a model via the Tock NLP API. Please consult the documentation /api . If you want to test the API, run the docker images and open the url http://localhost/doc/index.html Also, Administration API (in order to manage the models) is documented: /api/admin If you want to test the Admin API, run the docker images and open the url http://localhost/doc/admin.html","title":"Api"},{"location":"build-nlp-model/","text":"Build a New NLU (Natural Language Understanding) Model \u00b6 Overview \u00b6 Seven tabs are available: Try it : add (or test) a new sentence Inbox : not yet qualified sentences Archive : the set of archived sentences, i. e. marked as not yet recognized by the model. Search : an advanced search interface that lets you search for sentences, whether or not they are qualified. Intents : the list of the model's intentions Entities : the list of model entities Logs : the last queries requested via the NLP API The user is redirected by default to Inbox . Add and Qualify Sentences \u00b6 Add a New Sentence \u00b6 Click on the Try It menu and enter the new sentence. The add a new user intent by selecting \"Create a New Intent\" in the \"Intent\" selection list. Declaring Entities \u00b6 If necessary, you can specify the entities of this new intent, by selecting the text of these entities, and then clicking on the \"Add New Entity\" button that has just appeared. It's up to you to choose an existing entity type, or create a new one, and then give that entity a role. Built-in Entities \u00b6 In the window \"Add Entity\", you can see that there are already pre-existing entities (prefixed by duckling ). These are the entities recognized by the eponymous library. These entities will be recognized and valued automatically if you specify them in at least one sentence of the intent. Validate a Sentence \u00b6 If you think that the sentence is qualified correctly, you just have to click on \"Validate\" to confirm that the sentence is ok. If this is not the case, it's up to you to correct the meaning before validating it. You are building your first model! Explore the Model \u00b6 The Search Tab \u00b6 The Search tab allows you to browse all the sentences of the model. The most used criterion is the full text search input (regular expressions are allowed). You can then consult the sentences that are part of your model, and also change the qualifications of these sentences over time. States of a Sentence \u00b6 Each sentence has a state: Inbox : The sentence has not been qualified yet and is not included in the model Validated : The sentence has been validated but is not yet included in the NLP model (this can take some time for large models) Included in model : The sentence has been validated and is included in the model Advanced Features \u00b6 By clicking on the \"Applications\"menu, you get the list of existing applications. Then click of the edit button of the application you want to configure. Nlp Engine Selection \u00b6 You can select the NLP library used by this application with the \"NLP engine\" radio button: Use Built-in Entity Models \u00b6 This option allows you to reuse built-in entity models (ie duckling) in your new intent. For example, if you create an intent with a duckling:datetime entity, the dates will automatically be recognized for that intent in all new sentences assigned to that intent (Internally, a merge is performed between the info given by the built-in entity models and the info of your own model). This option is enabled by default, it can be useful to disable it for very large models, for which the NER detection will perform better in almost all cases. Use sub-entities \u00b6 If you enable this option, you will be able to qualify multiple levels of entities: The number of levels is not limited, but it is advisable not to specify more than 3 or 4. Use predefined values \u00b6 An entity can have predefined values : you just have to click on \"Entities\" tab, and select an entity. A small icon next to the delete icon shows the types of entities you can edit as shown in the picture below:","title":"Build NLP models"},{"location":"build-nlp-model/#build-a-new-nlu-natural-language-understanding-model","text":"","title":"Build a New NLU (Natural Language Understanding) Model"},{"location":"build-nlp-model/#overview","text":"Seven tabs are available: Try it : add (or test) a new sentence Inbox : not yet qualified sentences Archive : the set of archived sentences, i. e. marked as not yet recognized by the model. Search : an advanced search interface that lets you search for sentences, whether or not they are qualified. Intents : the list of the model's intentions Entities : the list of model entities Logs : the last queries requested via the NLP API The user is redirected by default to Inbox .","title":"Overview"},{"location":"build-nlp-model/#add-and-qualify-sentences","text":"","title":"Add and Qualify Sentences"},{"location":"build-nlp-model/#add-a-new-sentence","text":"Click on the Try It menu and enter the new sentence. The add a new user intent by selecting \"Create a New Intent\" in the \"Intent\" selection list.","title":"Add a New Sentence"},{"location":"build-nlp-model/#declaring-entities","text":"If necessary, you can specify the entities of this new intent, by selecting the text of these entities, and then clicking on the \"Add New Entity\" button that has just appeared. It's up to you to choose an existing entity type, or create a new one, and then give that entity a role.","title":"Declaring Entities"},{"location":"build-nlp-model/#built-in-entities","text":"In the window \"Add Entity\", you can see that there are already pre-existing entities (prefixed by duckling ). These are the entities recognized by the eponymous library. These entities will be recognized and valued automatically if you specify them in at least one sentence of the intent.","title":"Built-in Entities"},{"location":"build-nlp-model/#validate-a-sentence","text":"If you think that the sentence is qualified correctly, you just have to click on \"Validate\" to confirm that the sentence is ok. If this is not the case, it's up to you to correct the meaning before validating it. You are building your first model!","title":"Validate a Sentence"},{"location":"build-nlp-model/#explore-the-model","text":"","title":"Explore the Model"},{"location":"build-nlp-model/#the-search-tab","text":"The Search tab allows you to browse all the sentences of the model. The most used criterion is the full text search input (regular expressions are allowed). You can then consult the sentences that are part of your model, and also change the qualifications of these sentences over time.","title":"The Search Tab"},{"location":"build-nlp-model/#states-of-a-sentence","text":"Each sentence has a state: Inbox : The sentence has not been qualified yet and is not included in the model Validated : The sentence has been validated but is not yet included in the NLP model (this can take some time for large models) Included in model : The sentence has been validated and is included in the model","title":"States of a Sentence"},{"location":"build-nlp-model/#advanced-features","text":"By clicking on the \"Applications\"menu, you get the list of existing applications. Then click of the edit button of the application you want to configure.","title":"Advanced Features"},{"location":"build-nlp-model/#nlp-engine-selection","text":"You can select the NLP library used by this application with the \"NLP engine\" radio button:","title":"Nlp Engine Selection"},{"location":"build-nlp-model/#use-built-in-entity-models","text":"This option allows you to reuse built-in entity models (ie duckling) in your new intent. For example, if you create an intent with a duckling:datetime entity, the dates will automatically be recognized for that intent in all new sentences assigned to that intent (Internally, a merge is performed between the info given by the built-in entity models and the info of your own model). This option is enabled by default, it can be useful to disable it for very large models, for which the NER detection will perform better in almost all cases.","title":"Use Built-in Entity Models"},{"location":"build-nlp-model/#use-sub-entities","text":"If you enable this option, you will be able to qualify multiple levels of entities: The number of levels is not limited, but it is advisable not to specify more than 3 or 4.","title":"Use sub-entities"},{"location":"build-nlp-model/#use-predefined-values","text":"An entity can have predefined values : you just have to click on \"Entities\" tab, and select an entity. A small icon next to the delete icon shows the types of entities you can edit as shown in the picture below:","title":"Use predefined values"},{"location":"evaluate-the-model/","text":"Evaluate the relevance of a NLP model \u00b6 Tabs \u00b6 Five tabs are used to control the relevance of the model: Stats : Monitores model perfomance in production: self-evaluation of the model about its relevance in terms of recognition of intent and entities number of calls and errors average execution time Model Builds : the cimplete list of model builds Test Trend : evolution of the relevance of model tests Intent Errors : the list of intent errors found with model tests Entity Errors : the list of entity errors found with model tests Model Tests \u00b6 Model tests are used to detect qualifications errors. Temporarily models are built from a random part of the whole sentence set of the model (90% for example) and then tested against the remaining sentences. The process is repeated a number of times and the most frequent errors are pushed to an admin user. Model tests are useful only with large models. Intent errors \u00b6 Click on the Intent Errors tab: Since the picture above is built from a very simple model, no real error has been detected. We can nevertheless note that in some cases the model is systematically wrong with a high probability. Entity errors \u00b6 These errors can be viewed via the Entity Errors tab.","title":"Monitor NLP models"},{"location":"evaluate-the-model/#evaluate-the-relevance-of-a-nlp-model","text":"","title":"Evaluate the relevance of a NLP model"},{"location":"evaluate-the-model/#tabs","text":"Five tabs are used to control the relevance of the model: Stats : Monitores model perfomance in production: self-evaluation of the model about its relevance in terms of recognition of intent and entities number of calls and errors average execution time Model Builds : the cimplete list of model builds Test Trend : evolution of the relevance of model tests Intent Errors : the list of intent errors found with model tests Entity Errors : the list of entity errors found with model tests","title":"Tabs"},{"location":"evaluate-the-model/#model-tests","text":"Model tests are used to detect qualifications errors. Temporarily models are built from a random part of the whole sentence set of the model (90% for example) and then tested against the remaining sentences. The process is repeated a number of times and the most frequent errors are pushed to an admin user. Model tests are useful only with large models.","title":"Model Tests"},{"location":"evaluate-the-model/#intent-errors","text":"Click on the Intent Errors tab: Since the picture above is built from a very simple model, no real error has been detected. We can nevertheless note that in some cases the model is systematically wrong with a high probability.","title":"Intent errors"},{"location":"evaluate-the-model/#entity-errors","text":"These errors can be viewed via the Entity Errors tab.","title":"Entity errors"},{"location":"getting-started/","text":"TLDR; \u00b6 Deploy the Open Data Bot example with Docker. A Sample Bot \u00b6 The sample bot using Tock Integrated mode : https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit. Docker Images \u00b6 Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker . Start the NLP stack \u00b6 #get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password . Sample bot based on Open Data APIs \u00b6 A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images . Administration Interface Menu \u00b6 The Configuration menu allows you to create new models and configure them. The NLP and NLP QA menus are dedicated to building NLP models. The Build , Test and Monitoring menus are used for building bots or assistants.","title":"TLDR;"},{"location":"getting-started/#tldr","text":"Deploy the Open Data Bot example with Docker.","title":"TLDR;"},{"location":"getting-started/#a-sample-bot","text":"The sample bot using Tock Integrated mode : https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit.","title":"A Sample Bot"},{"location":"getting-started/#docker-images","text":"Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker .","title":"Docker Images"},{"location":"getting-started/#start-the-nlp-stack","text":"#get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password .","title":"Start the NLP stack"},{"location":"getting-started/#sample-bot-based-on-open-data-apis","text":"A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images .","title":"Sample bot based on Open Data APIs"},{"location":"getting-started/#administration-interface-menu","text":"The Configuration menu allows you to create new models and configure them. The NLP and NLP QA menus are dedicated to building NLP models. The Build , Test and Monitoring menus are used for building bots or assistants.","title":"Administration Interface Menu"},{"location":"kdoc/","text":"A KDoc documentation is provided .","title":"KDoc"},{"location":"test-the-bot/","text":"Use the Test Framework \u00b6 Tock provides extensions in order to help writing better unit tests. To use them, you need to add the bot-test dependency to your project. With Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> bot-test </artifactId> <version> 19.9.1 </version> <scope> test </scope> </dependency> With Gradle : testCompile 'ai.tock:bot-test:19.9.1' This framework is documented in KDoc format here . Write a Simple Test \u00b6 In the next samples, JUnit5 is used as test engine. A dedicated extension for Tock is available . @RegisterExtension @JvmField val ext = TockJUnit5Extension () To test the greetings story of the Open Data bot, just use the ext.send() method: @Test fun `greetings story displays welcome message` () { ext . send { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } } As the default connector is Messenger, it is possible to test the message specific to Messenger in the same way: @Test fun `greetings story displays welcome message with Messenger dedicated message` () { ext . send { lastAnswer . assertMessage ( buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) ) } } To test the message specific to Google Assistant (or any other connector), you need to indicate the connector to be tested: @Test fun `greetings story displays welcome message with GA dedicated message WHEN context contains GA connector` () { ext . send ( connectorType = gaConnectorType ) { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) lastAnswer . assertMessage ( gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) ) } } Test a specific Story \u00b6 In the previous examples, it was useless to specify the story to test ( greetings being the default story). Suppose you want to test the search story, then you need to indicate the story to test as follows: @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search ) { firstAnswer . assertText ( \"For which destination?\" ) } } Test a Conversation \u00b6 You can simulate a whole conversation. For example, here the user indicates the destination, then the origin: @Test fun `search story asks for origin WHEN there is a destination BUT no origin in context` () { ext . send ( \"I would like to find a train\" , search ) { firstAnswer . assertText ( \"For which destination?\" ) } ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( \"For which origin?\" ) } ext . send ( \"Paris\" , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( \"When?\" ) } } The first text parameter of the send method is merely indicative, to help understanding the tests. The others parameters defines how the NLP engine has analysed the text. For example : private val lille = PlaceValue ( SncfPlace ( \"stop_area\" , 90 , \"Lille Europe\" , \"Lille Europe (Lille)\" , \"stop_area:OCE:SA:87223263\" , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) indicate that the phrase \"Lille\" is categorized as an indicate_location intent with a value lille for the entity location . Finally it is possible to modify all the values of the mocked bus at initialization. In the following example, the use of the secondary intent indicate_location is simulated to indicate the origin: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Search\" , search ) { destination = lille origin = paris run () firstAnswer . assertText ( \"When?\" ) } } The destination and origin variables are updated, then a call to the bus is simulated with the function run() .","title":"Use the Test Framework"},{"location":"test-the-bot/#use-the-test-framework","text":"Tock provides extensions in order to help writing better unit tests. To use them, you need to add the bot-test dependency to your project. With Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> bot-test </artifactId> <version> 19.9.1 </version> <scope> test </scope> </dependency> With Gradle : testCompile 'ai.tock:bot-test:19.9.1' This framework is documented in KDoc format here .","title":"Use the Test Framework"},{"location":"test-the-bot/#write-a-simple-test","text":"In the next samples, JUnit5 is used as test engine. A dedicated extension for Tock is available . @RegisterExtension @JvmField val ext = TockJUnit5Extension () To test the greetings story of the Open Data bot, just use the ext.send() method: @Test fun `greetings story displays welcome message` () { ext . send { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } } As the default connector is Messenger, it is possible to test the message specific to Messenger in the same way: @Test fun `greetings story displays welcome message with Messenger dedicated message` () { ext . send { lastAnswer . assertMessage ( buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) ) } } To test the message specific to Google Assistant (or any other connector), you need to indicate the connector to be tested: @Test fun `greetings story displays welcome message with GA dedicated message WHEN context contains GA connector` () { ext . send ( connectorType = gaConnectorType ) { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) lastAnswer . assertMessage ( gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) ) } }","title":"Write a Simple Test"},{"location":"test-the-bot/#test-a-specific-story","text":"In the previous examples, it was useless to specify the story to test ( greetings being the default story). Suppose you want to test the search story, then you need to indicate the story to test as follows: @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search ) { firstAnswer . assertText ( \"For which destination?\" ) } }","title":"Test a specific Story"},{"location":"test-the-bot/#test-a-conversation","text":"You can simulate a whole conversation. For example, here the user indicates the destination, then the origin: @Test fun `search story asks for origin WHEN there is a destination BUT no origin in context` () { ext . send ( \"I would like to find a train\" , search ) { firstAnswer . assertText ( \"For which destination?\" ) } ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( \"For which origin?\" ) } ext . send ( \"Paris\" , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( \"When?\" ) } } The first text parameter of the send method is merely indicative, to help understanding the tests. The others parameters defines how the NLP engine has analysed the text. For example : private val lille = PlaceValue ( SncfPlace ( \"stop_area\" , 90 , \"Lille Europe\" , \"Lille Europe (Lille)\" , \"stop_area:OCE:SA:87223263\" , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) indicate that the phrase \"Lille\" is categorized as an indicate_location intent with a value lille for the entity location . Finally it is possible to modify all the values of the mocked bus at initialization. In the following example, the use of the secondary intent indicate_location is simulated to indicate the origin: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Search\" , search ) { destination = lille origin = paris run () firstAnswer . assertText ( \"When?\" ) } } The destination and origin variables are updated, then a call to the bus is simulated with the function run() .","title":"Test a Conversation"},{"location":"the-open-data-bot/","text":"The Open Data Bot example \u00b6 An integrated bot sample is available: the Open Data Bot . The Open Data Bot \u00b6 A good starting point is the source code of the Open Data Bot Follow the instructions of the README file of the project, to start the bot in the IDE (do not configure Messenger or Google Assistant at this point), then connect to the administration interface. The bot is already testable. The Test Tab \u00b6 Go to this tab, and test the bot: This is a test mode, so the interface is minimal. The real goal is to have your users interact with the bot via channels like Messenger, Google Assistant ... or your sites or applications. The Monitoring Tab \u00b6 It is then possible to consult the discussion that you just had with the bot via the Monitoring tab: In this sample, this dialog has the Messenger flag, as it was tested for this channel. The Build Tab \u00b6 Add a new answer \u00b6 With the category Add new Answer , it is possible to add directly a new answer: Then test the new intention and its answer: Modify the Answers and Internationalization \u00b6 Finally it is possible to modify each answer of the bot, by type of interface (chat / voice), by type of connector and by language with the i18n tab. The ability to add alternative answers (a response from the list will be chosen each time at random) is also provided (with the \"plus\" button).","title":"Code Samples"},{"location":"the-open-data-bot/#the-open-data-bot-example","text":"An integrated bot sample is available: the Open Data Bot .","title":"The Open Data Bot example"},{"location":"the-open-data-bot/#the-open-data-bot","text":"A good starting point is the source code of the Open Data Bot Follow the instructions of the README file of the project, to start the bot in the IDE (do not configure Messenger or Google Assistant at this point), then connect to the administration interface. The bot is already testable.","title":"The Open Data Bot"},{"location":"the-open-data-bot/#the-test-tab","text":"Go to this tab, and test the bot: This is a test mode, so the interface is minimal. The real goal is to have your users interact with the bot via channels like Messenger, Google Assistant ... or your sites or applications.","title":"The Test Tab"},{"location":"the-open-data-bot/#the-monitoring-tab","text":"It is then possible to consult the discussion that you just had with the bot via the Monitoring tab: In this sample, this dialog has the Messenger flag, as it was tested for this channel.","title":"The Monitoring Tab"},{"location":"the-open-data-bot/#the-build-tab","text":"","title":"The Build Tab"},{"location":"the-open-data-bot/#add-a-new-answer","text":"With the category Add new Answer , it is possible to add directly a new answer: Then test the new intention and its answer:","title":"Add a new answer"},{"location":"the-open-data-bot/#modify-the-answers-and-internationalization","text":"Finally it is possible to modify each answer of the bot, by type of interface (chat / voice), by type of connector and by language with the i18n tab. The ability to add alternative answers (a response from the list will be chosen each time at random) is also provided (with the \"plus\" button).","title":"Modify the Answers and Internationalization"},{"location":"toc/","text":"Tock documentation \u00b6 Overview Table of contents Try Tock : Create your first bot with Tock Studio Configure your bot for Slack Configure your bot for Messenger Program stories using the Bot API mode Deploy a standalone Tock platform with Docker Use Tock : Conversational concepts for Tock Tock Studio interfaces : General interface The Configuration menu The NLU menu The NLU QA menu The Build menu The Test menu The Monitoring menu Build your conversational model Create a multichannel bot (connectors) Create a multilingual bot (internationalization) Develop with Tock : Available modes Tock Bot API Tock Integrated Bot Unit Tests Connectors Internationalization ( i18n ) Tock APIs Code samples Run & administrate Tock : Functional and technical architecture Installation Security High Availability Monitoring Cloud About Tock : Why Tock Showcase Resources & press kit Contact us Community Contribute Jobs","title":"Tock documentation"},{"location":"toc/#tock-documentation","text":"Overview Table of contents Try Tock : Create your first bot with Tock Studio Configure your bot for Slack Configure your bot for Messenger Program stories using the Bot API mode Deploy a standalone Tock platform with Docker Use Tock : Conversational concepts for Tock Tock Studio interfaces : General interface The Configuration menu The NLU menu The NLU QA menu The Build menu The Test menu The Monitoring menu Build your conversational model Create a multichannel bot (connectors) Create a multilingual bot (internationalization) Develop with Tock : Available modes Tock Bot API Tock Integrated Bot Unit Tests Connectors Internationalization ( i18n ) Tock APIs Code samples Run & administrate Tock : Functional and technical architecture Installation Security High Availability Monitoring Cloud About Tock : Why Tock Showcase Resources & press kit Contact us Community Contribute Jobs","title":"Tock documentation"},{"location":"about/community/","text":"Community \u00b6 Tock has been designed to remain an open platform shared with the community. To know more, see why Tock . Next events / Meetup \u00b6 This lists the next planed events related to Tock, as well as groups identified to share with the community: November: We should present Tock at the following Paris NLP (season 4 meetup #2) An open Hackathon event will take place in Paris the 21-22 of November around conversational AI with Tock (+ info very soon) December: A talk about open conversational AI platforms has been submitted to the Paris Open Source Summit CFP (to be confirmed) TOSIT association \u00b6 The Tock solution is currently is the early stages to join the TOSIT (The Open Source I Trust) , an association dedicated to support Open Source and Free Software. Founded by Carrefour, EDF, Enedis, Orange, P\u00f4le Emploi and SNCF, TOSIT now gathers other important members, such as the (French) Minist\u00e8re des Arm\u00e9es, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale or MAIF for instance. To know more about TOSIT, please visit http://tosit.fr/ GitHub & Gitter \u00b6 The Tock platform and tools are available on https://github.com/theopenconversationkit/tock under the Apache 2 license . Sources License Versions Issues Contributors Gitter Demo To know more about repository structure, coding conventions, etc. refer to the contribute to Tock section. Help \u00b6 Feel free to contact us .","title":"Community"},{"location":"about/community/#community","text":"Tock has been designed to remain an open platform shared with the community. To know more, see why Tock .","title":"Community"},{"location":"about/community/#next-events-meetup","text":"This lists the next planed events related to Tock, as well as groups identified to share with the community: November: We should present Tock at the following Paris NLP (season 4 meetup #2) An open Hackathon event will take place in Paris the 21-22 of November around conversational AI with Tock (+ info very soon) December: A talk about open conversational AI platforms has been submitted to the Paris Open Source Summit CFP (to be confirmed)","title":"Next events / Meetup"},{"location":"about/community/#tosit-association","text":"The Tock solution is currently is the early stages to join the TOSIT (The Open Source I Trust) , an association dedicated to support Open Source and Free Software. Founded by Carrefour, EDF, Enedis, Orange, P\u00f4le Emploi and SNCF, TOSIT now gathers other important members, such as the (French) Minist\u00e8re des Arm\u00e9es, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale or MAIF for instance. To know more about TOSIT, please visit http://tosit.fr/","title":"TOSIT association"},{"location":"about/community/#github-gitter","text":"The Tock platform and tools are available on https://github.com/theopenconversationkit/tock under the Apache 2 license . Sources License Versions Issues Contributors Gitter Demo To know more about repository structure, coding conventions, etc. refer to the contribute to Tock section.","title":"GitHub &amp; Gitter"},{"location":"about/community/#help","text":"Feel free to contact us .","title":"Help"},{"location":"about/contact/","text":"Contact us \u00b6 Developers, users and curious people are more than welcome to share about Tock with both its creators and the community. Don't hesitate to join us on Gitter (the instant messaging service for GitHub): https://gitter.im/tockchat/Lobby GitHub issues can be used to keep track of bugs, enhancements or feature requests: https://github.com/theopenconversationkit/tock/issues","title":"Contact us"},{"location":"about/contact/#contact-us","text":"Developers, users and curious people are more than welcome to share about Tock with both its creators and the community. Don't hesitate to join us on Gitter (the instant messaging service for GitHub): https://gitter.im/tockchat/Lobby GitHub issues can be used to keep track of bugs, enhancements or feature requests: https://github.com/theopenconversationkit/tock/issues","title":"Contact us"},{"location":"about/contribute/","text":"Contribute to Tock \u00b6 The Tock project is open to contribution and any feedback is welcome! This page details the source structure and coding conventions for the platform. Main technologies \u00b6 The applicative platform is the JVM . The reference language is Kotlin , but other programming languages can be used through the provided API. Tock leverages Vert.x and MongoDB . Graphical interfaces (namely Tock Studio ) are powered by Angular in Typescript . Source structure \u00b6 Repositories \u00b6 tock : main source repository, including the framework and platform components under the Apache 2 license . tock-corenlp : optional module, leveraging a dependency to Stanford CoreNLP (instead of Apache OpenNLP ), under GPL license . tock-docker : Docker and Docker Compose images/descriptors, for platform hands-on and fast deployment of various configuations. tock-bot-samples : code samples, in particular the WebHook and WebSocket modes examples from Tock programing guides . tock-bot-open-data : a bot example, based on the SNCF Open Data API , also implementing basic internationalization ( i18n ) mecanisms with two distinct languages. The tock repository \u00b6 TODO : detail modules and repo structure Le tock-docker repository \u00b6 TODO : detail modules and repo structure, how Maven and Docker builds work, etc. Build Tock from sources \u00b6 Tock (core) \u00b6 Tock is built with Maven , including the Web modules leveraging NPM et Angular : $ mvn package Continuous integration build jobs are available on Travis . Docker images \u00b6 Tock Docker images can be rebuilt from sources, included in repository tock-docker . One can use Maven to trigger the Docker build: $ mvn docker:build Docker containers can then be instantiated from images, or Docker Compose stacks from the various descriptors at the root of the repository. Run in IDE \u00b6 To run Tock using Docker Compose outside the IDE, rather see Deploy Tock with Docker . Tock components (NLU, Studio, bot...) can run in an IDE, such as IntelliJ , Eclipse or Visual Studio Code for instance. Beside the Docker images , IntelliJ configurations are provided with Tock sources: The Tock Studio interfaces/server: BotAdmin The alternative standalone NLU interfaces/server: Admin The NLU service: NlpService The Duckling entity-recognition service: Duckling The NLU model-builder service: BuildWorker The script compilation service: KotlinCompilerServer The OpenDataBot example also has a run configuration available: OpenDataBot To start the Tock Studio interfaces, please refer to the commands described in the following pages: Full Tock Studio server commands Standalone NLU server commands Conventions \u00b6 Kotlin Code Conventions are used to develop Tock. Contact us \u00b6 To contribute to the project or to known more about the implementation, feel free to contact us . Ideas and feedback is more than welcome.","title":"Contribute"},{"location":"about/contribute/#contribute-to-tock","text":"The Tock project is open to contribution and any feedback is welcome! This page details the source structure and coding conventions for the platform.","title":"Contribute to Tock"},{"location":"about/contribute/#main-technologies","text":"The applicative platform is the JVM . The reference language is Kotlin , but other programming languages can be used through the provided API. Tock leverages Vert.x and MongoDB . Graphical interfaces (namely Tock Studio ) are powered by Angular in Typescript .","title":"Main technologies"},{"location":"about/contribute/#source-structure","text":"","title":"Source structure"},{"location":"about/contribute/#repositories","text":"tock : main source repository, including the framework and platform components under the Apache 2 license . tock-corenlp : optional module, leveraging a dependency to Stanford CoreNLP (instead of Apache OpenNLP ), under GPL license . tock-docker : Docker and Docker Compose images/descriptors, for platform hands-on and fast deployment of various configuations. tock-bot-samples : code samples, in particular the WebHook and WebSocket modes examples from Tock programing guides . tock-bot-open-data : a bot example, based on the SNCF Open Data API , also implementing basic internationalization ( i18n ) mecanisms with two distinct languages.","title":"Repositories"},{"location":"about/contribute/#the-tock-repository","text":"TODO : detail modules and repo structure","title":"The tock repository"},{"location":"about/contribute/#le-tock-docker-repository","text":"TODO : detail modules and repo structure, how Maven and Docker builds work, etc.","title":"Le tock-docker repository"},{"location":"about/contribute/#build-tock-from-sources","text":"","title":"Build Tock from sources"},{"location":"about/contribute/#tock-core","text":"Tock is built with Maven , including the Web modules leveraging NPM et Angular : $ mvn package Continuous integration build jobs are available on Travis .","title":"Tock (core)"},{"location":"about/contribute/#docker-images","text":"Tock Docker images can be rebuilt from sources, included in repository tock-docker . One can use Maven to trigger the Docker build: $ mvn docker:build Docker containers can then be instantiated from images, or Docker Compose stacks from the various descriptors at the root of the repository.","title":"Docker images"},{"location":"about/contribute/#run-in-ide","text":"To run Tock using Docker Compose outside the IDE, rather see Deploy Tock with Docker . Tock components (NLU, Studio, bot...) can run in an IDE, such as IntelliJ , Eclipse or Visual Studio Code for instance. Beside the Docker images , IntelliJ configurations are provided with Tock sources: The Tock Studio interfaces/server: BotAdmin The alternative standalone NLU interfaces/server: Admin The NLU service: NlpService The Duckling entity-recognition service: Duckling The NLU model-builder service: BuildWorker The script compilation service: KotlinCompilerServer The OpenDataBot example also has a run configuration available: OpenDataBot To start the Tock Studio interfaces, please refer to the commands described in the following pages: Full Tock Studio server commands Standalone NLU server commands","title":"Run in IDE"},{"location":"about/contribute/#conventions","text":"Kotlin Code Conventions are used to develop Tock.","title":"Conventions"},{"location":"about/contribute/#contact-us","text":"To contribute to the project or to known more about the implementation, feel free to contact us . Ideas and feedback is more than welcome.","title":"Contact us"},{"location":"about/jobs/","text":"Tock jobs \u00b6 Interested in working with Tock and contribute to the platform? This page lists companies and organizations, proposing job offers in the field of conversational AI with Tock: e-voyageurs Technologies (Tock creators) recruit various profiles to build conversational assistants with Tock. To known more, check offers on Gitter or https://jobs.oui.sncf/ . Do you leverage Tock and offer conversational jobs? Don't hesitate to tell us and expand the list.","title":"Jobs"},{"location":"about/jobs/#tock-jobs","text":"Interested in working with Tock and contribute to the platform? This page lists companies and organizations, proposing job offers in the field of conversational AI with Tock: e-voyageurs Technologies (Tock creators) recruit various profiles to build conversational assistants with Tock. To known more, check offers on Gitter or https://jobs.oui.sncf/ . Do you leverage Tock and offer conversational jobs? Don't hesitate to tell us and expand the list.","title":"Tock jobs"},{"location":"about/resources/","text":"Tock resources \u00b6 This page lists various presentations of Tock, giving an overview of the solution in addition to the main documentation and demo instance. Conferences / video (in French) \u00b6 Code a bot for Messenger and Google Assistant in 30 minutes @ Devoxx France 2018 (live coding \"tools in action\" 30 min) Meetup / Slides (in French) \u00b6 Tock - The Open Conversation Kit @ Meetup Open Transport (2019) Tock - The Open Conversation Kit @ CRiP OpenSource & Co-d\u00e9veloppement (2017) Don't hesitate to share with us more slides, documents and links about Tock. Press kit \u00b6 Tock logos are provided under the Apache 2 license . Tock logo - default colors / transparent ( download ) : Tock logo - blue / transparent ( download ) : Tock logo - black / transparent ( download ) : Tock logo - white / transparent ( download ) :","title":"Resources"},{"location":"about/resources/#tock-resources","text":"This page lists various presentations of Tock, giving an overview of the solution in addition to the main documentation and demo instance.","title":"Tock resources"},{"location":"about/resources/#conferences-video-in-french","text":"Code a bot for Messenger and Google Assistant in 30 minutes @ Devoxx France 2018 (live coding \"tools in action\" 30 min)","title":"Conferences / video (in French)"},{"location":"about/resources/#meetup-slides-in-french","text":"Tock - The Open Conversation Kit @ Meetup Open Transport (2019) Tock - The Open Conversation Kit @ CRiP OpenSource & Co-d\u00e9veloppement (2017) Don't hesitate to share with us more slides, documents and links about Tock.","title":"Meetup / Slides (in French)"},{"location":"about/resources/#press-kit","text":"Tock logos are provided under the Apache 2 license . Tock logo - default colors / transparent ( download ) : Tock logo - blue / transparent ( download ) : Tock logo - black / transparent ( download ) : Tock logo - white / transparent ( download ) :","title":"Press kit"},{"location":"about/showcase/","text":"User showcase \u00b6 Since its creation for OUI.sncf in 2016, Tock has been used by more and more teams to build conversational bots dedicated to various use cases : business to customer and business to business e-commerce, transactions, payment assistance, care, help desks FAQ and decision trees This page presents various assistants and products built and powered by Tock. OUIbot , the OUI.sncf bot \u00b6 OUIbot is the conversational assistant from OUI.sncf. Available since 2016 on Facebook Messenger, OUIbot was built along with the first versions of Tock. With OUIbot, booking a train ticket has never been easier! It assists you in the preparation of your trips, allows you to make a complete reservation quickly and easily, from research to purchase (payment included), and accompanies you during your trip. Thanks to the numerous connectors, OUIbot is now available on multiple conversational channels, such as the company Website www.oui.sncf , social networks, voice assistants, smart display and even SmartBrics with JCDecaux devices. In 2019, OUIbot answers approximately 10.000 users a day. It has been awarded Best Robot Experience for the second year in a row. Name: OUIbot Date of birth: in production since 2016 Field: e-commerce/travel, transactions (booking, payment), alerts & push notifications, push messages to an agent Channels: text & voice, on the company Website, Messenger, WhatsApp, Business Chat (Messages), Google Assistant, Google Home, Alexa, JCDecaux SmartBrics L'Assistant SNCF \u00b6 L' Assistant SNCF is the mobile application for SNCF passengers on Android and iOS, covering both trains and other modes of transport. With L' Assistant (the SNCF Assistant), you can plan your itinerary, stay informed in real time, buy your transport tickets directly or book a taxi ride. More features are yet to come. Accessible via the \"microphone\" in the mobile application, le SNCF Assistant's conversational bot is built with Tock plus the speech-to-text Android and iOS functions. Name: L' Assistant SNCF Date of birth: in production, featuring Tock voice function since 2019 Field: travel & transport (multi-modal route research, etc.) Channels: voice, on the SNCF mobile application for Android and iOS Tilien , the Transilien chatbot \u00b6 Tilien is the Transilien chatbot on Messenger. Designed as a personal and friendly travel companion, it informs you about upcoming departures, the service status, current and future works, itineraries and much more (route plans, timetables, etc.) on the entire Ile-De-France rail network: Metro, RER, Transilien, Tram. Powered by Tock, the chatbot is waiting for you on Facebook Messenger. Name: Tilien Date of birth: in production, since 2018 with Tock Field: transport & assistance (route research, route plans, traffic conditions, etc.) Channels: text, on Messenger Mon Assistant TGV INOUI \u00b6 Mon Assistant advises customers and travellers of the TGV INOUI brand before, during and after their journey. The chatbot can tell you all about the service status, train departure platforms, customer seats, onboard services (bar, electrical outlets, etc.). It also allows you to talk with a SNCF agents while remaining in the same conversation. Located on the TGV INOUI Facebook page, the assistant based on Tock is also accessible from the E-Ticket reminder SMS or directly from the application. Name: Mon Assistant TGV INOUI Date of birth: in production since 2019 Field: assistance & passenger information (dock information, current travel information, on-board services), relay to an agent Channels: text, on Messenger (Facebook TGV INOUI page) L' Agent virtuel SNCF \u00b6 L' Agent virtuel SNCF (SNCF Virtual Assistant) presents passenger information and any disruptions on all trains (TGV, Intercites, TER, Eurostar, etc.) in a conversational manner. Query the bot by train number, passenger file, next departures, etc. to get the latest information and traffic status. Accessible via the SNCF Facebook page, the Agent virtuel is based on Tock. Name: Agent virtuel SNCF Date of birth: in production since 2019 Field: travel & transport (traffic situation, works, next departures), relay to an agent Channels: text, on Messenger ( SNCF Facebook page) Eve , the e-voyageurs internal assistant \u00b6 Eve is the internal assistant of e-voyageurs SNCF employees. The chatbot answers common questions, refers to the right interlocutors and collaborative tools of the company, automates common requests to IT Support, General Services, Legal Department, etc. DevOps teams can also ask it for production status, next planned operations, or even to manage certain operations directly for greater simplicity and reactivity. Eve is always listening to the employees, both within the offices and on-the-go using Teams applications with Tock. Name: Eve Date of birth: in production since 2019 Field: internal & B2B support (FAQ, IT Support, HR, Legal), DevOps automation (monitoring, deployments, production management, etc.) Channels: text & voice, internally within the offices and on-the-go via Teams What about you? \u00b6 As a generic platform, Tock enables numerous use cases and integration of internal as well as external channels. Please feel free to contact us in case of doubts or questions about Tock features or possibilities for a new project of your own. And don't hesitate to share your achievements with the community! \ud83d\ude42","title":"Showcase"},{"location":"about/showcase/#user-showcase","text":"Since its creation for OUI.sncf in 2016, Tock has been used by more and more teams to build conversational bots dedicated to various use cases : business to customer and business to business e-commerce, transactions, payment assistance, care, help desks FAQ and decision trees This page presents various assistants and products built and powered by Tock.","title":"User showcase"},{"location":"about/showcase/#ouibot-the-ouisncf-bot","text":"OUIbot is the conversational assistant from OUI.sncf. Available since 2016 on Facebook Messenger, OUIbot was built along with the first versions of Tock. With OUIbot, booking a train ticket has never been easier! It assists you in the preparation of your trips, allows you to make a complete reservation quickly and easily, from research to purchase (payment included), and accompanies you during your trip. Thanks to the numerous connectors, OUIbot is now available on multiple conversational channels, such as the company Website www.oui.sncf , social networks, voice assistants, smart display and even SmartBrics with JCDecaux devices. In 2019, OUIbot answers approximately 10.000 users a day. It has been awarded Best Robot Experience for the second year in a row. Name: OUIbot Date of birth: in production since 2016 Field: e-commerce/travel, transactions (booking, payment), alerts & push notifications, push messages to an agent Channels: text & voice, on the company Website, Messenger, WhatsApp, Business Chat (Messages), Google Assistant, Google Home, Alexa, JCDecaux SmartBrics","title":"OUIbot, the OUI.sncf bot"},{"location":"about/showcase/#lassistant-sncf","text":"L' Assistant SNCF is the mobile application for SNCF passengers on Android and iOS, covering both trains and other modes of transport. With L' Assistant (the SNCF Assistant), you can plan your itinerary, stay informed in real time, buy your transport tickets directly or book a taxi ride. More features are yet to come. Accessible via the \"microphone\" in the mobile application, le SNCF Assistant's conversational bot is built with Tock plus the speech-to-text Android and iOS functions. Name: L' Assistant SNCF Date of birth: in production, featuring Tock voice function since 2019 Field: travel & transport (multi-modal route research, etc.) Channels: voice, on the SNCF mobile application for Android and iOS","title":"L'Assistant SNCF"},{"location":"about/showcase/#tilien-the-transilien-chatbot","text":"Tilien is the Transilien chatbot on Messenger. Designed as a personal and friendly travel companion, it informs you about upcoming departures, the service status, current and future works, itineraries and much more (route plans, timetables, etc.) on the entire Ile-De-France rail network: Metro, RER, Transilien, Tram. Powered by Tock, the chatbot is waiting for you on Facebook Messenger. Name: Tilien Date of birth: in production, since 2018 with Tock Field: transport & assistance (route research, route plans, traffic conditions, etc.) Channels: text, on Messenger","title":"Tilien, the Transilien chatbot"},{"location":"about/showcase/#mon-assistant-tgv-inoui","text":"Mon Assistant advises customers and travellers of the TGV INOUI brand before, during and after their journey. The chatbot can tell you all about the service status, train departure platforms, customer seats, onboard services (bar, electrical outlets, etc.). It also allows you to talk with a SNCF agents while remaining in the same conversation. Located on the TGV INOUI Facebook page, the assistant based on Tock is also accessible from the E-Ticket reminder SMS or directly from the application. Name: Mon Assistant TGV INOUI Date of birth: in production since 2019 Field: assistance & passenger information (dock information, current travel information, on-board services), relay to an agent Channels: text, on Messenger (Facebook TGV INOUI page)","title":"Mon Assistant TGV INOUI"},{"location":"about/showcase/#l-agent-virtuel-sncf","text":"L' Agent virtuel SNCF (SNCF Virtual Assistant) presents passenger information and any disruptions on all trains (TGV, Intercites, TER, Eurostar, etc.) in a conversational manner. Query the bot by train number, passenger file, next departures, etc. to get the latest information and traffic status. Accessible via the SNCF Facebook page, the Agent virtuel is based on Tock. Name: Agent virtuel SNCF Date of birth: in production since 2019 Field: travel & transport (traffic situation, works, next departures), relay to an agent Channels: text, on Messenger ( SNCF Facebook page)","title":"L' Agent virtuel SNCF"},{"location":"about/showcase/#eve-the-e-voyageurs-internal-assistant","text":"Eve is the internal assistant of e-voyageurs SNCF employees. The chatbot answers common questions, refers to the right interlocutors and collaborative tools of the company, automates common requests to IT Support, General Services, Legal Department, etc. DevOps teams can also ask it for production status, next planned operations, or even to manage certain operations directly for greater simplicity and reactivity. Eve is always listening to the employees, both within the offices and on-the-go using Teams applications with Tock. Name: Eve Date of birth: in production since 2019 Field: internal & B2B support (FAQ, IT Support, HR, Legal), DevOps automation (monitoring, deployments, production management, etc.) Channels: text & voice, internally within the offices and on-the-go via Teams","title":"Eve, the e-voyageurs internal assistant"},{"location":"about/showcase/#what-about-you","text":"As a generic platform, Tock enables numerous use cases and integration of internal as well as external channels. Please feel free to contact us in case of doubts or questions about Tock features or possibilities for a new project of your own. And don't hesitate to share your achievements with the community! \ud83d\ude42","title":"What about you?"},{"location":"about/why/","text":"Why Tock? \u00b6 Created in 2016 by the OUI.sncf Innovation team to implement voice-command on its mobile applications , the framework has then been used to create the Messenger chatbot , before being extended to support numerous channels and other bots with more use cases. At first the platform showed results, similar to other available solutions on the market, while keeping the code in control (relying on opensource libraries and academic solutions) and preventing \"black box\" effects (eg. debugging conversational models) for more reactive agility. Since then, the team behind OUIbot as well as other teams, dedicated to various conversational assistants at SNCF (see the showcase ) use Tock every day in production and add new features and connectors to the platform on a regular basis. We are convinced there is a need for open AI and conversational platforms , enabling various technical and business cases while keeping the code in control and the ownership of models and data . More and more partners and third-parties, small and big companies in France and worldwide, share this vision and requirement for their own projects. The complete Tock solution is shared with the community in order to federate and mutualize efforts from assistant builders.","title":"Why Tock"},{"location":"about/why/#why-tock","text":"Created in 2016 by the OUI.sncf Innovation team to implement voice-command on its mobile applications , the framework has then been used to create the Messenger chatbot , before being extended to support numerous channels and other bots with more use cases. At first the platform showed results, similar to other available solutions on the market, while keeping the code in control (relying on opensource libraries and academic solutions) and preventing \"black box\" effects (eg. debugging conversational models) for more reactive agility. Since then, the team behind OUIbot as well as other teams, dedicated to various conversational assistants at SNCF (see the showcase ) use Tock every day in production and add new features and connectors to the platform on a regular basis. We are convinced there is a need for open AI and conversational platforms , enabling various technical and business cases while keeping the code in control and the ownership of models and data . More and more partners and third-parties, small and big companies in France and worldwide, share this vision and requirement for their own projects. The complete Tock solution is shared with the community in order to federate and mutualize efforts from assistant builders.","title":"Why Tock?"},{"location":"dev/bot-api/","text":"Tock Bot API Mode \u00b6 This is the recommended way to start to develop with Tock. You add custom answers using a REST API. Kotlin client and Node client are available. Connect to the demo platform \u00b6 Rather than deploying its own Tock platform, it is possible to test the WebSocket or Webhook modes directly on the Tock demo platform . Develop with Kotlin \u00b6 Enable WebSocket mode \u00b6 This is the preferred mode at startup. To use the websocket client, add the tock-bot-api-websocket dependency to your Kotlin application / project. Using Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-websocket </artifactId> <version> 19.9.1 </version> </dependency> Or Gradle : compile 'ai.tock:tock-bot-api-websocket:19.9.1' Enable WebHook mode \u00b6 Alternatively, you can choose to use the WebHook client. Add the tock-bot-api-webhook dependency to your Kotlin application / project. Using Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-webhook </artifactId> <version> 19.9.1 </version> </dependency> Or Gradle : compile 'ai.tock:tock-bot-api-webhook:19.9.1' In this case, unlike the WebSocket mode, the bot application must be reachable by the Tock platform and so has to expose a public URL (you can use ngrok in order to provide this URL). This URL must be specified in the webhook url field in the Configuration > Bot Configurations view of Tock Studio . Set up the API key \u00b6 In Tock Studio , after configuring a bot, go to Configuration > Bot Configurations and copy the API key of the bot to which you want to connect. You can enter / paste this key into the Kotlin code (see below). Create Stories \u00b6 The following formats are supported: Text with Buttons (Quick Replies) \"Card\" format \"Carousel\" format Specific channel formats like Messenger format, Slack format, etc. Here is a simple bot with a few stories: fun main () { startWithDemo ( newBot ( \"PUT-YOUR-TOCK-APP-API-KEY-HERE\" , // Get your app API key from Bot Configurations in Tock Studio newStory ( \"greetings\" ) { // Intent 'greetings' end ( \"Hello!\" ) // Raw text answer }, newStory ( \"location\" ) { // Intent 'location' end ( // Anwser with a card - including text, file(image, video,..) and user action suggestions newCard ( \"Card title\" , \"Card sub title\" , newAttachment ( \"https://url-image.png\" ), newAction ( \"Action 1\" ), newAction ( \"Action 2\" , \"http://redirection\" ) ) ) }, newStory ( \"goodbye\" ) { // Intent 'goodbye' end { // Answer with Messenger-specific button/quick reply buttonsTemplate ( \"Are you sure ?\" , nlpQuickReply ( \"Stay here\" )) } }, // Fallback answer when the bot does find a correct response unknownStory { end ( \"Sorry I don't understand :(\" ) } ) ) } Please consult the full source code sample . Develop in another language \u00b6 Node \u00b6 Please consult the dedicated node client documentation. API \u00b6 It is possible to develop in the language of your choice by using directly the underlying REST API. Install Bot API on your own servers \u00b6 To use Tock's Bot API mode without the demo platform, a specific module must be deployed on your own server. Called bot-api in Docker Compose descriptors, this service: Expose the Bot API to the potential customers whatever their programming language are. Accept WebSocket connections and / or connections to the configured webhook. Compared to the \"demo mode\", The only required change in the code is to replace the startWithDemo method with the start one, specifying the bot-api target server address.","title":"Bot API mode"},{"location":"dev/bot-api/#tock-bot-api-mode","text":"This is the recommended way to start to develop with Tock. You add custom answers using a REST API. Kotlin client and Node client are available.","title":"Tock Bot API Mode"},{"location":"dev/bot-api/#connect-to-the-demo-platform","text":"Rather than deploying its own Tock platform, it is possible to test the WebSocket or Webhook modes directly on the Tock demo platform .","title":"Connect to the demo platform"},{"location":"dev/bot-api/#develop-with-kotlin","text":"","title":"Develop with Kotlin"},{"location":"dev/bot-api/#enable-websocket-mode","text":"This is the preferred mode at startup. To use the websocket client, add the tock-bot-api-websocket dependency to your Kotlin application / project. Using Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-websocket </artifactId> <version> 19.9.1 </version> </dependency> Or Gradle : compile 'ai.tock:tock-bot-api-websocket:19.9.1'","title":"Enable WebSocket mode"},{"location":"dev/bot-api/#enable-webhook-mode","text":"Alternatively, you can choose to use the WebHook client. Add the tock-bot-api-webhook dependency to your Kotlin application / project. Using Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-webhook </artifactId> <version> 19.9.1 </version> </dependency> Or Gradle : compile 'ai.tock:tock-bot-api-webhook:19.9.1' In this case, unlike the WebSocket mode, the bot application must be reachable by the Tock platform and so has to expose a public URL (you can use ngrok in order to provide this URL). This URL must be specified in the webhook url field in the Configuration > Bot Configurations view of Tock Studio .","title":"Enable WebHook mode"},{"location":"dev/bot-api/#set-up-the-api-key","text":"In Tock Studio , after configuring a bot, go to Configuration > Bot Configurations and copy the API key of the bot to which you want to connect. You can enter / paste this key into the Kotlin code (see below).","title":"Set up the API key"},{"location":"dev/bot-api/#create-stories","text":"The following formats are supported: Text with Buttons (Quick Replies) \"Card\" format \"Carousel\" format Specific channel formats like Messenger format, Slack format, etc. Here is a simple bot with a few stories: fun main () { startWithDemo ( newBot ( \"PUT-YOUR-TOCK-APP-API-KEY-HERE\" , // Get your app API key from Bot Configurations in Tock Studio newStory ( \"greetings\" ) { // Intent 'greetings' end ( \"Hello!\" ) // Raw text answer }, newStory ( \"location\" ) { // Intent 'location' end ( // Anwser with a card - including text, file(image, video,..) and user action suggestions newCard ( \"Card title\" , \"Card sub title\" , newAttachment ( \"https://url-image.png\" ), newAction ( \"Action 1\" ), newAction ( \"Action 2\" , \"http://redirection\" ) ) ) }, newStory ( \"goodbye\" ) { // Intent 'goodbye' end { // Answer with Messenger-specific button/quick reply buttonsTemplate ( \"Are you sure ?\" , nlpQuickReply ( \"Stay here\" )) } }, // Fallback answer when the bot does find a correct response unknownStory { end ( \"Sorry I don't understand :(\" ) } ) ) } Please consult the full source code sample .","title":"Create Stories"},{"location":"dev/bot-api/#develop-in-another-language","text":"","title":"Develop in another language"},{"location":"dev/bot-api/#node","text":"Please consult the dedicated node client documentation.","title":"Node"},{"location":"dev/bot-api/#api","text":"It is possible to develop in the language of your choice by using directly the underlying REST API.","title":"API"},{"location":"dev/bot-api/#install-bot-api-on-your-own-servers","text":"To use Tock's Bot API mode without the demo platform, a specific module must be deployed on your own server. Called bot-api in Docker Compose descriptors, this service: Expose the Bot API to the potential customers whatever their programming language are. Accept WebSocket connections and / or connections to the configured webhook. Compared to the \"demo mode\", The only required change in the code is to replace the startWithDemo method with the start one, specifying the bot-api target server address.","title":"Install Bot API on your own servers"},{"location":"dev/connectors/","text":"Tock default Connectors \u00b6 Messenger \u00b6 Please consult the dedicated connector-messenger page. Slack \u00b6 Please consult the dedicated connector-slack GitHub page. Google Assistant / Google Home \u00b6 Please consult the dedicated connector-ga GitHub page. Alexa / Echo \u00b6 Please consult the dedicated connector-alexa GitHub page. Rocket.Chat \u00b6 Please consult the dedicated connector-rocketchat GitHub page. WhatsApp \u00b6 Please consult the dedicated connector-whatsapp GitHub page. Teams \u00b6 Please consult the dedicated connector-teams GitHub page. Business Chat / iMessages \u00b6 Please consult the dedicated connector-businesschat GitHub page. Twitter \u00b6 Please consult the dedicated connector-twitter GitHub page. Web \u00b6 This connector deploys a REST API, allowing to create a chatbot on a Web or Mobile interface. Please consult the dedicated connector-web GitHub page. Define your own connector \u00b6 It is possible to develop its own connector. An example of custom connector can be seen in the Bot Open Data sample project . To develop your own, follow these steps: 1) Implement the interface Connector Here is an example of implementation: val testConnectorType = ConnectorType ( \"test\" ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router -> //main API router . post ( \"$path/message\" ). blockingHandler { context -> //ConnectorRequest is my business object passed by the front app val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //business object mapped to Tock event val event = readUserMessage ( message ) //we pass the Tock event to the framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //we record the action callback . actions . add ( event ) //if it's the last action to send, send the answer if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { \"unsupported event: $event\" } } } } // to retrieve all actions before sending class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList < Action > = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //we transform the list of Tock responses into a business response val response = mapper . writeValueAsString ( actions . map {...}) //then we send the answer context . response (). end ( response ) } } 2) Implement the interface ConnectorProvider Here is an example of implementation: object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Make this connector available via a Service Loader By placing a file META-INF/services/ai.tock.bot.connector.ConnectorProvider in the classpath, containing the class name : mypackage . TestConnectorProviderService 4) Add all classes and files created in the admin classpath and bot classpath The new connector must then be available in the \"Bot Configurations\" administration interface.","title":"Connectors"},{"location":"dev/connectors/#tock-default-connectors","text":"","title":"Tock default Connectors"},{"location":"dev/connectors/#messenger","text":"Please consult the dedicated connector-messenger page.","title":"Messenger"},{"location":"dev/connectors/#slack","text":"Please consult the dedicated connector-slack GitHub page.","title":"Slack"},{"location":"dev/connectors/#google-assistant-google-home","text":"Please consult the dedicated connector-ga GitHub page.","title":"Google Assistant / Google Home"},{"location":"dev/connectors/#alexa-echo","text":"Please consult the dedicated connector-alexa GitHub page.","title":"Alexa / Echo"},{"location":"dev/connectors/#rocketchat","text":"Please consult the dedicated connector-rocketchat GitHub page.","title":"Rocket.Chat"},{"location":"dev/connectors/#whatsapp","text":"Please consult the dedicated connector-whatsapp GitHub page.","title":"WhatsApp"},{"location":"dev/connectors/#teams","text":"Please consult the dedicated connector-teams GitHub page.","title":"Teams"},{"location":"dev/connectors/#business-chat-imessages","text":"Please consult the dedicated connector-businesschat GitHub page.","title":"Business Chat / iMessages"},{"location":"dev/connectors/#twitter","text":"Please consult the dedicated connector-twitter GitHub page.","title":"Twitter"},{"location":"dev/connectors/#web","text":"This connector deploys a REST API, allowing to create a chatbot on a Web or Mobile interface. Please consult the dedicated connector-web GitHub page.","title":"Web"},{"location":"dev/connectors/#define-your-own-connector","text":"It is possible to develop its own connector. An example of custom connector can be seen in the Bot Open Data sample project . To develop your own, follow these steps: 1) Implement the interface Connector Here is an example of implementation: val testConnectorType = ConnectorType ( \"test\" ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router -> //main API router . post ( \"$path/message\" ). blockingHandler { context -> //ConnectorRequest is my business object passed by the front app val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //business object mapped to Tock event val event = readUserMessage ( message ) //we pass the Tock event to the framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //we record the action callback . actions . add ( event ) //if it's the last action to send, send the answer if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { \"unsupported event: $event\" } } } } // to retrieve all actions before sending class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList < Action > = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //we transform the list of Tock responses into a business response val response = mapper . writeValueAsString ( actions . map {...}) //then we send the answer context . response (). end ( response ) } } 2) Implement the interface ConnectorProvider Here is an example of implementation: object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Make this connector available via a Service Loader By placing a file META-INF/services/ai.tock.bot.connector.ConnectorProvider in the classpath, containing the class name : mypackage . TestConnectorProviderService 4) Add all classes and files created in the admin classpath and bot classpath The new connector must then be available in the \"Bot Configurations\" administration interface.","title":"Define your own connector"},{"location":"dev/integrated-bot/","text":"Integrated Bot Mode \u00b6 To develop a bot or an assistant with Tock, you can also use the so called Integrated mode developed in Kotlin . You get then direct access to the MongoDb database. This mode is not available in the demo platform - you need to install the Tock docker images on your own servers. Sample Project \u00b6 A sample bot using Tock Integrated mode is provided: https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit. Docker Images \u00b6 Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker . Start the NLP stack \u00b6 #get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password . Sample bot based on Open Data APIs \u00b6 A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images . Develop a new Bot \u00b6 Add the bot-toolkit Dependency \u00b6 The bot-toolkit dependency is required: With Maven: <dependency> <groupId> ai.tock </groupId> <artifactId> bot-toolkit </artifactId> <version> 19.9.1 </version> </dependency> With Gradle: compile 'ai.tock:bot-toolkit:19.9.1' A Bot is a Set of Stories \u00b6 This is how the open data bot is defined: val openBot = bot ( \"bot_open_data\" , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) This bot has an unique identifier (required - \"bot_open_data\") and a list of \"Story\" . A Story is a functional subset that has a main intention and, optionally, one or more so-called \"secondary\" intentions. Here the bot defines 4 Stories , greetings, departures, arrivals and search. Greetings is also set ( hello = greetings ) as the default story used for a new dialog. A Simple Story \u00b6 How do you define a story? Here is a first simplified version of the story greetings : val greetings = story ( \"greetings\" ) { send ( \"Welcome to the Tock Open Data Bot! :)\" ) end ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } Note that in the body of the function, this has a BotBus type. From which you can interact with the user, and which also allows you to access to all available contextual elements. When the intention greetings will be detected by the NLP model, the function above will be called by the Tock framework. The bot sends successively a first response sentence ( bus.send() ), then a second one indicating that it is the last sentence of his answer using a bus.end() . Here is the full version of greetings : val greetings = story ( \"greetings\" ) { //cleanup state resetDialogState () send ( \"Welcome to the Tock Open Data Bot! :)\" ) send ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) withMessenger { buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) } withGoogleAssistant { gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) } end () } Two notions have been added: resetDialogState() which cleanup the state (forgetting any previous context). the withMessenger{} and withGoogleAssistant{} methods that define specific responses for each connector - Here it's a text with buttons for Messenger, and a text with suggestions for Google Assistant. Start and Connect the Bot \u00b6 To start the bot, simply add the following call to your main function: registerAndInstallBot ( openBot ) where the openBot variable is the bot you originally defined. When the bot is started, you also need to specify which connectors are used in the web administration interface: Configuration -> Bot Configurations -> Create a new configuration See Connectors page for the list of available connectors. Advanced options \u00b6 Of course, the StoryHandler of greetings does not depend on the context: the answer is always the same. Secondary Intentions \u00b6 Here is the beginning of the definition of the search story : val search = storyDef < SearchDef >( \"search\" , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } The story search defines a secondary starter intent ( indicate_origin ) and a simple secondary intent ( indicate_location ). A secondary starter intent is similar in every respect to the main intent: as soon as the intent is detected, if the current story does not contain indicate_origin as secondary intent, the story search is called. For a classic secondary intent, on the other hand, the story will be executed only if the current story of the context is already the search story. Different stories can therefore share the same secondary intents. Handle Entities \u00b6 To retrieve entity values, it is good practice to define Kotlin extensions . For example here is the code used to retrieve the destination entity: val destinationEntity = openBot . entity ( \"location\" , \"destination\" ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) An entity of type \"location\" and role \"destination\" is created. There is a corresponding entity in the NLP model. A variable destination is defined, which will simplify the handling of this entity in the conversational code. This variable contains the current value of the destination in the user context. Here's a full version of the search story that uses destination : val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } If there is no value in the current context for the destination, the bot asks to specify the destination and stays there. Same behaviour for the origin or date of departure. If the 3 required values are specified, then the real answer developed in the SearchDef class is used. Here is the full version of this first part of the code: val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) && location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } In the case where the detected intention is indicate_location , we do not know if the locality represents the origin or the destination. A simple rule is then used: If there is already in the context an origin and no destination, the new locality is actually the destination. Otherwise, it is the origin. HandlerDef \u00b6 In the search story above, you may have noted the generic SearchDef typing. Here is the code of this class: @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef < SearchConnector >( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( \"From {0} to {1}\" , o , d ) send ( \"Departure on {0}\" , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( \"Sorry, no routes found :(\" ) } else { send ( \"Here is the first proposal:\" ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef extends HandlerDef which is an alias of a Tock framework class. It is usually here that the code of complex stories is defined. The code contains an additional abstraction: SearchConnector . SearchConnector is the class that defines the behavior specific to each connector, and the annotations @GAHandler (GASearchConnector::class) and @MessengerHandler (MessengerSearchConnector::class) indicate the corresponding implementations for the different supported connectors (respectively Google Assistant and Messenger). What would happen there is no connector for Google Assistant for example, and if a call from Google Assistant is answered? The connector?.sendFirstJourney(journeys.first()) method call would not send the final response, since connector would be null . ConnectorDef \u00b6 Here is a simplified version of SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef < SearchDef >( context ) { fun Section . title (): CharSequence = i18n ( \"{0} - {1}\" , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List < Section >): ConnectorMessage } And its Messenger implementation: class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List < Section >): ConnectorMessage = flexibleListTemplate ( sections . map { section -> with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } The code specific to each connector is thus decoupled correctly. The code common to each connector is present in SearchConnector and the behavior specific to each connector is specified in the dedicated classes. StoryStep \u00b6 Sometimes you need to remember the stage at which the user is in the current story. For this, Tock provides the concept of StoryStep . There are two types of StoryStep. SimpleStoryStep \u00b6 enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps < MyStep >( \"intent\" ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } To modify the current step, two methods are available: Manually change the step val story = storyWithSteps < MyStep >( \"intent\" ) { //(...) step = MyStep . a // the step will be persisted as long as we stay in this story } Use buttons or quick replies More details on this topic here . StorySteps with complex behavior \u00b6 In more complex cases, we want to be able to define a behavior for each step. enum class MySteps : StoryStep < MyHandlerDef > { //no specific behaviour display , select { // \"select\" step will be automatically selected if the select sub-intention is detected override val intent : IntentAware ? = SecondaryIntent . select override fun answer (): MyHandlerDef .() -> Any ? = { end ( \"I don't know yet how to select something\" ) } }, disruption { override fun answer (): ScoreboardDef .() -> Any ? = { end ( \"some perturbation\" ) } }; } More configuration options are available. Check out the description of StoryStep . Postback buttons & quick replies \u00b6 Messenger provides this type of button, as most connectors with GUI. With Tock, you can easily define the action performed after clicking on these buttons. In the following example, the button will redirect to the \"search\" intent: buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , search ) ) It is also possible to define a * StoryStep * and dedicated parameters: //to define parameters, just extend the ParameterKey interface enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , intent = search , //if no step is specified, the current step is used step = MyStep . a , parameters = //this parameter is stored as a string (hooks are used) nextResultDate [ nextDate ] + //this parameter is stored in json (parentheses are used) nextResultOrigin ( origin ) ) ) To retrieve the parameters of the button that was clicked: val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin )","title":"Integrated Bot mode"},{"location":"dev/integrated-bot/#integrated-bot-mode","text":"To develop a bot or an assistant with Tock, you can also use the so called Integrated mode developed in Kotlin . You get then direct access to the MongoDb database. This mode is not available in the demo platform - you need to install the Tock docker images on your own servers.","title":"Integrated Bot Mode"},{"location":"dev/integrated-bot/#sample-project","text":"A sample bot using Tock Integrated mode is provided: https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit.","title":"Sample Project"},{"location":"dev/integrated-bot/#docker-images","text":"Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker .","title":"Docker Images"},{"location":"dev/integrated-bot/#start-the-nlp-stack","text":"#get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password .","title":"Start the NLP stack"},{"location":"dev/integrated-bot/#sample-bot-based-on-open-data-apis","text":"A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images .","title":"Sample bot based on Open Data APIs"},{"location":"dev/integrated-bot/#develop-a-new-bot","text":"","title":"Develop a new Bot"},{"location":"dev/integrated-bot/#add-the-bot-toolkit-dependency","text":"The bot-toolkit dependency is required: With Maven: <dependency> <groupId> ai.tock </groupId> <artifactId> bot-toolkit </artifactId> <version> 19.9.1 </version> </dependency> With Gradle: compile 'ai.tock:bot-toolkit:19.9.1'","title":"Add the bot-toolkit Dependency"},{"location":"dev/integrated-bot/#a-bot-is-a-set-of-stories","text":"This is how the open data bot is defined: val openBot = bot ( \"bot_open_data\" , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) This bot has an unique identifier (required - \"bot_open_data\") and a list of \"Story\" . A Story is a functional subset that has a main intention and, optionally, one or more so-called \"secondary\" intentions. Here the bot defines 4 Stories , greetings, departures, arrivals and search. Greetings is also set ( hello = greetings ) as the default story used for a new dialog.","title":"A Bot is a Set of Stories"},{"location":"dev/integrated-bot/#a-simple-story","text":"How do you define a story? Here is a first simplified version of the story greetings : val greetings = story ( \"greetings\" ) { send ( \"Welcome to the Tock Open Data Bot! :)\" ) end ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } Note that in the body of the function, this has a BotBus type. From which you can interact with the user, and which also allows you to access to all available contextual elements. When the intention greetings will be detected by the NLP model, the function above will be called by the Tock framework. The bot sends successively a first response sentence ( bus.send() ), then a second one indicating that it is the last sentence of his answer using a bus.end() . Here is the full version of greetings : val greetings = story ( \"greetings\" ) { //cleanup state resetDialogState () send ( \"Welcome to the Tock Open Data Bot! :)\" ) send ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) withMessenger { buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) } withGoogleAssistant { gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) } end () } Two notions have been added: resetDialogState() which cleanup the state (forgetting any previous context). the withMessenger{} and withGoogleAssistant{} methods that define specific responses for each connector - Here it's a text with buttons for Messenger, and a text with suggestions for Google Assistant.","title":"A Simple Story"},{"location":"dev/integrated-bot/#start-and-connect-the-bot","text":"To start the bot, simply add the following call to your main function: registerAndInstallBot ( openBot ) where the openBot variable is the bot you originally defined. When the bot is started, you also need to specify which connectors are used in the web administration interface: Configuration -> Bot Configurations -> Create a new configuration See Connectors page for the list of available connectors.","title":"Start and Connect the Bot"},{"location":"dev/integrated-bot/#advanced-options","text":"Of course, the StoryHandler of greetings does not depend on the context: the answer is always the same.","title":"Advanced options"},{"location":"dev/integrated-bot/#secondary-intentions","text":"Here is the beginning of the definition of the search story : val search = storyDef < SearchDef >( \"search\" , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } The story search defines a secondary starter intent ( indicate_origin ) and a simple secondary intent ( indicate_location ). A secondary starter intent is similar in every respect to the main intent: as soon as the intent is detected, if the current story does not contain indicate_origin as secondary intent, the story search is called. For a classic secondary intent, on the other hand, the story will be executed only if the current story of the context is already the search story. Different stories can therefore share the same secondary intents.","title":"Secondary Intentions"},{"location":"dev/integrated-bot/#handle-entities","text":"To retrieve entity values, it is good practice to define Kotlin extensions . For example here is the code used to retrieve the destination entity: val destinationEntity = openBot . entity ( \"location\" , \"destination\" ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) An entity of type \"location\" and role \"destination\" is created. There is a corresponding entity in the NLP model. A variable destination is defined, which will simplify the handling of this entity in the conversational code. This variable contains the current value of the destination in the user context. Here's a full version of the search story that uses destination : val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } If there is no value in the current context for the destination, the bot asks to specify the destination and stays there. Same behaviour for the origin or date of departure. If the 3 required values are specified, then the real answer developed in the SearchDef class is used. Here is the full version of this first part of the code: val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) && location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } In the case where the detected intention is indicate_location , we do not know if the locality represents the origin or the destination. A simple rule is then used: If there is already in the context an origin and no destination, the new locality is actually the destination. Otherwise, it is the origin.","title":"Handle Entities"},{"location":"dev/integrated-bot/#handlerdef","text":"In the search story above, you may have noted the generic SearchDef typing. Here is the code of this class: @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef < SearchConnector >( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( \"From {0} to {1}\" , o , d ) send ( \"Departure on {0}\" , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( \"Sorry, no routes found :(\" ) } else { send ( \"Here is the first proposal:\" ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef extends HandlerDef which is an alias of a Tock framework class. It is usually here that the code of complex stories is defined. The code contains an additional abstraction: SearchConnector . SearchConnector is the class that defines the behavior specific to each connector, and the annotations @GAHandler (GASearchConnector::class) and @MessengerHandler (MessengerSearchConnector::class) indicate the corresponding implementations for the different supported connectors (respectively Google Assistant and Messenger). What would happen there is no connector for Google Assistant for example, and if a call from Google Assistant is answered? The connector?.sendFirstJourney(journeys.first()) method call would not send the final response, since connector would be null .","title":"HandlerDef"},{"location":"dev/integrated-bot/#connectordef","text":"Here is a simplified version of SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef < SearchDef >( context ) { fun Section . title (): CharSequence = i18n ( \"{0} - {1}\" , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List < Section >): ConnectorMessage } And its Messenger implementation: class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List < Section >): ConnectorMessage = flexibleListTemplate ( sections . map { section -> with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } The code specific to each connector is thus decoupled correctly. The code common to each connector is present in SearchConnector and the behavior specific to each connector is specified in the dedicated classes.","title":"ConnectorDef"},{"location":"dev/integrated-bot/#storystep","text":"Sometimes you need to remember the stage at which the user is in the current story. For this, Tock provides the concept of StoryStep . There are two types of StoryStep.","title":"StoryStep"},{"location":"dev/integrated-bot/#simplestorystep","text":"enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps < MyStep >( \"intent\" ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } To modify the current step, two methods are available: Manually change the step val story = storyWithSteps < MyStep >( \"intent\" ) { //(...) step = MyStep . a // the step will be persisted as long as we stay in this story } Use buttons or quick replies More details on this topic here .","title":"SimpleStoryStep"},{"location":"dev/integrated-bot/#storysteps-with-complex-behavior","text":"In more complex cases, we want to be able to define a behavior for each step. enum class MySteps : StoryStep < MyHandlerDef > { //no specific behaviour display , select { // \"select\" step will be automatically selected if the select sub-intention is detected override val intent : IntentAware ? = SecondaryIntent . select override fun answer (): MyHandlerDef .() -> Any ? = { end ( \"I don't know yet how to select something\" ) } }, disruption { override fun answer (): ScoreboardDef .() -> Any ? = { end ( \"some perturbation\" ) } }; } More configuration options are available. Check out the description of StoryStep .","title":"StorySteps with complex behavior"},{"location":"dev/integrated-bot/#postback-buttons-quick-replies","text":"Messenger provides this type of button, as most connectors with GUI. With Tock, you can easily define the action performed after clicking on these buttons. In the following example, the button will redirect to the \"search\" intent: buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , search ) ) It is also possible to define a * StoryStep * and dedicated parameters: //to define parameters, just extend the ParameterKey interface enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , intent = search , //if no step is specified, the current step is used step = MyStep . a , parameters = //this parameter is stored as a string (hooks are used) nextResultDate [ nextDate ] + //this parameter is stored in json (parentheses are used) nextResultOrigin ( origin ) ) ) To retrieve the parameters of the button that was clicked: val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin )","title":"Postback buttons &amp; quick replies"},{"location":"guide/studio/","text":"Create your first bot with Tock Studio \u00b6 The best way to try Tock is probably to create a first conversational bot using Tock Studio (the graphical user interface provided with the platform). By connecting to the Tock demonstration platform , it is possible to both design and test a conversational assistant in a few minutes, without having to write code. What you will build \u00b6 An application and a connector on the Tock demo platform A story : user sentence / bot answer, testable through the Tock Studio interface An assistant who answers, when you say \"hello\"! \ud83d\ude42 What you need \u00b6 About 5 to 15 minutes (reading the additional notes) A GitHub account, to connect to the demo platform Connect to the demo platform \u00b6 Open https://demo.tock.ai/ to access the Tock demonstration platform. Important : this platform is not supposed to host bots in production. This is merely a sandbox instance, in order to try the Tock solution without installing it. A login dialog invites you to connect with GitHub. Only your account ID will be read from GitHub. Create a Tock application \u00b6 When accessing the demo platform for the first time, a wizard helps to create the first application : Enter a name for the application Select a language - other languages can be added later Validate to create the application The just-created application is now visible from the menu: Configuration > NLU Applications . Once the first application has been created, you can create others using Create New Application . Add a connector \u00b6 To interact with the bot (through a communication channel), a connector must be used. Numerous connectors are provided with Tock: Messenger , WhatsApp , Google Assistant and Google Home , Twitter , Alexa , Business Chat , Teams , Slack , Rocket.Chat ... It is even possible to implement your own connectors to integrate with more channels. In this tutorial, you will configure a connector for Slack - the collaborative and instant messaging platform. It will be possible to try the bot using the Tock Studio interface - no need to use Slack or get an account. Create the first connector for your application: Go to Configuration > Bot Configurations Create a new Configuration Select the connector type Slack Enter anything e.g. token in Token fields (for the moment) Create Note that an API Key is automatically generated for the application, once the first connector is created. This key is required to connect to the bot API, in order to leverage the WebHook or WebSocket modes. Clicking on Display test configurations , you can see another Test configuration has been created. This connector is used when the bot is tested directly through the Tock Studio interface. It allows to try the bot without having Slack, for instance. Create a story \u00b6 A conversational bot receives and understands user sentences, using natural-language techniques to identify an intent and possibly entities . Example: from the sentence \"What will the weather be like tomorrow?\", the Tock NLU (Natural Language Understanding) engine should detect a \"weather\" intent and a \"tomorrow\" date/time entity precising the question (like a kind of intent variable/parameter). In order to detect intents and entities, sentences must first be added and qualifieds. The Tock NLU menu allows to manage intents and entities, qualify sentences and supervise the bot training: the more qualified sentences, the more relevant is the bot . Nevertheless, let's leave intents and entities for now... The Tock Stories mode allows to create intents automatically in a few minutes, as well as the expected answers. You will now create a first template of a conversation, using the Tock Studio graphical tools: Go to Build > New Story Enter a new user sentence - for instance \"hello\" A form now opens to configure the new story creation, the intent, the type of response, etc. In the Add new Answer field, enter the answer - for instance \"what a nice day!\" End with Create Story Test the bot \u00b6 It is time to try the bot and its first story! Go to Test > Test the bot Say \"hello\", the bot answers Please check that the correct application and language are selected (in case there are more than one) when testing: they are visible in the top-right corner of the interface. Improve the understanding \u00b6 By entering various sentences through the Test the bot interface, you can see it does not understand much your phrases - even with sentences very similar to the one at story creation. The conversational model and the Tock NLU engine must be trained and improved by progressively adding user qualified sentences to feed underlying algorithms and give more and more relevant results. Although first tries can be deceiving, several qualified sentences (one or two dozens if necessary) usually make a difference and the bot gets more relevant. Go to NLU > Inbox Here you can see the previously entered sentences, and more interestingly how the bot qualified them. For each sentence, Tock shows the detected intent, the language, as well as the scores (given by the algorithms according to their level of confidence for the sentence). Choose several sentences, for each one: select the correct intent then Validate Return to Test > Test the bot Check the bot now understands these sentences correctly, as well as slightly-different ones you have never entered! Create more stories (optional) \u00b6 To go a little further with Tock stories , you could create more stories and test them directly from Tock Studio . Each bot response comes from the intent detected/triggered, without another form of navigation than the thread of YOUR sentences. Conversational is magic: natural language is the navigation, users are not forced to use traditional links and menus anymore (contrary to Websites and mobile apps). For curious users, let's have a word about managing numerous stories and the possible impact on understanding. If you take time and create many stories , you may experience unintended effects with how work NLU models and algorithms. As an example, numerous intents and entities can make detection difficult (or more random). A general recommendation is to create bots, dedicated to a limited functional perimeter. It makes it easier to train each bot and focus on the model for its own domain. Qualifying a lot of sentences generally improves the bot understanding, however too many sentences (or too similar) can over-train the model for an intent, resulting in degraded performance. As a conclusion, remember the design and maintenance of conversational models is complex, it requires training (the bot, as well as people building it), qualifying and adapting the models on a regular basis to user needs and language. Congratulations! \u00b6 You have just created your first conversational application with Tock. With a few minutes and no particular knowledge or skill, more importantly without writing or deploying code, you have been able to create a simple conversational workflow and test it online.","title":"Create your 1st bot"},{"location":"guide/studio/#create-your-first-bot-with-tock-studio","text":"The best way to try Tock is probably to create a first conversational bot using Tock Studio (the graphical user interface provided with the platform). By connecting to the Tock demonstration platform , it is possible to both design and test a conversational assistant in a few minutes, without having to write code.","title":"Create your first bot with Tock Studio"},{"location":"guide/studio/#what-you-will-build","text":"An application and a connector on the Tock demo platform A story : user sentence / bot answer, testable through the Tock Studio interface An assistant who answers, when you say \"hello\"! \ud83d\ude42","title":"What you will build"},{"location":"guide/studio/#what-you-need","text":"About 5 to 15 minutes (reading the additional notes) A GitHub account, to connect to the demo platform","title":"What you need"},{"location":"guide/studio/#connect-to-the-demo-platform","text":"Open https://demo.tock.ai/ to access the Tock demonstration platform. Important : this platform is not supposed to host bots in production. This is merely a sandbox instance, in order to try the Tock solution without installing it. A login dialog invites you to connect with GitHub. Only your account ID will be read from GitHub.","title":"Connect to the demo platform"},{"location":"guide/studio/#create-a-tock-application","text":"When accessing the demo platform for the first time, a wizard helps to create the first application : Enter a name for the application Select a language - other languages can be added later Validate to create the application The just-created application is now visible from the menu: Configuration > NLU Applications . Once the first application has been created, you can create others using Create New Application .","title":"Create a Tock application"},{"location":"guide/studio/#add-a-connector","text":"To interact with the bot (through a communication channel), a connector must be used. Numerous connectors are provided with Tock: Messenger , WhatsApp , Google Assistant and Google Home , Twitter , Alexa , Business Chat , Teams , Slack , Rocket.Chat ... It is even possible to implement your own connectors to integrate with more channels. In this tutorial, you will configure a connector for Slack - the collaborative and instant messaging platform. It will be possible to try the bot using the Tock Studio interface - no need to use Slack or get an account. Create the first connector for your application: Go to Configuration > Bot Configurations Create a new Configuration Select the connector type Slack Enter anything e.g. token in Token fields (for the moment) Create Note that an API Key is automatically generated for the application, once the first connector is created. This key is required to connect to the bot API, in order to leverage the WebHook or WebSocket modes. Clicking on Display test configurations , you can see another Test configuration has been created. This connector is used when the bot is tested directly through the Tock Studio interface. It allows to try the bot without having Slack, for instance.","title":"Add a connector"},{"location":"guide/studio/#create-a-story","text":"A conversational bot receives and understands user sentences, using natural-language techniques to identify an intent and possibly entities . Example: from the sentence \"What will the weather be like tomorrow?\", the Tock NLU (Natural Language Understanding) engine should detect a \"weather\" intent and a \"tomorrow\" date/time entity precising the question (like a kind of intent variable/parameter). In order to detect intents and entities, sentences must first be added and qualifieds. The Tock NLU menu allows to manage intents and entities, qualify sentences and supervise the bot training: the more qualified sentences, the more relevant is the bot . Nevertheless, let's leave intents and entities for now... The Tock Stories mode allows to create intents automatically in a few minutes, as well as the expected answers. You will now create a first template of a conversation, using the Tock Studio graphical tools: Go to Build > New Story Enter a new user sentence - for instance \"hello\" A form now opens to configure the new story creation, the intent, the type of response, etc. In the Add new Answer field, enter the answer - for instance \"what a nice day!\" End with Create Story","title":"Create a story"},{"location":"guide/studio/#test-the-bot","text":"It is time to try the bot and its first story! Go to Test > Test the bot Say \"hello\", the bot answers Please check that the correct application and language are selected (in case there are more than one) when testing: they are visible in the top-right corner of the interface.","title":"Test the bot"},{"location":"guide/studio/#improve-the-understanding","text":"By entering various sentences through the Test the bot interface, you can see it does not understand much your phrases - even with sentences very similar to the one at story creation. The conversational model and the Tock NLU engine must be trained and improved by progressively adding user qualified sentences to feed underlying algorithms and give more and more relevant results. Although first tries can be deceiving, several qualified sentences (one or two dozens if necessary) usually make a difference and the bot gets more relevant. Go to NLU > Inbox Here you can see the previously entered sentences, and more interestingly how the bot qualified them. For each sentence, Tock shows the detected intent, the language, as well as the scores (given by the algorithms according to their level of confidence for the sentence). Choose several sentences, for each one: select the correct intent then Validate Return to Test > Test the bot Check the bot now understands these sentences correctly, as well as slightly-different ones you have never entered!","title":"Improve the understanding"},{"location":"guide/studio/#create-more-stories-optional","text":"To go a little further with Tock stories , you could create more stories and test them directly from Tock Studio . Each bot response comes from the intent detected/triggered, without another form of navigation than the thread of YOUR sentences. Conversational is magic: natural language is the navigation, users are not forced to use traditional links and menus anymore (contrary to Websites and mobile apps). For curious users, let's have a word about managing numerous stories and the possible impact on understanding. If you take time and create many stories , you may experience unintended effects with how work NLU models and algorithms. As an example, numerous intents and entities can make detection difficult (or more random). A general recommendation is to create bots, dedicated to a limited functional perimeter. It makes it easier to train each bot and focus on the model for its own domain. Qualifying a lot of sentences generally improves the bot understanding, however too many sentences (or too similar) can over-train the model for an intent, resulting in degraded performance. As a conclusion, remember the design and maintenance of conversational models is complex, it requires training (the bot, as well as people building it), qualifying and adapting the models on a regular basis to user needs and language.","title":"Create more stories (optional)"},{"location":"guide/studio/#congratulations","text":"You have just created your first conversational application with Tock. With a few minutes and no particular knowledge or skill, more importantly without writing or deploying code, you have been able to create a simple conversational workflow and test it online.","title":"Congratulations!"}]}