{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Tock - open conversational platform \u00b6 Tock ( The Open Conversation Kit ) is a complete and open platform to build conversational agents - also known as bots . The Tock.ai site is a good starting point to learn about the solution and its growing community. Tock does not depend on 3rd-party APIs, although it is possible to integrate with them. Users choose which components to embed and decide to keep (or share) ownership of conversational data and models. Tock has been used in production for several years by OUI.sncf to propose various assistants over its own channels (Web, mobile), social networks, as well as smart speakers. The platform source code is available on GitHub under the Apache License, version 2.0 . To find out more about AlloCovid (built with Tock) please visit www.allocovid.com . Available by phone, on the Web and WhatsApp, the bot informs and guides French population about the Covid-19, thanks to experts, partners and volunteers. This page gives technical details and links to the sources. Features \u00b6 Bots standalone or integrated with Web sites, mobile apps, social networks, smart speakers. Full-featured NLU ( Natural Language Understanding ) platform: Leveraging open technologies, such as OpenNLP , Stanford CoreNLP , Duckling , Rasa (later Spacy , BERT , ...) Can be deployed alone (for use cases like Internet Of Things ) Tock Studio user interfaces: NLU model management, bot training and performance monitoring Zero-code conversational stories and decision trees builder Internationalization support ( i18n ) for multilingual bots Dialog monitoring and user flow analytics Frameworks provided to develop complex stories and integrate with 3 rd -party services: Kotlin , Javascript/Nodejs , Python DSLs and any-language REST API (see Bot API ) Numerous text/voice integrations available with Messenger , WhatsApp , Google Assistant , Alexa , Twitter , Apple Business Chat , Teams , Slack ... (see connectors ) Cloud or on-premise setups, with or without Docker , \"embedded\" bots without Internet Technologies \u00b6 Tock components can run as containers (provided implementation for Docker ). The application runs on JVM platforms. The reference language is Kotlin , but other programming languages can be leveraged through the available APIs. On the server side, Tock relies on Vert.x and MongoDB (alt. DocumentDB ) . Various NLU libraries and algorithms can be used, but Tock does not depend on them directly. Tock Studio graphical user interfaces are built with Angular in Typescript . React and Flutter toolkits are provided for Web and Mobile integrations. Getting started... \u00b6 Contents Read Tutorial and start using the demo/sandbox platform User manual for developers","title":"Overview"},{"location":"#welcome-to-tock-open-conversational-platform","text":"Tock ( The Open Conversation Kit ) is a complete and open platform to build conversational agents - also known as bots . The Tock.ai site is a good starting point to learn about the solution and its growing community. Tock does not depend on 3rd-party APIs, although it is possible to integrate with them. Users choose which components to embed and decide to keep (or share) ownership of conversational data and models. Tock has been used in production for several years by OUI.sncf to propose various assistants over its own channels (Web, mobile), social networks, as well as smart speakers. The platform source code is available on GitHub under the Apache License, version 2.0 . To find out more about AlloCovid (built with Tock) please visit www.allocovid.com . Available by phone, on the Web and WhatsApp, the bot informs and guides French population about the Covid-19, thanks to experts, partners and volunteers. This page gives technical details and links to the sources.","title":"Welcome to Tock - open conversational platform"},{"location":"#features","text":"Bots standalone or integrated with Web sites, mobile apps, social networks, smart speakers. Full-featured NLU ( Natural Language Understanding ) platform: Leveraging open technologies, such as OpenNLP , Stanford CoreNLP , Duckling , Rasa (later Spacy , BERT , ...) Can be deployed alone (for use cases like Internet Of Things ) Tock Studio user interfaces: NLU model management, bot training and performance monitoring Zero-code conversational stories and decision trees builder Internationalization support ( i18n ) for multilingual bots Dialog monitoring and user flow analytics Frameworks provided to develop complex stories and integrate with 3 rd -party services: Kotlin , Javascript/Nodejs , Python DSLs and any-language REST API (see Bot API ) Numerous text/voice integrations available with Messenger , WhatsApp , Google Assistant , Alexa , Twitter , Apple Business Chat , Teams , Slack ... (see connectors ) Cloud or on-premise setups, with or without Docker , \"embedded\" bots without Internet","title":"Features"},{"location":"#technologies","text":"Tock components can run as containers (provided implementation for Docker ). The application runs on JVM platforms. The reference language is Kotlin , but other programming languages can be leveraged through the available APIs. On the server side, Tock relies on Vert.x and MongoDB (alt. DocumentDB ) . Various NLU libraries and algorithms can be used, but Tock does not depend on them directly. Tock Studio graphical user interfaces are built with Angular in Typescript . React and Flutter toolkits are provided for Web and Mobile integrations.","title":"Technologies"},{"location":"#getting-started","text":"Contents Read Tutorial and start using the demo/sandbox platform User manual for developers","title":"Getting started..."},{"location":"api/","text":"Tock documented APIs \u00b6 Tock Web Connector API \u00b6 The Tock Web Connector allows to interact with a bot using a REST API. API documentation is available at /api/web-connector . Tock Web Connector API \u00b6 To test a model via the Tock NLU API, see /api . It is also possible to run the provided Docker images and open http://localhost/doc/index.html Tock Studio / Admin API \u00b6 Tock Studio Admin API (to manage the models) is documented: /api/admin It is also possible to run the provided Docker images and open http://localhost/doc/admin.html . Tock Bot Definition API \u00b6 This API allows to create bots and stories with any programing language. Tock bots can be composed of configured stories (using Tock Studio builder) and programatic stories, possibly implementing complex rules or leveraging other external APIs. This API is used by provided Kotlin, Javascript/Nodejs and Python clients available in WebHook or WebSocket mode. The API is under development, it will soon be documented. To know more about the Bot API development frameworks, see this page .","title":"API documentation"},{"location":"api/#tock-documented-apis","text":"","title":"Tock documented APIs"},{"location":"api/#tock-web-connector-api","text":"The Tock Web Connector allows to interact with a bot using a REST API. API documentation is available at /api/web-connector .","title":"Tock Web Connector API"},{"location":"api/#tock-web-connector-api_1","text":"To test a model via the Tock NLU API, see /api . It is also possible to run the provided Docker images and open http://localhost/doc/index.html","title":"Tock Web Connector API"},{"location":"api/#tock-studio-admin-api","text":"Tock Studio Admin API (to manage the models) is documented: /api/admin It is also possible to run the provided Docker images and open http://localhost/doc/admin.html .","title":"Tock Studio / Admin API"},{"location":"api/#tock-bot-definition-api","text":"This API allows to create bots and stories with any programing language. Tock bots can be composed of configured stories (using Tock Studio builder) and programatic stories, possibly implementing complex rules or leveraging other external APIs. This API is used by provided Kotlin, Javascript/Nodejs and Python clients available in WebHook or WebSocket mode. The API is under development, it will soon be documented. To know more about the Bot API development frameworks, see this page .","title":"Tock Bot Definition API"},{"location":"build-nlp-model/","text":"Build a New NLU (Natural Language Understanding) Model \u00b6 Overview \u00b6 Seven tabs are available: Try it : add (or test) a new sentence Inbox : not yet qualified sentences Archive : the set of archived sentences, i. e. marked as not yet recognized by the model. Search : an advanced search interface that lets you search for sentences, whether or not they are qualified. Intents : the list of the model's intentions Entities : the list of model entities Logs : the last queries requested via the NLP API The user is redirected by default to Inbox . Add and Qualify Sentences \u00b6 Add a New Sentence \u00b6 Click on the New Sentence menu and enter the new sentence. The add a new user intent by selecting \"Create a New Intent\" in the \"Intent\" selection list. Declaring Entities \u00b6 If necessary, you can specify the entities of this new intent, by selecting the text of these entities, and then clicking on the \"Add New Entity\" button that has just appeared. It's up to you to choose an existing entity type, or create a new one, and then give that entity a role. Built-in Entities \u00b6 In the window \"Add Entity\", you can see that there are already pre-existing entities (prefixed by duckling ). These are the entities recognized by the eponymous library. These entities will be recognized and valued automatically if you specify them in at least one sentence of the intent. Validate a Sentence \u00b6 If you think that the sentence is qualified correctly, you just have to click on \"Validate\" to confirm that the sentence is ok. If this is not the case, it's up to you to correct the meaning before validating it. You are building your first model! Explore the Model \u00b6 The Search Tab \u00b6 The Search tab allows you to browse all the sentences of the model. The most used criterion is the full text search input (regular expressions are allowed). You can then consult the sentences that are part of your model, and also change the qualifications of these sentences over time. States of a Sentence \u00b6 Each sentence has a state: Inbox : The sentence has not been qualified yet and is not included in the model Validated : The sentence has been validated but is not yet included in the NLP model (this can take some time for large models) Included in model : The sentence has been validated and is included in the model Advanced Features \u00b6 By clicking on the \"Applications\"menu, you get the list of existing applications. Then click of the edit button of the application you want to configure. Nlp Engine Selection \u00b6 You can select the NLP library used by this application with the \"NLP engine\" radio button: Use Built-in Entity Models \u00b6 This option allows you to reuse built-in entity models (ie duckling) in your new intent. For example, if you create an intent with a duckling:datetime entity, the dates will automatically be recognized for that intent in all new sentences assigned to that intent (Internally, a merge is performed between the info given by the built-in entity models and the info of your own model). This option is enabled by default, it can be useful to disable it for very large models, for which the NER detection will perform better in almost all cases. Use sub-entities \u00b6 If you enable this option, you will be able to qualify multiple levels of entities: The number of levels is not limited, but it is advisable not to specify more than 3 or 4. Use predefined values \u00b6 An entity can have predefined values : you just have to click on \"Entities\" tab, and select an entity. A small icon next to the delete icon shows the types of entities you can edit as shown in the picture below:","title":"Build NLP models"},{"location":"build-nlp-model/#build-a-new-nlu-natural-language-understanding-model","text":"","title":"Build a New NLU (Natural Language Understanding) Model"},{"location":"build-nlp-model/#overview","text":"Seven tabs are available: Try it : add (or test) a new sentence Inbox : not yet qualified sentences Archive : the set of archived sentences, i. e. marked as not yet recognized by the model. Search : an advanced search interface that lets you search for sentences, whether or not they are qualified. Intents : the list of the model's intentions Entities : the list of model entities Logs : the last queries requested via the NLP API The user is redirected by default to Inbox .","title":"Overview"},{"location":"build-nlp-model/#add-and-qualify-sentences","text":"","title":"Add and Qualify Sentences"},{"location":"build-nlp-model/#add-a-new-sentence","text":"Click on the New Sentence menu and enter the new sentence. The add a new user intent by selecting \"Create a New Intent\" in the \"Intent\" selection list.","title":"Add a New Sentence"},{"location":"build-nlp-model/#declaring-entities","text":"If necessary, you can specify the entities of this new intent, by selecting the text of these entities, and then clicking on the \"Add New Entity\" button that has just appeared. It's up to you to choose an existing entity type, or create a new one, and then give that entity a role.","title":"Declaring Entities"},{"location":"build-nlp-model/#built-in-entities","text":"In the window \"Add Entity\", you can see that there are already pre-existing entities (prefixed by duckling ). These are the entities recognized by the eponymous library. These entities will be recognized and valued automatically if you specify them in at least one sentence of the intent.","title":"Built-in Entities"},{"location":"build-nlp-model/#validate-a-sentence","text":"If you think that the sentence is qualified correctly, you just have to click on \"Validate\" to confirm that the sentence is ok. If this is not the case, it's up to you to correct the meaning before validating it. You are building your first model!","title":"Validate a Sentence"},{"location":"build-nlp-model/#explore-the-model","text":"","title":"Explore the Model"},{"location":"build-nlp-model/#the-search-tab","text":"The Search tab allows you to browse all the sentences of the model. The most used criterion is the full text search input (regular expressions are allowed). You can then consult the sentences that are part of your model, and also change the qualifications of these sentences over time.","title":"The Search Tab"},{"location":"build-nlp-model/#states-of-a-sentence","text":"Each sentence has a state: Inbox : The sentence has not been qualified yet and is not included in the model Validated : The sentence has been validated but is not yet included in the NLP model (this can take some time for large models) Included in model : The sentence has been validated and is included in the model","title":"States of a Sentence"},{"location":"build-nlp-model/#advanced-features","text":"By clicking on the \"Applications\"menu, you get the list of existing applications. Then click of the edit button of the application you want to configure.","title":"Advanced Features"},{"location":"build-nlp-model/#nlp-engine-selection","text":"You can select the NLP library used by this application with the \"NLP engine\" radio button:","title":"Nlp Engine Selection"},{"location":"build-nlp-model/#use-built-in-entity-models","text":"This option allows you to reuse built-in entity models (ie duckling) in your new intent. For example, if you create an intent with a duckling:datetime entity, the dates will automatically be recognized for that intent in all new sentences assigned to that intent (Internally, a merge is performed between the info given by the built-in entity models and the info of your own model). This option is enabled by default, it can be useful to disable it for very large models, for which the NER detection will perform better in almost all cases.","title":"Use Built-in Entity Models"},{"location":"build-nlp-model/#use-sub-entities","text":"If you enable this option, you will be able to qualify multiple levels of entities: The number of levels is not limited, but it is advisable not to specify more than 3 or 4.","title":"Use sub-entities"},{"location":"build-nlp-model/#use-predefined-values","text":"An entity can have predefined values : you just have to click on \"Entities\" tab, and select an entity. A small icon next to the delete icon shows the types of entities you can edit as shown in the picture below:","title":"Use predefined values"},{"location":"evaluate-the-model/","text":"Evaluate the relevance of a NLP model \u00b6 In Model Quality various views give insights about the relevance of the model: Model Stats : Monitores model perfomance in production: self-evaluation of the model about its relevance in terms of recognition of intent and entities number of calls and errors average execution time Intent Distance : the distance between intents Model Builds : history and details about model builds Test Trends : evolution of the relevance of model tests Test Intent Errors : the list of intent errors found with model tests Test Entity Errors : the list of entity errors found with model tests Model Tests 101 \u00b6 Model tests are used to detect qualifications errors. Temporarily models are built from a random part of the whole sentence set of the model (90% for example) and then tested against the remaining sentences. The process is repeated a number of times and the most frequent errors are pushed to an admin user. Model tests are useful only with large models. Test Intent errors \u00b6 Click on the Intent Errors tab: Since the picture above is built from a very simple model, no real error has been detected. We can nevertheless note that in some cases the model is systematically wrong with a high probability. Test Entity errors \u00b6 These errors can be viewed via the Entity Errors tab.","title":"Monitor NLP models"},{"location":"evaluate-the-model/#evaluate-the-relevance-of-a-nlp-model","text":"In Model Quality various views give insights about the relevance of the model: Model Stats : Monitores model perfomance in production: self-evaluation of the model about its relevance in terms of recognition of intent and entities number of calls and errors average execution time Intent Distance : the distance between intents Model Builds : history and details about model builds Test Trends : evolution of the relevance of model tests Test Intent Errors : the list of intent errors found with model tests Test Entity Errors : the list of entity errors found with model tests","title":"Evaluate the relevance of a NLP model"},{"location":"evaluate-the-model/#model-tests-101","text":"Model tests are used to detect qualifications errors. Temporarily models are built from a random part of the whole sentence set of the model (90% for example) and then tested against the remaining sentences. The process is repeated a number of times and the most frequent errors are pushed to an admin user. Model tests are useful only with large models.","title":"Model Tests 101"},{"location":"evaluate-the-model/#test-intent-errors","text":"Click on the Intent Errors tab: Since the picture above is built from a very simple model, no real error has been detected. We can nevertheless note that in some cases the model is systematically wrong with a high probability.","title":"Test Intent errors"},{"location":"evaluate-the-model/#test-entity-errors","text":"These errors can be viewed via the Entity Errors tab.","title":"Test Entity errors"},{"location":"getting-started/","text":"TLDR; \u00b6 Deploy the Open Data Bot example with Docker. A Sample Bot \u00b6 The sample bot using Tock Integrated mode : https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit. Docker Images \u00b6 Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker . Start the NLP stack \u00b6 #get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password . Sample bot based on Open Data APIs \u00b6 A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images . Administration Interface Menu \u00b6 The Configuration menu allows you to create new models and configure them. The NLP and NLP QA menus are dedicated to building NLP models. The Build , Test and Monitoring menus are used for building bots or assistants.","title":"TLDR;"},{"location":"getting-started/#tldr","text":"Deploy the Open Data Bot example with Docker.","title":"TLDR;"},{"location":"getting-started/#a-sample-bot","text":"The sample bot using Tock Integrated mode : https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit.","title":"A Sample Bot"},{"location":"getting-started/#docker-images","text":"Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker .","title":"Docker Images"},{"location":"getting-started/#start-the-nlp-stack","text":"#get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password .","title":"Start the NLP stack"},{"location":"getting-started/#sample-bot-based-on-open-data-apis","text":"A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images .","title":"Sample bot based on Open Data APIs"},{"location":"getting-started/#administration-interface-menu","text":"The Configuration menu allows you to create new models and configure them. The NLP and NLP QA menus are dedicated to building NLP models. The Build , Test and Monitoring menus are used for building bots or assistants.","title":"Administration Interface Menu"},{"location":"kdoc/","text":"A KDoc documentation is provided .","title":"KDoc"},{"location":"test-the-bot/","text":"Use the Test Framework \u00b6 Tock provides extensions in order to help writing better unit tests. To use them, you need to add the bot-test dependency to your project. With Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> bot-test </artifactId> <version> 20.9.2-1 </version> <scope> test </scope> </dependency> With Gradle : testCompile 'ai.tock:bot-test:20.9.2-1' This framework is documented in KDoc format [here]https://doc.tock.ai/tock/dokka/tock/ai.tock.bot.test). Write a Simple Test \u00b6 In the next samples, JUnit5 is used as test engine. A dedicated extension for Tock is available . @RegisterExtension @JvmField val ext = TockJUnit5Extension ( bot ) To test the greetings story of the Open Data bot, just use the ext.send() method: @Test fun `greetings story displays welcome message` () { ext . send { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } } As the default connector is Messenger, it is possible to test the message specific to Messenger in the same way: @Test fun `greetings story displays welcome message with Messenger dedicated message` () { ext . send { lastAnswer . assertMessage ( buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) ) } } To test the message specific to Google Assistant (or any other connector), you need to indicate the connector to be tested: @Test fun `greetings story displays welcome message with GA dedicated message WHEN context contains GA connector` () { ext . send ( connectorType = gaConnectorType ) { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) lastAnswer . assertMessage ( gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) ) } } Test a specific Story \u00b6 In the previous examples, it was useless to specify the story to test ( greetings being the default story). Suppose you want to test the search story, then you need to indicate the story to test as follows: @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search ) { firstAnswer . assertText ( \"For which destination?\" ) } } Test a Conversation \u00b6 You can simulate a whole conversation. For example, here the user indicates the destination, then the origin: @Test fun `search story asks for origin WHEN there is a destination BUT no origin in context` () { ext . send ( \"I would like to find a train\" , search ) { firstAnswer . assertText ( \"For which destination?\" ) } ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( \"For which origin?\" ) } ext . send ( \"Paris\" , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( \"When?\" ) } } The first text parameter of the send method is merely indicative, to help understanding the tests. The others parameters defines how the NLP engine has analysed the text. For example : private val lille = PlaceValue ( SncfPlace ( \"stop_area\" , 90 , \"Lille Europe\" , \"Lille Europe (Lille)\" , \"stop_area:OCE:SA:87223263\" , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) indicate that the phrase \"Lille\" is categorized as an indicate_location intent with a value lille for the entity location . Finally it is possible to modify all the values of the mocked bus at initialization. In the following example, the use of the secondary intent indicate_location is simulated to indicate the origin: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Search\" , search ) { destination = lille origin = paris run () firstAnswer . assertText ( \"When?\" ) } } The destination and origin variables are updated, then a call to the bus is simulated with the function run() .","title":"Use the Test Framework"},{"location":"test-the-bot/#use-the-test-framework","text":"Tock provides extensions in order to help writing better unit tests. To use them, you need to add the bot-test dependency to your project. With Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> bot-test </artifactId> <version> 20.9.2-1 </version> <scope> test </scope> </dependency> With Gradle : testCompile 'ai.tock:bot-test:20.9.2-1' This framework is documented in KDoc format [here]https://doc.tock.ai/tock/dokka/tock/ai.tock.bot.test).","title":"Use the Test Framework"},{"location":"test-the-bot/#write-a-simple-test","text":"In the next samples, JUnit5 is used as test engine. A dedicated extension for Tock is available . @RegisterExtension @JvmField val ext = TockJUnit5Extension ( bot ) To test the greetings story of the Open Data bot, just use the ext.send() method: @Test fun `greetings story displays welcome message` () { ext . send { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } } As the default connector is Messenger, it is possible to test the message specific to Messenger in the same way: @Test fun `greetings story displays welcome message with Messenger dedicated message` () { ext . send { lastAnswer . assertMessage ( buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) ) } } To test the message specific to Google Assistant (or any other connector), you need to indicate the connector to be tested: @Test fun `greetings story displays welcome message with GA dedicated message WHEN context contains GA connector` () { ext . send ( connectorType = gaConnectorType ) { firstAnswer . assertText ( \"Welcome to the Tock Open Data Bot! :)\" ) secondAnswer . assertText ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) lastAnswer . assertMessage ( gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) ) } }","title":"Write a Simple Test"},{"location":"test-the-bot/#test-a-specific-story","text":"In the previous examples, it was useless to specify the story to test ( greetings being the default story). Suppose you want to test the search story, then you need to indicate the story to test as follows: @Test fun `search story asks for destination WHEN there is no destination in context` () { ext . send ( intent = search ) { firstAnswer . assertText ( \"For which destination?\" ) } }","title":"Test a specific Story"},{"location":"test-the-bot/#test-a-conversation","text":"You can simulate a whole conversation. For example, here the user indicates the destination, then the origin: @Test fun `search story asks for origin WHEN there is a destination BUT no origin in context` () { ext . send ( \"I would like to find a train\" , search ) { firstAnswer . assertText ( \"For which destination?\" ) } ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) { firstBusAnswer . assertText ( \"For which origin?\" ) } ext . send ( \"Paris\" , indicate_location , locationEntity setTo paris ) { firstBusAnswer . assertText ( \"When?\" ) } } The first text parameter of the send method is merely indicative, to help understanding the tests. The others parameters defines how the NLP engine has analysed the text. For example : private val lille = PlaceValue ( SncfPlace ( \"stop_area\" , 90 , \"Lille Europe\" , \"Lille Europe (Lille)\" , \"stop_area:OCE:SA:87223263\" , Coordinates ( 50.638861 , 3.075774 ) ) ) ext . send ( \"Lille\" , indicate_location , locationEntity setTo lille ) indicate that the phrase \"Lille\" is categorized as an indicate_location intent with a value lille for the entity location . Finally it is possible to modify all the values of the mocked bus at initialization. In the following example, the use of the secondary intent indicate_location is simulated to indicate the origin: @Test fun `search story asks for departure date WHEN there is a destination and an origin but no departure date in context` () { ext . newRequest ( \"Search\" , search ) { destination = lille origin = paris run () firstAnswer . assertText ( \"When?\" ) } } The destination and origin variables are updated, then a call to the bus is simulated with the function run() .","title":"Test a Conversation"},{"location":"the-open-data-bot/","text":"The Open Data Bot example \u00b6 An integrated bot sample is available: the Open Data Bot . The Open Data Bot \u00b6 A good starting point is the source code of the Open Data Bot Follow the instructions of the README file of the project, to start the bot in the IDE (do not configure Messenger or Google Assistant at this point), then connect to the administration interface. The bot is already testable. The Test Tab \u00b6 Go to this tab, and test the bot: This is a test mode, so the interface is minimal. The real goal is to have your users interact with the bot via channels like Messenger, Google Assistant ... or your sites or applications. The Monitoring Tab \u00b6 It is then possible to consult the discussion that you just had with the bot via the Monitoring tab: In this sample, this dialog has the Messenger flag, as it was tested for this channel. The Build Tab \u00b6 Add a new answer \u00b6 With the category Add new Answer , it is possible to add directly a new answer: Then test the new intention and its answer: Modify the Answers and Internationalization \u00b6 Finally it is possible to modify each answer of the bot, by type of interface (chat / voice), by type of connector and by language with the i18n tab. The ability to add alternative answers (a response from the list will be chosen each time at random) is also provided (with the \"plus\" button).","title":"Code Samples"},{"location":"the-open-data-bot/#the-open-data-bot-example","text":"An integrated bot sample is available: the Open Data Bot .","title":"The Open Data Bot example"},{"location":"the-open-data-bot/#the-open-data-bot","text":"A good starting point is the source code of the Open Data Bot Follow the instructions of the README file of the project, to start the bot in the IDE (do not configure Messenger or Google Assistant at this point), then connect to the administration interface. The bot is already testable.","title":"The Open Data Bot"},{"location":"the-open-data-bot/#the-test-tab","text":"Go to this tab, and test the bot: This is a test mode, so the interface is minimal. The real goal is to have your users interact with the bot via channels like Messenger, Google Assistant ... or your sites or applications.","title":"The Test Tab"},{"location":"the-open-data-bot/#the-monitoring-tab","text":"It is then possible to consult the discussion that you just had with the bot via the Monitoring tab: In this sample, this dialog has the Messenger flag, as it was tested for this channel.","title":"The Monitoring Tab"},{"location":"the-open-data-bot/#the-build-tab","text":"","title":"The Build Tab"},{"location":"the-open-data-bot/#add-a-new-answer","text":"With the category Add new Answer , it is possible to add directly a new answer: Then test the new intention and its answer:","title":"Add a new answer"},{"location":"the-open-data-bot/#modify-the-answers-and-internationalization","text":"Finally it is possible to modify each answer of the bot, by type of interface (chat / voice), by type of connector and by language with the i18n tab. The ability to add alternative answers (a response from the list will be chosen each time at random) is also provided (with the \"plus\" button).","title":"Modify the Answers and Internationalization"},{"location":"toc/","text":"","title":"Toc"},{"location":"about/awards/","text":"Awards \u00b6 From its creation in for OUI.sncf in 2016 to the French AlloCovid service in 2020, both the technical solution and bots designed with Tock have been awarded. Best Open Source Strategy 2019 (SNCF) \u00b6 In 2019, the Acteurs du Libre award for the Best Open Source Strategy was given to SNCF (\"French National Railway Company\") for creating and sharing open platforms, such as Tock (e.Voyageurs subsidiary) and Navitia (Kisio Digital subsidiary). Simon Clavier and Fran\u00e7ois Nollen received the award on December 10 th in the Grand Auditorium of Paris Open Source Summit . Several photos and a video recording (in French) are available. To find out more, see Les Acteurs Du Libre (French). Best Robot Experience 2019 (OUI.sncf) \u00b6 In 2019, OUIbot was awarded the Best Robot Experience for the 2 nd time in a row. Received by Caroline Chupin and Evelyne Papon for OUI.sncf, the award was the result of ranking 31 robots, chatbots and voicebots. An interview is available (in French). More on the Cultures Services blog (in French too). Best Robot Experience 2018 (OUI.sncf) \u00b6 In 2018, OUIbot (the OUI.sncf assistant, with 10.000 users a day) received the Best Robot Experience award from the Acad\u00e9mie du Service / Sens du client . Given to Caroline Chupin for OUI.sncf, the award assessed mutliple criteria to rank 24 virtual agents from prestigious organizations (companies, GAFAM, public sector). To find out more, visit the Sens du client blog.","title":"Awards"},{"location":"about/awards/#awards","text":"From its creation in for OUI.sncf in 2016 to the French AlloCovid service in 2020, both the technical solution and bots designed with Tock have been awarded.","title":"Awards"},{"location":"about/awards/#best-open-source-strategy-2019-sncf","text":"In 2019, the Acteurs du Libre award for the Best Open Source Strategy was given to SNCF (\"French National Railway Company\") for creating and sharing open platforms, such as Tock (e.Voyageurs subsidiary) and Navitia (Kisio Digital subsidiary). Simon Clavier and Fran\u00e7ois Nollen received the award on December 10 th in the Grand Auditorium of Paris Open Source Summit . Several photos and a video recording (in French) are available. To find out more, see Les Acteurs Du Libre (French).","title":"Best Open Source Strategy 2019 (SNCF)"},{"location":"about/awards/#best-robot-experience-2019-ouisncf","text":"In 2019, OUIbot was awarded the Best Robot Experience for the 2 nd time in a row. Received by Caroline Chupin and Evelyne Papon for OUI.sncf, the award was the result of ranking 31 robots, chatbots and voicebots. An interview is available (in French). More on the Cultures Services blog (in French too).","title":"Best Robot Experience 2019 (OUI.sncf)"},{"location":"about/awards/#best-robot-experience-2018-ouisncf","text":"In 2018, OUIbot (the OUI.sncf assistant, with 10.000 users a day) received the Best Robot Experience award from the Acad\u00e9mie du Service / Sens du client . Given to Caroline Chupin for OUI.sncf, the award assessed mutliple criteria to rank 24 virtual agents from prestigious organizations (companies, GAFAM, public sector). To find out more, visit the Sens du client blog.","title":"Best Robot Experience 2018 (OUI.sncf)"},{"location":"about/community/","text":"Community \u00b6 Tock has been designed to remain an open platform shared with the community. To know more, see why Tock . The Tock community is open to contribution: every feedback, issue , feature request and obviously pull request is more than welcome! Join the community (Gitter) \u00b6 Many Tock users and contributors meet on Gitter chatrooms. Join them to see how much the community is active and open. Tock community on Gitter Tock releases thread Follow Tock news \u00b6 To find Tock news, new projects, conferences, releases and more please visit the homepage: Tock.ai Specific news can be found on these topics: Known users & projects Presentations & conferences Awards For releases & features: Releases & features thread Release Notes Roadmap Code & Contribution (GitHub) \u00b6 The Tock platform and tools are available on GitHub under the Apache 2 license . Sources & projects License Issues Contributors To know more about repository structure, coding conventions, etc. refer to the contribute to Tock section. For other types of contribution, don't hesitate to use GitHub issues and join the community directly on Gitter. TOSIT association \u00b6 The Tock solution is currently being assessed by the TOSIT (The Open Source I Trust) , an association dedicated to support Open Source and Free Software, as part of the Chatbots Work Group. Founded by Carrefour, EDF, Enedis, Orange, P\u00f4le Emploi and SNCF, TOSIT now gathers other important members, such as the (French) Minist\u00e8re des Arm\u00e9es, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale or MAIF. Several TOSIT members, including SNCF, already use or experiment Tock. To know more about TOSIT, please visit http://tosit.fr/ Public Demo hosting \u00b6 The public Live Demo helps newcomers try and experiment with the solution. A dedicated user guide is available to make one's first steps with Tock and bots. Thanks to e.Voyageurs SNCF for hosting and maintaining the public Live Demo platform. Live Demo Guide Create your 1st bot with Tock Help \u00b6 Feel free to contact us .","title":"Community"},{"location":"about/community/#community","text":"Tock has been designed to remain an open platform shared with the community. To know more, see why Tock . The Tock community is open to contribution: every feedback, issue , feature request and obviously pull request is more than welcome!","title":"Community"},{"location":"about/community/#join-the-community-gitter","text":"Many Tock users and contributors meet on Gitter chatrooms. Join them to see how much the community is active and open. Tock community on Gitter Tock releases thread","title":"Join the community (Gitter)"},{"location":"about/community/#follow-tock-news","text":"To find Tock news, new projects, conferences, releases and more please visit the homepage: Tock.ai Specific news can be found on these topics: Known users & projects Presentations & conferences Awards For releases & features: Releases & features thread Release Notes Roadmap","title":"Follow Tock news"},{"location":"about/community/#code-contribution-github","text":"The Tock platform and tools are available on GitHub under the Apache 2 license . Sources & projects License Issues Contributors To know more about repository structure, coding conventions, etc. refer to the contribute to Tock section. For other types of contribution, don't hesitate to use GitHub issues and join the community directly on Gitter.","title":"Code &amp; Contribution (GitHub)"},{"location":"about/community/#tosit-association","text":"The Tock solution is currently being assessed by the TOSIT (The Open Source I Trust) , an association dedicated to support Open Source and Free Software, as part of the Chatbots Work Group. Founded by Carrefour, EDF, Enedis, Orange, P\u00f4le Emploi and SNCF, TOSIT now gathers other important members, such as the (French) Minist\u00e8re des Arm\u00e9es, Soci\u00e9t\u00e9 G\u00e9n\u00e9rale or MAIF. Several TOSIT members, including SNCF, already use or experiment Tock. To know more about TOSIT, please visit http://tosit.fr/","title":"TOSIT association"},{"location":"about/community/#public-demo-hosting","text":"The public Live Demo helps newcomers try and experiment with the solution. A dedicated user guide is available to make one's first steps with Tock and bots. Thanks to e.Voyageurs SNCF for hosting and maintaining the public Live Demo platform. Live Demo Guide Create your 1st bot with Tock","title":"Public Demo hosting"},{"location":"about/community/#help","text":"Feel free to contact us .","title":"Help"},{"location":"about/contact/","text":"Contact us \u00b6 Developers, users and curious people are more than welcome to share about Tock with both its creators and the community. Don't hesitate to join us on Gitter (the instant messaging service for GitHub): https://gitter.im/tockchat/Lobby GitHub issues can be used to keep track of bugs, enhancements or feature requests: https://github.com/theopenconversationkit/tock/issues","title":"Contact us"},{"location":"about/contact/#contact-us","text":"Developers, users and curious people are more than welcome to share about Tock with both its creators and the community. Don't hesitate to join us on Gitter (the instant messaging service for GitHub): https://gitter.im/tockchat/Lobby GitHub issues can be used to keep track of bugs, enhancements or feature requests: https://github.com/theopenconversationkit/tock/issues","title":"Contact us"},{"location":"about/contribute/","text":"Contribute to Tock \u00b6 The Tock project is open to contribution and any feedback is welcome! This page details the source structure and coding conventions for the platform. TL;DR \u00b6 See CONTRIBUTING.md . Main technologies \u00b6 Tock components can run as containers (provided implementation for Docker ). The application runs on JVM platforms. The reference language is Kotlin , but other programming languages can be leveraged through the available APIs. On the server side, Tock relies on Vert.x and MongoDB (alt. DocumentDB ) . Various NLU libraries and algorithms can be used, but Tock does not depend on them directly. Tock Studio graphical user interfaces are built with Angular in Typescript . React and Flutter toolkits are provided for Web and Mobile integrations. Source structure \u00b6 Repositories \u00b6 tock : main source repository, including the framework and platform components under the Apache 2 license . tock-corenlp : optional module, leveraging a dependency to Stanford CoreNLP (instead of Apache OpenNLP ), under GPL license . tock-docker : Docker and Docker Compose images/descriptors, for platform hands-on and fast deployment of various configurations. tock-bot-samples : code samples, in particular the WebHook and WebSocket modes examples from Tock programing guides . tock-bot-open-data : a bot example, based on the SNCF Open Data API , also implementing basic internationalization ( i18n ) mecanisms with two distinct languages. The tock repository \u00b6 TODO : detail modules and repo structure Le tock-docker repository \u00b6 TODO : detail modules and repo structure, how Maven and Docker builds work, etc. Build & run \u00b6 Build Tock from sources \u00b6 Tock (core) \u00b6 Tock is built with Maven , including the Web modules leveraging NPM et Angular : $ mvn package Continuous integration build jobs are available on Travis . Docker images \u00b6 Tock Docker images can be rebuilt from sources, included in repository tock-docker . One can use Maven to trigger the Docker build: $ mvn package docker:build Docker containers can then be instantiated from images, or Docker Compose stacks from the various descriptors at the root of the repository. Run Tock in IDE \u00b6 To run Tock using Docker Compose outside the IDE, rather see Deploy Tock with Docker . Tock components (NLU, Studio, bot...) can run in an IDE, such as IntelliJ , Eclipse or Visual Studio Code for instance. Beside the Docker images , IntelliJ configurations are provided with Tock sources: The Tock Studio interfaces/server: BotAdmin The alternative standalone NLU interfaces/server: Admin The NLU service: NlpService The Duckling entity-recognition service: Duckling The NLU model-builder service: BuildWorker The script compilation service: KotlinCompilerServer The OpenDataBot example also has a run configuration available: OpenDataBot To start the Tock Studio interfaces, please refer to the commands described in the following pages: Full Tock Studio server commands Standalone NLU server commands Code \u00b6 Commits & merge requests \u00b6 To submit a feature or bugfix: Create an issue : Reccommended format for the title: [Component] Title where component might be Studio , Core , Doc , etc. and title usually is like Do or fix something Create a pull request and link it to the issue(s): All commits should be signed Please rebase and squash unnecessary commits (tips: PR can be tagged as Draft ) before submitting Recommended format for the branch name : ISSUEID_short_title Recommended format for the commit(s) message(s): resolves #ISSUEID Component: title for features fixes #ISSUEID Component: title for fixes To be merged, a pull request must pass the tests and be reviewed by at least two of these developers: @vsct-jburet , @francoisno , @NainJaune , @elebescond , @SarukaUsagi , @MaximeLeFrancois , @bakic , @broxmik , @mrboizo Code conventions \u00b6 Kotlin Code Conventions are used. Unit tests \u00b6 Every new feature or fix should embed its unit test(s). Contact us \u00b6 To contribute to the project or to known more about the implementation, feel free to contact us . Ideas and feedback is more than welcome.","title":"Contribute"},{"location":"about/contribute/#contribute-to-tock","text":"The Tock project is open to contribution and any feedback is welcome! This page details the source structure and coding conventions for the platform.","title":"Contribute to Tock"},{"location":"about/contribute/#tldr","text":"See CONTRIBUTING.md .","title":"TL;DR"},{"location":"about/contribute/#main-technologies","text":"Tock components can run as containers (provided implementation for Docker ). The application runs on JVM platforms. The reference language is Kotlin , but other programming languages can be leveraged through the available APIs. On the server side, Tock relies on Vert.x and MongoDB (alt. DocumentDB ) . Various NLU libraries and algorithms can be used, but Tock does not depend on them directly. Tock Studio graphical user interfaces are built with Angular in Typescript . React and Flutter toolkits are provided for Web and Mobile integrations.","title":"Main technologies"},{"location":"about/contribute/#source-structure","text":"","title":"Source structure"},{"location":"about/contribute/#repositories","text":"tock : main source repository, including the framework and platform components under the Apache 2 license . tock-corenlp : optional module, leveraging a dependency to Stanford CoreNLP (instead of Apache OpenNLP ), under GPL license . tock-docker : Docker and Docker Compose images/descriptors, for platform hands-on and fast deployment of various configurations. tock-bot-samples : code samples, in particular the WebHook and WebSocket modes examples from Tock programing guides . tock-bot-open-data : a bot example, based on the SNCF Open Data API , also implementing basic internationalization ( i18n ) mecanisms with two distinct languages.","title":"Repositories"},{"location":"about/contribute/#the-tock-repository","text":"TODO : detail modules and repo structure","title":"The tock repository"},{"location":"about/contribute/#le-tock-docker-repository","text":"TODO : detail modules and repo structure, how Maven and Docker builds work, etc.","title":"Le tock-docker repository"},{"location":"about/contribute/#build-run","text":"","title":"Build &amp; run"},{"location":"about/contribute/#build-tock-from-sources","text":"","title":"Build Tock from sources"},{"location":"about/contribute/#tock-core","text":"Tock is built with Maven , including the Web modules leveraging NPM et Angular : $ mvn package Continuous integration build jobs are available on Travis .","title":"Tock (core)"},{"location":"about/contribute/#docker-images","text":"Tock Docker images can be rebuilt from sources, included in repository tock-docker . One can use Maven to trigger the Docker build: $ mvn package docker:build Docker containers can then be instantiated from images, or Docker Compose stacks from the various descriptors at the root of the repository.","title":"Docker images"},{"location":"about/contribute/#run-tock-in-ide","text":"To run Tock using Docker Compose outside the IDE, rather see Deploy Tock with Docker . Tock components (NLU, Studio, bot...) can run in an IDE, such as IntelliJ , Eclipse or Visual Studio Code for instance. Beside the Docker images , IntelliJ configurations are provided with Tock sources: The Tock Studio interfaces/server: BotAdmin The alternative standalone NLU interfaces/server: Admin The NLU service: NlpService The Duckling entity-recognition service: Duckling The NLU model-builder service: BuildWorker The script compilation service: KotlinCompilerServer The OpenDataBot example also has a run configuration available: OpenDataBot To start the Tock Studio interfaces, please refer to the commands described in the following pages: Full Tock Studio server commands Standalone NLU server commands","title":"Run Tock in IDE"},{"location":"about/contribute/#code","text":"","title":"Code"},{"location":"about/contribute/#commits-merge-requests","text":"To submit a feature or bugfix: Create an issue : Reccommended format for the title: [Component] Title where component might be Studio , Core , Doc , etc. and title usually is like Do or fix something Create a pull request and link it to the issue(s): All commits should be signed Please rebase and squash unnecessary commits (tips: PR can be tagged as Draft ) before submitting Recommended format for the branch name : ISSUEID_short_title Recommended format for the commit(s) message(s): resolves #ISSUEID Component: title for features fixes #ISSUEID Component: title for fixes To be merged, a pull request must pass the tests and be reviewed by at least two of these developers: @vsct-jburet , @francoisno , @NainJaune , @elebescond , @SarukaUsagi , @MaximeLeFrancois , @bakic , @broxmik , @mrboizo","title":"Commits &amp; merge requests"},{"location":"about/contribute/#code-conventions","text":"Kotlin Code Conventions are used.","title":"Code conventions"},{"location":"about/contribute/#unit-tests","text":"Every new feature or fix should embed its unit test(s).","title":"Unit tests"},{"location":"about/contribute/#contact-us","text":"To contribute to the project or to known more about the implementation, feel free to contact us . Ideas and feedback is more than welcome.","title":"Contact us"},{"location":"about/jobs/","text":"Tock jobs \u00b6 Interested in working with Tock and contribute to the platform? This page lists companies and organizations, proposing job offers in the field of conversational AI with Tock: e.Voyageurs SNCF (Tock creators) recruit various profiles to build conversational assistants with Tock. To known more, check offers on Gitter or https://jobs.oui.sncf/ . Do you leverage Tock and offer conversational jobs? Don't hesitate to tell us and expand the list.","title":"Jobs"},{"location":"about/jobs/#tock-jobs","text":"Interested in working with Tock and contribute to the platform? This page lists companies and organizations, proposing job offers in the field of conversational AI with Tock: e.Voyageurs SNCF (Tock creators) recruit various profiles to build conversational assistants with Tock. To known more, check offers on Gitter or https://jobs.oui.sncf/ . Do you leverage Tock and offer conversational jobs? Don't hesitate to tell us and expand the list.","title":"Tock jobs"},{"location":"about/resources/","text":"Tock resources \u00b6 This page lists various presentations of Tock, giving an overview of the solution in addition to the main documentation and demo instance. Conferences / video (in French) \u00b6 Tock & Melusine @ AI Paris 2020 (SNCF & MAIF) \ud83d\udd33 slides (French) Conversational AI & Open Source @ Paris Open Source Summit 2019 (SNCF & guests from EDF, Enedis, Orange, SogetiLabs, TOSIT.fr) \ud83d\udcfd\ufe0f 30 min (French) / \ud83d\udd33 slides (English) Code a bot for Messenger and Google Assistant in 30 minutes @ Devoxx France 2018 (live coding) \ud83d\udcfd\ufe0f 30 min (French) Meetup / Slides (in French) \u00b6 Tock - The Open Conversation Kit @ Meetup Open Transport (2019) Tock - The Open Conversation Kit @ CRiP OpenSource & Co-d\u00e9veloppement (2017) Don't hesitate to share with us more slides, documents and links about Tock. Press kit \u00b6 Tock logos are provided under the Apache 2 license . Tock logo - default colors / transparent ( download ) : Tock logo - blue / transparent ( download ) : Tock logo - black / transparent ( download ) : Tock logo - white / transparent ( download ) :","title":"Resources"},{"location":"about/resources/#tock-resources","text":"This page lists various presentations of Tock, giving an overview of the solution in addition to the main documentation and demo instance.","title":"Tock resources"},{"location":"about/resources/#conferences-video-in-french","text":"Tock & Melusine @ AI Paris 2020 (SNCF & MAIF) \ud83d\udd33 slides (French) Conversational AI & Open Source @ Paris Open Source Summit 2019 (SNCF & guests from EDF, Enedis, Orange, SogetiLabs, TOSIT.fr) \ud83d\udcfd\ufe0f 30 min (French) / \ud83d\udd33 slides (English) Code a bot for Messenger and Google Assistant in 30 minutes @ Devoxx France 2018 (live coding) \ud83d\udcfd\ufe0f 30 min (French)","title":"Conferences / video (in French)"},{"location":"about/resources/#meetup-slides-in-french","text":"Tock - The Open Conversation Kit @ Meetup Open Transport (2019) Tock - The Open Conversation Kit @ CRiP OpenSource & Co-d\u00e9veloppement (2017) Don't hesitate to share with us more slides, documents and links about Tock.","title":"Meetup / Slides (in French)"},{"location":"about/resources/#press-kit","text":"Tock logos are provided under the Apache 2 license . Tock logo - default colors / transparent ( download ) : Tock logo - blue / transparent ( download ) : Tock logo - black / transparent ( download ) : Tock logo - white / transparent ( download ) :","title":"Press kit"},{"location":"about/showcase/","text":"User showcase \u00b6 Since its creation for OUI.sncf in 2016 to the French AlloCovid service in 2020, Tock has been used by more and more teams (including SNCF but not only) to build conversational bots dedicated to various use cases : business to customer and business to business e-commerce, transactions, payment assistance, care, help desks FAQ and decision trees This page presents various assistants and products built and powered by Tock, some of them awarded by the community. AlloCovid \u00b6 The AlloCovid conversational service informs and guides French population about the Covid-19. It results from the collaboration of numerous French experts, tech partners and volunteers. To find out more about the project, the team and partners, how the bot works, etc. visit www.allocovid.com . Available by phone, on the Web and WhatsApp, AlloCovid builds around a Tock bot and integrates with additional technologies such as Allo-Media and Voxygen voice solutions. The AlloCovid bot is powered by open source technologies (Tock) and open source itself: its sources are available on repository allocovid . The source repository also includes the Allo-Media connector , technical details about the bot and its functional specification . Name: AlloCovid Date of birth: in production since spring 2020 Field: health information and guidance Channels: text & voice, by phone, on WhatsApp and Website OUIbot , the OUI.sncf bot \u00b6 OUIbot is the conversational assistant from OUI.sncf. Available since 2016 on Facebook Messenger, OUIbot was built along with the first versions of Tock. With OUIbot, booking a train ticket has never been easier! It assists you in the preparation of your trips, allows you to make a complete reservation quickly and easily, from research to purchase (payment included), and accompanies you during your trip. Thanks to the numerous connectors, OUIbot is now available on multiple conversational channels, such as the company Website www.oui.sncf , social networks, voice assistants, smart display and even SmartBrics with JCDecaux devices. In 2019, OUIbot answers approximately 10.000 users a day. It has been awarded Best Robot Experience for the second year in a row. Name: OUIbot Date of birth: in production since 2016 Field: e-commerce/travel, transactions (booking, payment), alerts & push notifications, push messages to an agent Channels: text & voice, on the company Website, Messenger, WhatsApp, Business Chat (Messages), Google Assistant, Google Home, Alexa, JCDecaux SmartBrics Enedis internal Chatbot \u00b6 The Enedis internal Chatbot gives the 39 000 employees a simplified means to access the company logistics services. The conversational agent provides level-1 support by answering frequent employee questions, as well as guiding them to Business service-desk tools. It also aims at better understanding employee needs through the analysis of most frequent demands. Built with Tock, the chatbot is available on an internal company Website. Name: Chatbot interne Enedis Date of birth: in production since 2020 Field: internal logistics services Channels: text, on an internal Website L'Assistant SNCF \u00b6 L' Assistant SNCF is the mobile application for SNCF passengers on Android and iOS, covering both trains and other modes of transport. With L' Assistant (the SNCF Assistant), you can plan your itinerary, stay informed in real time, buy your transport tickets directly or book a taxi ride. More features are yet to come. Accessible via the \"microphone\" in the mobile application, le SNCF Assistant's conversational bot is built with Tock plus the speech-to-text Android and iOS functions. Name: L' Assistant SNCF Date of birth: in production, featuring Tock voice function since 2019 Field: travel & transport (multi-modal route research, etc.) Channels: voice, on the SNCF mobile application for Android and iOS LinTO by Linagora \u00b6 The LinTO platform is an Open Source toolbox designed to address professional and industry needs by enabling the development and integration of voice operated processes. LinTO is a smart Open Source assistant designed by LINAGORA: based only on Open Source technologies, LinTO is cloud enabled but GAFAM-free (Google-Amazon-Facebook-Apple-Microsoft), and respects your privacy as it doesn\u2019t share your data for commercial use. LinTO is designed to reduce time-consuming & stressful tasks, using a smart AI program to understand your voice and help you all along the office day even during meetings: agenda management, reminders, notetaking, e-mails, weather forecast, traffic, words definition, newspaper headlines, etc. The research project, which is funded by the French government's PIA (for \u201cFuture Investment Program\u201d) as part of the Grands D\u00e9fis du Num\u00e9rique, is a collaboration between French companies, LINAGORA and ZELROS, and French research laboratories, IRIT, LaaS and LIX. The LinTO NLU (Natural Language Understanding) system is based on Tock to support the use of several AI models dedicated to specific use cases. It automatically learns according to one's usage when adding or removing skills from the platform. Name: LinTO Date of birth: in production, leveraging Tock since 2019 Field: Smart Business Assistant (agenda, e-mails, notetaking, etc.) Channels: voice (portability: Raspberry Pi, ARM, Android, Web...) Tilien , the Transilien chatbot \u00b6 Tilien is the Transilien chatbot on Messenger. Designed as a personal and friendly travel companion, it informs you about upcoming departures, the service status, current and future works, itineraries and much more (route plans, timetables, etc.) on the entire Ile-De-France rail network: Metro, RER, Transilien, Tram. Powered by Tock, the chatbot is waiting for you on Facebook Messenger. Name: Tilien Date of birth: in production, since 2018 with Tock Field: transport & assistance (route research, route plans, traffic conditions, etc.) Channels: text, on Messenger ( botsncftransilien ) Mon Assistant TGV INOUI \u00b6 Mon Assistant advises customers and travellers of the TGV INOUI brand before, during and after their journey. The chatbot can tell you all about the service status, train departure platforms, customer seats, onboard services (bar, electrical outlets, etc.). It also allows you to talk with a SNCF agents while remaining in the same conversation. Located on the TGV INOUI Facebook page and the WiFi Portal aboard the train, the assistant is based on Tock and the tock-react-kit . Name: Mon Assistant TGV INOUI Date of birth: in production since 2019 Field: assistance & passenger information (dock information, current travel information, on-board services), relay to an agent Channels: text, on Messenger ( TGV INOUI ) and the WiFi Portal aboard the train L' Agent virtuel SNCF \u00b6 L' Agent virtuel SNCF (SNCF Virtual Assistant) presents passenger information and any disruptions on all trains (TGV, Intercites, TER, Eurostar, etc.) in a conversational manner. Query the bot by train number, passenger file, next departures, etc. to get the latest information and traffic status. Accessible via the SNCF Facebook page, Twitter and sncf.com , the Agent virtuel leverages Tock and the tock-react-kit . Name: Agent virtuel SNCF Date of birth: in production since 2019 Field: travel & transport (traffic situation, works, next departures), relay to an agent Channels: text, on sncf.com ( direct link ), Messenger ( SNCFOFFICIEL ) and Twitter ( @sncf ) Eve , the e-voyageurs internal assistant \u00b6 Eve is the internal assistant of e-voyageurs SNCF employees. The chatbot answers common questions, refers to the right interlocutors and collaborative tools of the company, automates common requests to IT Support, General Services, Legal Department, etc. DevOps teams can also ask it for production status, next planned operations, or even to manage certain operations directly for greater simplicity and reactivity. Eve is always listening to the employees, both within the offices and on-the-go using Teams applications with Tock. Name: Eve Date of birth: in production since 2019 Field: internal & B2B support (FAQ, IT Support, HR, Legal), DevOps automation (monitoring, deployments, production management, etc.) Channels: text & voice, internally within the offices and on-the-go via Teams Other Tock bots... \u00b6 Various organizations already leverage Tock to build conversational agents, which are not mentionned here (among them, several of the TOSIT companies). Sometimes these applications are not dedicated to public usage and their organization will not communicate about them. We will mention them here when it is possible ;) Do not hesitate to look at the Gitter community chat to see professionals, students, large and smaller companies currently using or experimenting with Tock for their conversational or NLU projects. What about you? \u00b6 As a generic platform, Tock enables numerous use cases and integration of internal as well as external channels. Please feel free to contact us in case of doubts or questions about Tock features or possibilities for a new project of your own. And don't hesitate to share your achievements with the community! \ud83d\ude42","title":"Showcase"},{"location":"about/showcase/#user-showcase","text":"Since its creation for OUI.sncf in 2016 to the French AlloCovid service in 2020, Tock has been used by more and more teams (including SNCF but not only) to build conversational bots dedicated to various use cases : business to customer and business to business e-commerce, transactions, payment assistance, care, help desks FAQ and decision trees This page presents various assistants and products built and powered by Tock, some of them awarded by the community.","title":"User showcase"},{"location":"about/showcase/#allocovid","text":"The AlloCovid conversational service informs and guides French population about the Covid-19. It results from the collaboration of numerous French experts, tech partners and volunteers. To find out more about the project, the team and partners, how the bot works, etc. visit www.allocovid.com . Available by phone, on the Web and WhatsApp, AlloCovid builds around a Tock bot and integrates with additional technologies such as Allo-Media and Voxygen voice solutions. The AlloCovid bot is powered by open source technologies (Tock) and open source itself: its sources are available on repository allocovid . The source repository also includes the Allo-Media connector , technical details about the bot and its functional specification . Name: AlloCovid Date of birth: in production since spring 2020 Field: health information and guidance Channels: text & voice, by phone, on WhatsApp and Website","title":"AlloCovid"},{"location":"about/showcase/#ouibot-the-ouisncf-bot","text":"OUIbot is the conversational assistant from OUI.sncf. Available since 2016 on Facebook Messenger, OUIbot was built along with the first versions of Tock. With OUIbot, booking a train ticket has never been easier! It assists you in the preparation of your trips, allows you to make a complete reservation quickly and easily, from research to purchase (payment included), and accompanies you during your trip. Thanks to the numerous connectors, OUIbot is now available on multiple conversational channels, such as the company Website www.oui.sncf , social networks, voice assistants, smart display and even SmartBrics with JCDecaux devices. In 2019, OUIbot answers approximately 10.000 users a day. It has been awarded Best Robot Experience for the second year in a row. Name: OUIbot Date of birth: in production since 2016 Field: e-commerce/travel, transactions (booking, payment), alerts & push notifications, push messages to an agent Channels: text & voice, on the company Website, Messenger, WhatsApp, Business Chat (Messages), Google Assistant, Google Home, Alexa, JCDecaux SmartBrics","title":"OUIbot, the OUI.sncf bot"},{"location":"about/showcase/#enedis-internal-chatbot","text":"The Enedis internal Chatbot gives the 39 000 employees a simplified means to access the company logistics services. The conversational agent provides level-1 support by answering frequent employee questions, as well as guiding them to Business service-desk tools. It also aims at better understanding employee needs through the analysis of most frequent demands. Built with Tock, the chatbot is available on an internal company Website. Name: Chatbot interne Enedis Date of birth: in production since 2020 Field: internal logistics services Channels: text, on an internal Website","title":"Enedis internal Chatbot"},{"location":"about/showcase/#lassistant-sncf","text":"L' Assistant SNCF is the mobile application for SNCF passengers on Android and iOS, covering both trains and other modes of transport. With L' Assistant (the SNCF Assistant), you can plan your itinerary, stay informed in real time, buy your transport tickets directly or book a taxi ride. More features are yet to come. Accessible via the \"microphone\" in the mobile application, le SNCF Assistant's conversational bot is built with Tock plus the speech-to-text Android and iOS functions. Name: L' Assistant SNCF Date of birth: in production, featuring Tock voice function since 2019 Field: travel & transport (multi-modal route research, etc.) Channels: voice, on the SNCF mobile application for Android and iOS","title":"L'Assistant SNCF"},{"location":"about/showcase/#linto-by-linagora","text":"The LinTO platform is an Open Source toolbox designed to address professional and industry needs by enabling the development and integration of voice operated processes. LinTO is a smart Open Source assistant designed by LINAGORA: based only on Open Source technologies, LinTO is cloud enabled but GAFAM-free (Google-Amazon-Facebook-Apple-Microsoft), and respects your privacy as it doesn\u2019t share your data for commercial use. LinTO is designed to reduce time-consuming & stressful tasks, using a smart AI program to understand your voice and help you all along the office day even during meetings: agenda management, reminders, notetaking, e-mails, weather forecast, traffic, words definition, newspaper headlines, etc. The research project, which is funded by the French government's PIA (for \u201cFuture Investment Program\u201d) as part of the Grands D\u00e9fis du Num\u00e9rique, is a collaboration between French companies, LINAGORA and ZELROS, and French research laboratories, IRIT, LaaS and LIX. The LinTO NLU (Natural Language Understanding) system is based on Tock to support the use of several AI models dedicated to specific use cases. It automatically learns according to one's usage when adding or removing skills from the platform. Name: LinTO Date of birth: in production, leveraging Tock since 2019 Field: Smart Business Assistant (agenda, e-mails, notetaking, etc.) Channels: voice (portability: Raspberry Pi, ARM, Android, Web...)","title":"LinTO by Linagora"},{"location":"about/showcase/#tilien-the-transilien-chatbot","text":"Tilien is the Transilien chatbot on Messenger. Designed as a personal and friendly travel companion, it informs you about upcoming departures, the service status, current and future works, itineraries and much more (route plans, timetables, etc.) on the entire Ile-De-France rail network: Metro, RER, Transilien, Tram. Powered by Tock, the chatbot is waiting for you on Facebook Messenger. Name: Tilien Date of birth: in production, since 2018 with Tock Field: transport & assistance (route research, route plans, traffic conditions, etc.) Channels: text, on Messenger ( botsncftransilien )","title":"Tilien, the Transilien chatbot"},{"location":"about/showcase/#mon-assistant-tgv-inoui","text":"Mon Assistant advises customers and travellers of the TGV INOUI brand before, during and after their journey. The chatbot can tell you all about the service status, train departure platforms, customer seats, onboard services (bar, electrical outlets, etc.). It also allows you to talk with a SNCF agents while remaining in the same conversation. Located on the TGV INOUI Facebook page and the WiFi Portal aboard the train, the assistant is based on Tock and the tock-react-kit . Name: Mon Assistant TGV INOUI Date of birth: in production since 2019 Field: assistance & passenger information (dock information, current travel information, on-board services), relay to an agent Channels: text, on Messenger ( TGV INOUI ) and the WiFi Portal aboard the train","title":"Mon Assistant TGV INOUI"},{"location":"about/showcase/#l-agent-virtuel-sncf","text":"L' Agent virtuel SNCF (SNCF Virtual Assistant) presents passenger information and any disruptions on all trains (TGV, Intercites, TER, Eurostar, etc.) in a conversational manner. Query the bot by train number, passenger file, next departures, etc. to get the latest information and traffic status. Accessible via the SNCF Facebook page, Twitter and sncf.com , the Agent virtuel leverages Tock and the tock-react-kit . Name: Agent virtuel SNCF Date of birth: in production since 2019 Field: travel & transport (traffic situation, works, next departures), relay to an agent Channels: text, on sncf.com ( direct link ), Messenger ( SNCFOFFICIEL ) and Twitter ( @sncf )","title":"L' Agent virtuel SNCF"},{"location":"about/showcase/#eve-the-e-voyageurs-internal-assistant","text":"Eve is the internal assistant of e-voyageurs SNCF employees. The chatbot answers common questions, refers to the right interlocutors and collaborative tools of the company, automates common requests to IT Support, General Services, Legal Department, etc. DevOps teams can also ask it for production status, next planned operations, or even to manage certain operations directly for greater simplicity and reactivity. Eve is always listening to the employees, both within the offices and on-the-go using Teams applications with Tock. Name: Eve Date of birth: in production since 2019 Field: internal & B2B support (FAQ, IT Support, HR, Legal), DevOps automation (monitoring, deployments, production management, etc.) Channels: text & voice, internally within the offices and on-the-go via Teams","title":"Eve, the e-voyageurs internal assistant"},{"location":"about/showcase/#other-tock-bots","text":"Various organizations already leverage Tock to build conversational agents, which are not mentionned here (among them, several of the TOSIT companies). Sometimes these applications are not dedicated to public usage and their organization will not communicate about them. We will mention them here when it is possible ;) Do not hesitate to look at the Gitter community chat to see professionals, students, large and smaller companies currently using or experimenting with Tock for their conversational or NLU projects.","title":"Other Tock bots..."},{"location":"about/showcase/#what-about-you","text":"As a generic platform, Tock enables numerous use cases and integration of internal as well as external channels. Please feel free to contact us in case of doubts or questions about Tock features or possibilities for a new project of your own. And don't hesitate to share your achievements with the community! \ud83d\ude42","title":"What about you?"},{"location":"about/why/","text":"Why Tock? \u00b6 Created in 2016 by the OUI.sncf Innovation team to implement voice-command on its mobile applications , the framework has then been used to create the Messenger chatbot , before being extended to support numerous channels and other bots with more use cases. At first the platform showed results, similar to other available solutions on the market, while keeping the code in control (relying on opensource libraries and academic solutions) and preventing \"black box\" effects (eg. debugging conversational models) for more reactive agility. Since then, the team behind OUIbot as well as other teams, dedicated to various conversational assistants at SNCF (see the showcase ) use Tock every day in production and add new features and connectors to the platform on a regular basis. We are convinced there is a need for open AI and conversational platforms , enabling various technical and business cases while keeping the code in control and the ownership of models and data . More and more partners and third-parties, small and big companies in France and worldwide, share this vision and requirement for their own projects. The complete Tock solution is shared with the community in order to federate and mutualize efforts from assistant builders. Starting 2019, Tock is a recommended solution at Group SNCF. Several other companies leverage Tock in production (see showcase ). Eventually, we believe that Tock should join an Open Source organization, such as the TOSIT (The Open Source I Trust) association or an Open Source foundation or consortium.","title":"Why Tock"},{"location":"about/why/#why-tock","text":"Created in 2016 by the OUI.sncf Innovation team to implement voice-command on its mobile applications , the framework has then been used to create the Messenger chatbot , before being extended to support numerous channels and other bots with more use cases. At first the platform showed results, similar to other available solutions on the market, while keeping the code in control (relying on opensource libraries and academic solutions) and preventing \"black box\" effects (eg. debugging conversational models) for more reactive agility. Since then, the team behind OUIbot as well as other teams, dedicated to various conversational assistants at SNCF (see the showcase ) use Tock every day in production and add new features and connectors to the platform on a regular basis. We are convinced there is a need for open AI and conversational platforms , enabling various technical and business cases while keeping the code in control and the ownership of models and data . More and more partners and third-parties, small and big companies in France and worldwide, share this vision and requirement for their own projects. The complete Tock solution is shared with the community in order to federate and mutualize efforts from assistant builders. Starting 2019, Tock is a recommended solution at Group SNCF. Several other companies leverage Tock in production (see showcase ). Eventually, we believe that Tock should join an Open Source organization, such as the TOSIT (The Open Source I Trust) association or an Open Source foundation or consortium.","title":"Why Tock?"},{"location":"dev/bot-api/","text":"Tock Bot API Mode \u00b6 This is the recommended way to start developing stories with Tock. Kotlin , Javascript and Python clients are available. Any programing language can be used, leveraging the Tock Bot API . Connect to the demo platform \u00b6 Rather than deploying its own Tock platform, it is possible to test the WebSocket or Webhook modes directly on the Tock demo platform . Develop with Kotlin \u00b6 Enable WebSocket mode \u00b6 This is the preferred mode at startup, requiring no additional tunnel / setup. To use the WebSocket client, add the tock-bot-api-websocket dependency to your Kotlin application / project. Using Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-websocket </artifactId> <version> 20.9.2-1 </version> </dependency> Or Gradle : compile 'ai.tock:tock-bot-api-websocket:20.9.2-1' Enable WebHook mode \u00b6 Alternatively, you can choose to use the WebHook client. Add the tock-bot-api-webhook dependency to your Kotlin application / project. Using Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-webhook </artifactId> <version> 20.9.2-1 </version> </dependency> Or Gradle : compile 'ai.tock:tock-bot-api-webhook:20.9.2-1' In this case, unlike the WebSocket mode, the bot application must be reachable by the Tock platform and so has to expose a public URL (you can use ngrok in order to provide this URL). This URL must be specified in the webhook url field in the Configuration > Bot Configurations view of Tock Studio . Note that the WebHook mode may require the setup of a secure tunnel to the Bot API running client. As a matter of fact, the client may not be reachable from the server. For development, tools like ngrok may help. Set up the API key \u00b6 In Tock Studio , after configuring a bot, go to Configuration > Bot Configurations and copy the API key of the bot to which you want to connect. You can enter / paste this key into the Kotlin code (see below). Create Stories \u00b6 The following formats are supported: Text with Buttons (Quick Replies) \"Card\" format \"Carousel\" format Specific channel formats like Messenger format, Slack format, etc. Here is a simple bot with a few stories: fun main () { startWithDemo ( newBot ( \"PUT-YOUR-TOCK-APP-API-KEY-HERE\" , // Get your app API key from Bot Configurations in Tock Studio newStory ( \"greetings\" ) { // Intent 'greetings' end ( \"Hello!\" ) // Raw text answer }, newStory ( \"location\" ) { // Intent 'location' end ( // Anwser with a card - including text, file(image, video,..) and user action suggestions newCard ( \"Card title\" , \"Card sub title\" , newAttachment ( \"https://url-image.png\" ), newAction ( \"Action 1\" ), newAction ( \"Action 2\" , \"http://redirection\" ) ) ) }, newStory ( \"goodbye\" ) { // Intent 'goodbye' end { // Answer with Messenger-specific button/quick reply buttonsTemplate ( \"Are you sure ?\" , nlpQuickReply ( \"Stay here\" )) } }, // Fallback answer when the bot does find a correct response unknownStory { end ( \"Sorry I don't understand :(\" ) } ) ) } Please consult the full source code sample . Develop with Javascript \u00b6 A Nodejs client is available to program Tock stories in Javascript. Please visit the tock-node repository and documentation. Develop with Python \u00b6 A client is available to program Tock stories in Python . Please visit the tock-py repository and documentation. Develop through the API \u00b6 It is possible to develop in the language of your choice by using directly the underlying REST API . Install Bot API server-side \u00b6 To use Tock's Bot API mode without the demo platform, a specific module must be deployed on your own server. Called bot-api in Docker Compose descriptors, this service: Expose the Bot API to the potential customers whatever their programming language are. Accept WebSocket connections and / or connections to the configured webhook. Compared to the \"demo mode\", The only required change in the code is to replace the startWithDemo method with the start one, specifying the bot-api target server address.","title":"Bot API mode"},{"location":"dev/bot-api/#tock-bot-api-mode","text":"This is the recommended way to start developing stories with Tock. Kotlin , Javascript and Python clients are available. Any programing language can be used, leveraging the Tock Bot API .","title":"Tock Bot API Mode"},{"location":"dev/bot-api/#connect-to-the-demo-platform","text":"Rather than deploying its own Tock platform, it is possible to test the WebSocket or Webhook modes directly on the Tock demo platform .","title":"Connect to the demo platform"},{"location":"dev/bot-api/#develop-with-kotlin","text":"","title":"Develop with Kotlin"},{"location":"dev/bot-api/#enable-websocket-mode","text":"This is the preferred mode at startup, requiring no additional tunnel / setup. To use the WebSocket client, add the tock-bot-api-websocket dependency to your Kotlin application / project. Using Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-websocket </artifactId> <version> 20.9.2-1 </version> </dependency> Or Gradle : compile 'ai.tock:tock-bot-api-websocket:20.9.2-1'","title":"Enable WebSocket mode"},{"location":"dev/bot-api/#enable-webhook-mode","text":"Alternatively, you can choose to use the WebHook client. Add the tock-bot-api-webhook dependency to your Kotlin application / project. Using Maven : <dependency> <groupId> ai.tock </groupId> <artifactId> tock-bot-api-webhook </artifactId> <version> 20.9.2-1 </version> </dependency> Or Gradle : compile 'ai.tock:tock-bot-api-webhook:20.9.2-1' In this case, unlike the WebSocket mode, the bot application must be reachable by the Tock platform and so has to expose a public URL (you can use ngrok in order to provide this URL). This URL must be specified in the webhook url field in the Configuration > Bot Configurations view of Tock Studio . Note that the WebHook mode may require the setup of a secure tunnel to the Bot API running client. As a matter of fact, the client may not be reachable from the server. For development, tools like ngrok may help.","title":"Enable WebHook mode"},{"location":"dev/bot-api/#set-up-the-api-key","text":"In Tock Studio , after configuring a bot, go to Configuration > Bot Configurations and copy the API key of the bot to which you want to connect. You can enter / paste this key into the Kotlin code (see below).","title":"Set up the API key"},{"location":"dev/bot-api/#create-stories","text":"The following formats are supported: Text with Buttons (Quick Replies) \"Card\" format \"Carousel\" format Specific channel formats like Messenger format, Slack format, etc. Here is a simple bot with a few stories: fun main () { startWithDemo ( newBot ( \"PUT-YOUR-TOCK-APP-API-KEY-HERE\" , // Get your app API key from Bot Configurations in Tock Studio newStory ( \"greetings\" ) { // Intent 'greetings' end ( \"Hello!\" ) // Raw text answer }, newStory ( \"location\" ) { // Intent 'location' end ( // Anwser with a card - including text, file(image, video,..) and user action suggestions newCard ( \"Card title\" , \"Card sub title\" , newAttachment ( \"https://url-image.png\" ), newAction ( \"Action 1\" ), newAction ( \"Action 2\" , \"http://redirection\" ) ) ) }, newStory ( \"goodbye\" ) { // Intent 'goodbye' end { // Answer with Messenger-specific button/quick reply buttonsTemplate ( \"Are you sure ?\" , nlpQuickReply ( \"Stay here\" )) } }, // Fallback answer when the bot does find a correct response unknownStory { end ( \"Sorry I don't understand :(\" ) } ) ) } Please consult the full source code sample .","title":"Create Stories"},{"location":"dev/bot-api/#develop-with-javascript","text":"A Nodejs client is available to program Tock stories in Javascript. Please visit the tock-node repository and documentation.","title":"Develop with Javascript"},{"location":"dev/bot-api/#develop-with-python","text":"A client is available to program Tock stories in Python . Please visit the tock-py repository and documentation.","title":"Develop with Python"},{"location":"dev/bot-api/#develop-through-the-api","text":"It is possible to develop in the language of your choice by using directly the underlying REST API .","title":"Develop through the API"},{"location":"dev/bot-api/#install-bot-api-server-side","text":"To use Tock's Bot API mode without the demo platform, a specific module must be deployed on your own server. Called bot-api in Docker Compose descriptors, this service: Expose the Bot API to the potential customers whatever their programming language are. Accept WebSocket connections and / or connections to the configured webhook. Compared to the \"demo mode\", The only required change in the code is to replace the startWithDemo method with the start one, specifying the bot-api target server address.","title":"Install Bot API server-side"},{"location":"dev/connectors/","text":"Tock Connectors \u00b6 Introduction \u00b6 Tock connectors integrate bots with various text/voice channels. Beside the test connector used by Tock Studio internally, connectors refer to channels, external to the Tock platform. The Tock connector architecture makes it possible to build conversational assistants, loosely coupled to the channels they are exposed to. One can first build a bot for a given channel, then make it a multichannel bot by adding connectors. The Web connector exposes a generic API to interact with a Tock bot. As a consequence, more integrations are possible on the \"frontend\" by leveraging this API as a gateway. This page actually lists: The connectors provided with Tock: Available toolkits leveraging the Web connector to integrate with more channels: Voice technologies possible to integrate with Tock: Connectors provided with Tock \u00b6 Many connectors are provided with Tock for various types of text/voice external channels. New connectors are regularly added to the platform, depending on user project needs and availability of new messaging channels. Examples: Google Home arriving in France in 2017, Alexa in 2018, WhatsApp then Business Chat APIs opened in 2019, etc. To find, which bot leverages which connector in production, please refer to the Tock user showcase page. Messenger \u00b6 Channel : Facebook Messenger Type : text (+ voice through voice recording upload) Status : Tock connector in production since 2016 Please refer to connector-messenger for sources and README instructions. Slack \u00b6 Channel : Slack Type : text Status : Tock connector not used for production (no use case yet) Please refer to connector-slack for sources and README instructions. Google Assistant / Home \u00b6 Channel : Google Assistant / Google Home Type : text + voice Status : Tock connector in production since 2017 Please refer to connector-ga for sources and README instructions. Alexa / Echo \u00b6 Channel : Amazon Alexa / Amazon Echo Type : voice Status : Tock connector in production since 2018 Important : please note that the NLP model for Alexa is necessarily built and managed by Amazon online services. Only the conversational framework can be used from Tock. Please refer to connector-alexa for sources and README instructions. Rocket.Chat \u00b6 Channel : Rocket.Chat Type : text Status : to be precised Please refer to connector-rocketchat for sources and README instructions. WhatsApp \u00b6 Channel : WhatsApp from Facebook Type : text Status : Tock connector in production since 2019 Please refer to connector-whatsapp for sources and README instructions. Teams \u00b6 Channel : Microsoft Teams Type : text + voice Status : Tock connector in production since 2019 Please refer to connector-teams for sources and README instructions. Business Chat \u00b6 Channel : Apple Business Chat (Messages) Type : text Status : Tock connector in production since 2019 Please refer to connector-businesschat for sources and README instructions. Twitter \u00b6 Channel : Twitter (messages priv\u00e9s) Type : text Status : Tock connector in production since 2019 Please refer to connector-twitter for sources and README instructions. Allo-Media \u00b6 Channel : Allo-Media (t\u00e9l\u00e9phonie) Type : voice Status : Tock connector in production since 2020 This connector has been developped for the French AlloCovid bot. To know more, please check the AlloMediaConnector class and the bot sources also on GitHub. Google Chat \u00b6 Channel : Google Chat (aka Google Hangouts) Type : text Status : Tock connector not used for production (no use case yet) Please refer to connector-google-chat for sources and README instructions. Web (generic) \u00b6 This generic connector integrates Tock bots with Web sites or applications: portals, dedicated sites, apps, REST clients, etc. The connector exposes a REST API to the bot, making it easy to integrate with any Website, mobile application or programming language. Several toolkits and components consuming the Web connector API are already available to integrate Tock bots with more types of sites and applications, such as Websites with React , mobile-native applications with Flutter and intranet sites on SharePoint . Channel : Web (generic for any Web site or application) Type : text Status : Tock connector in production since 2020 Please refer to connector-web for sources and README instructions, including samples and the Swagger documentation for the REST API. Test (generic) \u00b6 This Tock-internal connector allows to talk to a bot directly from the Tock Studio interface ( Test > Test the bot ) and emulates other connectors. Integrations through the Web connector \u00b6 The Web connector exposes a generic API to interact with a bot. As a consequence, more integrations are possible on the \"frontend\", by consuming the API as a gateway to the bot. React \u00b6 This React component integrates and renders a Tock bot inside a Web application or site. The Webapp communicates with the bot through a Web connector . Integration : React (JavaScript / JSX) Type : Web applications Status : in production since 2020 Please refer to tock-react-kit for sources and README instructions. Flutter (beta) \u00b6 This Flutter component integrates and renders a Tock bot inside a mobile or Web application. The application communicates with the bot through a Web connector . Integration : Flutter (Dart) Type : mobile-native or Web applications Status : beta, in development Please refer to tock-flutter-kit for sources and README instructions. SharePoint (beta) \u00b6 This WebPart component integrates and renders a Tock bot inside a SharePoint page/site. The component embeds the tock-react-kit to communicate with the bot through a Web connector and render the bot inside the SharePoint page. Integration : Microsoft SharePoint Type : Web & intranet sites Status : beta, in development Please refer to tock-sharepoint for sources and README instructions. Voice Technologies \u00b6 Tock bots merely process text sentences by default. Nevertheless, voice and speech technologies can be leveraged around the bot to achieve voice dialogs (namely voicebots and callbots): Translating Speech-To-Text before bot processing (ie. before NLU ) Translating Text-To-Speech after bot processing (ie. synthesis speech from bot answer) Some of the provided connectors integrate with external channels, capable of STT and TTS. More voice technologies have been integrated with Tock over time, even when no ready-to-use connector is provided. Google / Android \u00b6 Google Speech-To-Text and Text-To-Speech features are used by the Google Assistant / Home connector , the microphone feature from the Microsoft Teams app for Android compatible with the Teams connector , as well as the Android platform for mobile-native development. Technologie : Google / Android STT & TTS Status : used with Tock in production (through Google Assistant / Home and Microsoft Teams connectors, as well as native Android for on-app mobile bots) Apple / iOS \u00b6 Apple Speech-To-Text and Text-To-Speech features are used by the Business Chat connector , as well as the iOS platform for mobile-native development. Technologie : Apple / iOS STT & TTS Status : used with Tock in production (though Business Chat connector and native iOS for on-app mobile bots) Amazon / Alexa \u00b6 Technologie : Amazon / Alexa STT & TTS Status : used with Tock in production (through Alexa connector) Allo-Media & Voxygen \u00b6 To build the French AlloCovid bot, an Allo-Media connector has been developped, to integrate the Tock bot with Allo-Media services: Speech-To-Text (from phone speech) and Text-To-Speech (leveraging Voxygen synthesis voices). Technologie : Allo-Media & Voxygen Status : used with Tock in production (though Allo-Media connector ) Nuance \u00b6 Nuance propose des solutions de reconnaissance vocale & IA. Back in 2016 for voice command usages, Nuance was successfully integrated with Tock for its Speech-To-Text features. Technologie : Nuance Status : used with Tock in 2016 Define your own connector \u00b6 It is possible to develop its own connector. An example of custom connector can be seen in the Bot Open Data sample project . To develop your own, follow these steps: 1) Implement the interface Connector Here is an example of implementation: val testConnectorType = ConnectorType ( \"test\" ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router -> //main API router . post ( \"$path/message\" ). blockingHandler { context -> //ConnectorRequest is my business object passed by the front app val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //business object mapped to Tock event val event = readUserMessage ( message ) //we pass the Tock event to the framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //we record the action callback . actions . add ( event ) //if it's the last action to send, send the answer if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { \"unsupported event: $event\" } } } } // to retrieve all actions before sending class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList < Action > = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //we transform the list of Tock responses into a business response val response = mapper . writeValueAsString ( actions . map {...}) //then we send the answer context . response (). end ( response ) } } 2) Implement the interface ConnectorProvider Here is an example of implementation: object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Make this connector available via a Service Loader By placing a file META-INF/services/ai.tock.bot.connector.ConnectorProvider in the classpath, containing the class name : mypackage . TestConnectorProviderService 4) Add all classes and files created in the admin classpath and bot classpath The new connector must then be available in the \"Bot Configurations\" administration interface.","title":"Connectors"},{"location":"dev/connectors/#tock-connectors","text":"","title":"Tock Connectors"},{"location":"dev/connectors/#introduction","text":"Tock connectors integrate bots with various text/voice channels. Beside the test connector used by Tock Studio internally, connectors refer to channels, external to the Tock platform. The Tock connector architecture makes it possible to build conversational assistants, loosely coupled to the channels they are exposed to. One can first build a bot for a given channel, then make it a multichannel bot by adding connectors. The Web connector exposes a generic API to interact with a Tock bot. As a consequence, more integrations are possible on the \"frontend\" by leveraging this API as a gateway. This page actually lists: The connectors provided with Tock: Available toolkits leveraging the Web connector to integrate with more channels: Voice technologies possible to integrate with Tock:","title":"Introduction"},{"location":"dev/connectors/#connectors-provided-with-tock","text":"Many connectors are provided with Tock for various types of text/voice external channels. New connectors are regularly added to the platform, depending on user project needs and availability of new messaging channels. Examples: Google Home arriving in France in 2017, Alexa in 2018, WhatsApp then Business Chat APIs opened in 2019, etc. To find, which bot leverages which connector in production, please refer to the Tock user showcase page.","title":"Connectors provided with Tock"},{"location":"dev/connectors/#messenger","text":"Channel : Facebook Messenger Type : text (+ voice through voice recording upload) Status : Tock connector in production since 2016 Please refer to connector-messenger for sources and README instructions.","title":"Messenger"},{"location":"dev/connectors/#slack","text":"Channel : Slack Type : text Status : Tock connector not used for production (no use case yet) Please refer to connector-slack for sources and README instructions.","title":"Slack"},{"location":"dev/connectors/#google-assistant-home","text":"Channel : Google Assistant / Google Home Type : text + voice Status : Tock connector in production since 2017 Please refer to connector-ga for sources and README instructions.","title":"Google Assistant / Home"},{"location":"dev/connectors/#alexa-echo","text":"Channel : Amazon Alexa / Amazon Echo Type : voice Status : Tock connector in production since 2018 Important : please note that the NLP model for Alexa is necessarily built and managed by Amazon online services. Only the conversational framework can be used from Tock. Please refer to connector-alexa for sources and README instructions.","title":"Alexa / Echo"},{"location":"dev/connectors/#rocketchat","text":"Channel : Rocket.Chat Type : text Status : to be precised Please refer to connector-rocketchat for sources and README instructions.","title":"Rocket.Chat"},{"location":"dev/connectors/#whatsapp","text":"Channel : WhatsApp from Facebook Type : text Status : Tock connector in production since 2019 Please refer to connector-whatsapp for sources and README instructions.","title":"WhatsApp"},{"location":"dev/connectors/#teams","text":"Channel : Microsoft Teams Type : text + voice Status : Tock connector in production since 2019 Please refer to connector-teams for sources and README instructions.","title":"Teams"},{"location":"dev/connectors/#business-chat","text":"Channel : Apple Business Chat (Messages) Type : text Status : Tock connector in production since 2019 Please refer to connector-businesschat for sources and README instructions.","title":"Business Chat"},{"location":"dev/connectors/#twitter","text":"Channel : Twitter (messages priv\u00e9s) Type : text Status : Tock connector in production since 2019 Please refer to connector-twitter for sources and README instructions.","title":"Twitter"},{"location":"dev/connectors/#allo-media","text":"Channel : Allo-Media (t\u00e9l\u00e9phonie) Type : voice Status : Tock connector in production since 2020 This connector has been developped for the French AlloCovid bot. To know more, please check the AlloMediaConnector class and the bot sources also on GitHub.","title":"Allo-Media"},{"location":"dev/connectors/#google-chat","text":"Channel : Google Chat (aka Google Hangouts) Type : text Status : Tock connector not used for production (no use case yet) Please refer to connector-google-chat for sources and README instructions.","title":"Google Chat"},{"location":"dev/connectors/#web-generic","text":"This generic connector integrates Tock bots with Web sites or applications: portals, dedicated sites, apps, REST clients, etc. The connector exposes a REST API to the bot, making it easy to integrate with any Website, mobile application or programming language. Several toolkits and components consuming the Web connector API are already available to integrate Tock bots with more types of sites and applications, such as Websites with React , mobile-native applications with Flutter and intranet sites on SharePoint . Channel : Web (generic for any Web site or application) Type : text Status : Tock connector in production since 2020 Please refer to connector-web for sources and README instructions, including samples and the Swagger documentation for the REST API.","title":"Web (generic)"},{"location":"dev/connectors/#test-generic","text":"This Tock-internal connector allows to talk to a bot directly from the Tock Studio interface ( Test > Test the bot ) and emulates other connectors.","title":"Test (generic)"},{"location":"dev/connectors/#integrations-through-the-web-connector","text":"The Web connector exposes a generic API to interact with a bot. As a consequence, more integrations are possible on the \"frontend\", by consuming the API as a gateway to the bot.","title":"Integrations through the Web connector"},{"location":"dev/connectors/#react","text":"This React component integrates and renders a Tock bot inside a Web application or site. The Webapp communicates with the bot through a Web connector . Integration : React (JavaScript / JSX) Type : Web applications Status : in production since 2020 Please refer to tock-react-kit for sources and README instructions.","title":"React"},{"location":"dev/connectors/#flutter-beta","text":"This Flutter component integrates and renders a Tock bot inside a mobile or Web application. The application communicates with the bot through a Web connector . Integration : Flutter (Dart) Type : mobile-native or Web applications Status : beta, in development Please refer to tock-flutter-kit for sources and README instructions.","title":"Flutter (beta)"},{"location":"dev/connectors/#sharepoint-beta","text":"This WebPart component integrates and renders a Tock bot inside a SharePoint page/site. The component embeds the tock-react-kit to communicate with the bot through a Web connector and render the bot inside the SharePoint page. Integration : Microsoft SharePoint Type : Web & intranet sites Status : beta, in development Please refer to tock-sharepoint for sources and README instructions.","title":"SharePoint (beta)"},{"location":"dev/connectors/#voice-technologies","text":"Tock bots merely process text sentences by default. Nevertheless, voice and speech technologies can be leveraged around the bot to achieve voice dialogs (namely voicebots and callbots): Translating Speech-To-Text before bot processing (ie. before NLU ) Translating Text-To-Speech after bot processing (ie. synthesis speech from bot answer) Some of the provided connectors integrate with external channels, capable of STT and TTS. More voice technologies have been integrated with Tock over time, even when no ready-to-use connector is provided.","title":"Voice Technologies"},{"location":"dev/connectors/#google-android","text":"Google Speech-To-Text and Text-To-Speech features are used by the Google Assistant / Home connector , the microphone feature from the Microsoft Teams app for Android compatible with the Teams connector , as well as the Android platform for mobile-native development. Technologie : Google / Android STT & TTS Status : used with Tock in production (through Google Assistant / Home and Microsoft Teams connectors, as well as native Android for on-app mobile bots)","title":"Google / Android"},{"location":"dev/connectors/#apple-ios","text":"Apple Speech-To-Text and Text-To-Speech features are used by the Business Chat connector , as well as the iOS platform for mobile-native development. Technologie : Apple / iOS STT & TTS Status : used with Tock in production (though Business Chat connector and native iOS for on-app mobile bots)","title":"Apple / iOS"},{"location":"dev/connectors/#amazon-alexa","text":"Technologie : Amazon / Alexa STT & TTS Status : used with Tock in production (through Alexa connector)","title":"Amazon / Alexa"},{"location":"dev/connectors/#allo-media-voxygen","text":"To build the French AlloCovid bot, an Allo-Media connector has been developped, to integrate the Tock bot with Allo-Media services: Speech-To-Text (from phone speech) and Text-To-Speech (leveraging Voxygen synthesis voices). Technologie : Allo-Media & Voxygen Status : used with Tock in production (though Allo-Media connector )","title":"Allo-Media &amp; Voxygen"},{"location":"dev/connectors/#nuance","text":"Nuance propose des solutions de reconnaissance vocale & IA. Back in 2016 for voice command usages, Nuance was successfully integrated with Tock for its Speech-To-Text features. Technologie : Nuance Status : used with Tock in 2016","title":"Nuance"},{"location":"dev/connectors/#define-your-own-connector","text":"It is possible to develop its own connector. An example of custom connector can be seen in the Bot Open Data sample project . To develop your own, follow these steps: 1) Implement the interface Connector Here is an example of implementation: val testConnectorType = ConnectorType ( \"test\" ) class TestConnector ( val applicationId : String , val path : String ) : Connector { override val connectorType : ConnectorType = testConnectorType override fun register ( controller : ConnectorController ) { controller . registerServices ( path ) { router -> //main API router . post ( \"$path/message\" ). blockingHandler { context -> //ConnectorRequest is my business object passed by the front app val message : ConnectorRequest = mapper . readValue ( context . bodyAsString ) //business object mapped to Tock event val event = readUserMessage ( message ) //we pass the Tock event to the framework val callback = TestConnectorCallback ( applicationId , message . userId , context , controller ) controller . handle ( event , ConnectorData ( callback )) } } } override fun send ( event : Event , callback : ConnectorCallback , delayInMs : Long ) { callback as TestConnectorCallback if ( event is Action ) { //we record the action callback . actions . add ( event ) //if it's the last action to send, send the answer if ( event . metadata . lastAnswer ) { callback . sendAnswer () } } else { logger . trace { \"unsupported event: $event\" } } } } // to retrieve all actions before sending class TestConnectorCallback ( override val applicationId : String , val userId : String , val context : RoutingContext , val controller : ConnectorController , val actions : MutableList < Action > = CopyOnWriteArrayList ()): ConnectorCallbackBase ( applicationId , testConnectorType ) { internal fun sendAnswer () { //we transform the list of Tock responses into a business response val response = mapper . writeValueAsString ( actions . map {...}) //then we send the answer context . response (). end ( response ) } } 2) Implement the interface ConnectorProvider Here is an example of implementation: object TestConnectorProvider : ConnectorProvider { override val connectorType : ConnectorType = testConnectorType override fun connector ( connectorConfiguration : ConnectorConfiguration ): Connector { return TestConnector ( connectorConfiguration . connectorId , connectorConfiguration . path ) } } class TestConnectorProviderService : ConnectorProvider by TestConnectorProvider 3) Make this connector available via a Service Loader By placing a file META-INF/services/ai.tock.bot.connector.ConnectorProvider in the classpath, containing the class name : mypackage . TestConnectorProviderService 4) Add all classes and files created in the admin classpath and bot classpath The new connector must then be available in the \"Bot Configurations\" administration interface.","title":"Define your own connector"},{"location":"dev/integrated-bot/","text":"Integrated Bot Mode \u00b6 To develop a bot or an assistant with Tock, you can also use the so called Integrated mode developed in Kotlin . You get then direct access to the MongoDb database. This mode is not available in the demo platform - you need to install the Tock docker images on your own servers. Sample Project \u00b6 A sample bot using Tock Integrated mode is provided: https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit. Docker Images \u00b6 Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker . Start the NLP stack \u00b6 #get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password . Sample bot based on Open Data APIs \u00b6 A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images . Develop a new Bot \u00b6 Add the bot-toolkit Dependency \u00b6 The bot-toolkit dependency is required: With Maven: <dependency> <groupId> ai.tock </groupId> <artifactId> bot-toolkit </artifactId> <version> 20.9.2-1 </version> </dependency> With Gradle: compile 'ai.tock:bot-toolkit:20.9.2-1' A Bot is a Set of Stories \u00b6 This is how the open data bot is defined: val openBot = bot ( \"bot_open_data\" , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) This bot has an unique identifier (required - \"bot_open_data\") and a list of \"Story\" . A Story is a functional subset that has a main intention and, optionally, one or more so-called \"secondary\" intentions. Here the bot defines 4 Stories , greetings, departures, arrivals and search. Greetings is also set ( hello = greetings ) as the default story used for a new dialog. A Simple Story \u00b6 How do you define a story? Here is a first simplified version of the story greetings : val greetings = story ( \"greetings\" ) { send ( \"Welcome to the Tock Open Data Bot! :)\" ) end ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } Note that in the body of the function, this has a BotBus type. From which you can interact with the user, and which also allows you to access to all available contextual elements. When the intention greetings will be detected by the NLP model, the function above will be called by the Tock framework. The bot sends successively a first response sentence ( bus.send() ), then a second one indicating that it is the last sentence of his answer using a bus.end() . Here is the full version of greetings : val greetings = story ( \"greetings\" ) { //cleanup state resetDialogState () send ( \"Welcome to the Tock Open Data Bot! :)\" ) send ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) withMessenger { buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) } withGoogleAssistant { gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) } end () } Two notions have been added: resetDialogState() which cleanup the state (forgetting any previous context). the withMessenger{} and withGoogleAssistant{} methods that define specific responses for each connector - Here it's a text with buttons for Messenger, and a text with suggestions for Google Assistant. Start and Connect the Bot \u00b6 To start the bot, simply add the following call to your main function: registerAndInstallBot ( openBot ) where the openBot variable is the bot you originally defined. When the bot is started, you also need to specify which connectors are used in the web administration interface: Configuration -> Bot Configurations -> Create a new configuration See Connectors page for the list of available connectors. Import configuration (dumps) \u00b6 It is possible to export various types of configurations from Tock Studio, then import them programmatically at bot startup. Once the dump files exported to the bot classpath , you can use one or more of the following functions from the bot main : importApplicationDump : import an application from an application dump ( Tock Studio > Settings > Applications ). Note that import is skipped when application exists already. importNlpDump : import a NLP model (intents, sentences, entities) from a NLP dump ( Tock Studio > Settings > Applications ). importI18nDump : import labels (aka i18n ) from a labels dump ( Tock Studio > Stories & Answers > Answers ). Example: fun main ( args : Array < String >) { registerAndInstallBot ( bot ) // Import application importApplicationDump ( \"/bot_app_dump.json\" ) // Import NLP model (intents, sentences, entities...) importNlpDump ( \"/bot_nlp_dump.json\" ) // Import story labels (aka i18n) importI18nDump ( \"/bot_labels_dump.json\" ) } Advanced options \u00b6 Of course, the StoryHandler of greetings does not depend on the context: the answer is always the same. Secondary Intentions \u00b6 Here is the beginning of the definition of the search story : val search = storyDef < SearchDef >( \"search\" , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } The story search defines a secondary starter intent ( indicate_origin ) and a simple secondary intent ( indicate_location ). A secondary starter intent is similar in every respect to the main intent: as soon as the intent is detected, if the current story does not contain indicate_origin as secondary intent, the story search is called. For a classic secondary intent, on the other hand, the story will be executed only if the current story of the context is already the search story. Different stories can therefore share the same secondary intents. Handle Entities \u00b6 To retrieve entity values, it is good practice to define Kotlin extensions . For example here is the code used to retrieve the destination entity: val destinationEntity = openBot . entity ( \"location\" , \"destination\" ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) An entity of type \"location\" and role \"destination\" is created. There is a corresponding entity in the NLP model. A variable destination is defined, which will simplify the handling of this entity in the conversational code. This variable contains the current value of the destination in the user context. Here's a full version of the search story that uses destination : val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } If there is no value in the current context for the destination, the bot asks to specify the destination and stays there. Same behaviour for the origin or date of departure. If the 3 required values are specified, then the real answer developed in the SearchDef class is used. Here is the full version of this first part of the code: val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) && location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } In the case where the detected intention is indicate_location , we do not know if the locality represents the origin or the destination. A simple rule is then used: If there is already in the context an origin and no destination, the new locality is actually the destination. Otherwise, it is the origin. HandlerDef \u00b6 In the search story above, you may have noted the generic SearchDef typing. Here is the code of this class: @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef < SearchConnector >( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( \"From {0} to {1}\" , o , d ) send ( \"Departure on {0}\" , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( \"Sorry, no routes found :(\" ) } else { send ( \"Here is the first proposal:\" ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef extends HandlerDef which is an alias of a Tock framework class. It is usually here that the code of complex stories is defined. The code contains an additional abstraction: SearchConnector . SearchConnector is the class that defines the behavior specific to each connector, and the annotations @GAHandler (GASearchConnector::class) and @MessengerHandler (MessengerSearchConnector::class) indicate the corresponding implementations for the different supported connectors (respectively Google Assistant and Messenger). What would happen there is no connector for Google Assistant for example, and if a call from Google Assistant is answered? The connector?.sendFirstJourney(journeys.first()) method call would not send the final response, since connector would be null . ConnectorDef \u00b6 Here is a simplified version of SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef < SearchDef >( context ) { fun Section . title (): CharSequence = i18n ( \"{0} - {1}\" , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List < Section >): ConnectorMessage } And its Messenger implementation: class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List < Section >): ConnectorMessage = flexibleListTemplate ( sections . map { section -> with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } The code specific to each connector is thus decoupled correctly. The code common to each connector is present in SearchConnector and the behavior specific to each connector is specified in the dedicated classes. StoryStep \u00b6 Sometimes you need to remember the stage at which the user is in the current story. For this, Tock provides the concept of StoryStep . There are two types of StoryStep. SimpleStoryStep \u00b6 enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps < MyStep >( \"intent\" ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } To modify the current step, two methods are available: Manually change the step val story = storyWithSteps < MyStep >( \"intent\" ) { //(...) step = MyStep . a // the step will be persisted as long as we stay in this story } Use buttons or quick replies More details on this topic here . StorySteps with complex behavior \u00b6 In more complex cases, we want to be able to define a behavior for each step. enum class MySteps : StoryStep < MyHandlerDef > { //no specific behaviour display , select { // \"select\" step will be automatically selected if the select sub-intention is detected override val intent : IntentAware ? = SecondaryIntent . select override fun answer (): MyHandlerDef .() -> Any ? = { end ( \"I don't know yet how to select something\" ) } }, disruption { override fun answer (): ScoreboardDef .() -> Any ? = { end ( \"some perturbation\" ) } }; } More configuration options are available. Check out the description of StoryStep . Postback buttons & quick replies \u00b6 Messenger provides this type of button, as most connectors with GUI. With Tock, you can easily define the action performed after clicking on these buttons. In the following example, the button will redirect to the \"search\" intent: buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , search ) ) It is also possible to define a * StoryStep * and dedicated parameters: //to define parameters, just extend the ParameterKey interface enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , intent = search , //if no step is specified, the current step is used step = MyStep . a , parameters = //this parameter is stored as a string (hooks are used) nextResultDate [ nextDate ] + //this parameter is stored in json (parentheses are used) nextResultOrigin ( origin ) ) ) To retrieve the parameters of the button that was clicked: val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin )","title":"Integrated Bot mode"},{"location":"dev/integrated-bot/#integrated-bot-mode","text":"To develop a bot or an assistant with Tock, you can also use the so called Integrated mode developed in Kotlin . You get then direct access to the MongoDb database. This mode is not available in the demo platform - you need to install the Tock docker images on your own servers.","title":"Integrated Bot Mode"},{"location":"dev/integrated-bot/#sample-project","text":"A sample bot using Tock Integrated mode is provided: https://github.com/theopenconversationkit/tock-bot-open-data . It uses Open Data SNCF API (french trainlines itineraries). This is a good starting point, since it also includes a very simple NLP model. Of course, as the model is not big, the quality of the bot is low, but still it's enough to demonstrate the use of the toolkit.","title":"Sample Project"},{"location":"dev/integrated-bot/#docker-images","text":"Docker images in Docker Hub . The source code used to build these images, as well as the docker-compose files used to start the Tock toolkit, are available in the GitHub repository https://github.com/theopenconversationkit/tock-docker .","title":"Docker Images"},{"location":"dev/integrated-bot/#start-the-nlp-stack","text":"#get the last docker-compose file curl -o docker-compose.yml https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/docker-compose.yml #get the script to start mongo in replicaset mode mkdir -p scripts && curl -o scripts/setup.sh https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/scripts/setup.sh && chmod +x scripts/setup.sh #get the last tag curl -o .env https://raw.githubusercontent.com/theopenconversationkit/tock-docker/master/.env #launch the stack docker-compose up The admin webapp is now available on port 80 : http://localhost The default login is admin@app.com and the password is password .","title":"Start the NLP stack"},{"location":"dev/integrated-bot/#sample-bot-based-on-open-data-apis","text":"A docker image is available to launch it directly. The instructions are specified in the github project containing the docker images .","title":"Sample bot based on Open Data APIs"},{"location":"dev/integrated-bot/#develop-a-new-bot","text":"","title":"Develop a new Bot"},{"location":"dev/integrated-bot/#add-the-bot-toolkit-dependency","text":"The bot-toolkit dependency is required: With Maven: <dependency> <groupId> ai.tock </groupId> <artifactId> bot-toolkit </artifactId> <version> 20.9.2-1 </version> </dependency> With Gradle: compile 'ai.tock:bot-toolkit:20.9.2-1'","title":"Add the bot-toolkit Dependency"},{"location":"dev/integrated-bot/#a-bot-is-a-set-of-stories","text":"This is how the open data bot is defined: val openBot = bot ( \"bot_open_data\" , stories = listOf ( greetings , departures , arrivals , search ), hello = greetings ) This bot has an unique identifier (required - \"bot_open_data\") and a list of \"Story\" . A Story is a functional subset that has a main intention and, optionally, one or more so-called \"secondary\" intentions. Here the bot defines 4 Stories , greetings, departures, arrivals and search. Greetings is also set ( hello = greetings ) as the default story used for a new dialog.","title":"A Bot is a Set of Stories"},{"location":"dev/integrated-bot/#a-simple-story","text":"How do you define a story? Here is a first simplified version of the story greetings : val greetings = story ( \"greetings\" ) { send ( \"Welcome to the Tock Open Data Bot! :)\" ) end ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) } Note that in the body of the function, this has a BotBus type. From which you can interact with the user, and which also allows you to access to all available contextual elements. When the intention greetings will be detected by the NLP model, the function above will be called by the Tock framework. The bot sends successively a first response sentence ( bus.send() ), then a second one indicating that it is the last sentence of his answer using a bus.end() . Here is the full version of greetings : val greetings = story ( \"greetings\" ) { //cleanup state resetDialogState () send ( \"Welcome to the Tock Open Data Bot! :)\" ) send ( \"This is a Tock framework demonstration bot: https://github.com/theopenconversationkit/tock\" ) withMessenger { buttonsTemplate ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , postbackButton ( \"Itineraries\" , search ), postbackButton ( \"Departures\" , Departures ), postbackButton ( \"Arrivals\" , Arrivals ) ) } withGoogleAssistant { gaMessage ( \"The bot is very limited, but ask him a route or the next departures from a station in France, and see the result! :)\" , \"Itineraries\" , \"Departures\" , \"Arrivals\" ) } end () } Two notions have been added: resetDialogState() which cleanup the state (forgetting any previous context). the withMessenger{} and withGoogleAssistant{} methods that define specific responses for each connector - Here it's a text with buttons for Messenger, and a text with suggestions for Google Assistant.","title":"A Simple Story"},{"location":"dev/integrated-bot/#start-and-connect-the-bot","text":"To start the bot, simply add the following call to your main function: registerAndInstallBot ( openBot ) where the openBot variable is the bot you originally defined. When the bot is started, you also need to specify which connectors are used in the web administration interface: Configuration -> Bot Configurations -> Create a new configuration See Connectors page for the list of available connectors.","title":"Start and Connect the Bot"},{"location":"dev/integrated-bot/#import-configuration-dumps","text":"It is possible to export various types of configurations from Tock Studio, then import them programmatically at bot startup. Once the dump files exported to the bot classpath , you can use one or more of the following functions from the bot main : importApplicationDump : import an application from an application dump ( Tock Studio > Settings > Applications ). Note that import is skipped when application exists already. importNlpDump : import a NLP model (intents, sentences, entities) from a NLP dump ( Tock Studio > Settings > Applications ). importI18nDump : import labels (aka i18n ) from a labels dump ( Tock Studio > Stories & Answers > Answers ). Example: fun main ( args : Array < String >) { registerAndInstallBot ( bot ) // Import application importApplicationDump ( \"/bot_app_dump.json\" ) // Import NLP model (intents, sentences, entities...) importNlpDump ( \"/bot_nlp_dump.json\" ) // Import story labels (aka i18n) importI18nDump ( \"/bot_labels_dump.json\" ) }","title":"Import configuration (dumps)"},{"location":"dev/integrated-bot/#advanced-options","text":"Of course, the StoryHandler of greetings does not depend on the context: the answer is always the same.","title":"Advanced options"},{"location":"dev/integrated-bot/#secondary-intentions","text":"Here is the beginning of the definition of the search story : val search = storyDef < SearchDef >( \"search\" , otherStarterIntents = setOf ( indicate_origin ), secondaryIntents = setOf ( indicate_location )) { } The story search defines a secondary starter intent ( indicate_origin ) and a simple secondary intent ( indicate_location ). A secondary starter intent is similar in every respect to the main intent: as soon as the intent is detected, if the current story does not contain indicate_origin as secondary intent, the story search is called. For a classic secondary intent, on the other hand, the story will be executed only if the current story of the context is already the search story. Different stories can therefore share the same secondary intents.","title":"Secondary Intentions"},{"location":"dev/integrated-bot/#handle-entities","text":"To retrieve entity values, it is good practice to define Kotlin extensions . For example here is the code used to retrieve the destination entity: val destinationEntity = openBot . entity ( \"location\" , \"destination\" ) var BotBus . destination : Place ? get () = place ( destinationEntity ) set ( value ) = setPlace ( destinationEntity , value ) private fun BotBus . place ( entity : Entity ): Place ? = entityValue ( entity , :: placeValue ) ?. place private fun BotBus . setPlace ( entity : Entity , place : Place ?) = changeEntityValue ( entity , place ?. let { PlaceValue ( place ) }) An entity of type \"location\" and role \"destination\" is created. There is a corresponding entity in the NLP model. A variable destination is defined, which will simplify the handling of this entity in the conversational code. This variable contains the current value of the destination in the user context. Here's a full version of the search story that uses destination : val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } If there is no value in the current context for the destination, the bot asks to specify the destination and stays there. Same behaviour for the origin or date of departure. If the 3 required values are specified, then the real answer developed in the SearchDef class is used. Here is the full version of this first part of the code: val search = storyDef < SearchDef >( \"search\" , setOf ( indicate_origin ), setOf ( indicate_location )) { //handle generic location intent if ( isIntent ( indicate_location ) && location != null ) { if ( destination == null || origin != null ) { destination = returnsAndRemoveLocation () } else { origin = returnsAndRemoveLocation () } } //check mandatory entities when { destination == null -> end ( \"For which destination?\" ) origin == null -> end ( \"For which origin?\" ) departureDate == null -> end ( \"When?\" ) } } In the case where the detected intention is indicate_location , we do not know if the locality represents the origin or the destination. A simple rule is then used: If there is already in the context an origin and no destination, the new locality is actually the destination. Otherwise, it is the origin.","title":"Handle Entities"},{"location":"dev/integrated-bot/#handlerdef","text":"In the search story above, you may have noted the generic SearchDef typing. Here is the code of this class: @GAHandler ( GASearchConnector :: class ) @MessengerHandler ( MessengerSearchConnector :: class ) class SearchDef ( bus : BotBus ) : HandlerDef < SearchConnector >( bus ) { private val d : Place = bus . destination !! private val o : Place = bus . origin !! private val date : LocalDateTime = bus . departureDate !! override fun answer () { send ( \"From {0} to {1}\" , o , d ) send ( \"Departure on {0}\" , date by datetimeFormat ) val journeys = SncfOpenDataClient . journey ( o , d , date ) if ( journeys . isEmpty ()) { end ( \"Sorry, no routes found :(\" ) } else { send ( \"Here is the first proposal:\" ) connector ?. sendFirstJourney ( journeys . first ()) end () } } } SearchDef extends HandlerDef which is an alias of a Tock framework class. It is usually here that the code of complex stories is defined. The code contains an additional abstraction: SearchConnector . SearchConnector is the class that defines the behavior specific to each connector, and the annotations @GAHandler (GASearchConnector::class) and @MessengerHandler (MessengerSearchConnector::class) indicate the corresponding implementations for the different supported connectors (respectively Google Assistant and Messenger). What would happen there is no connector for Google Assistant for example, and if a call from Google Assistant is answered? The connector?.sendFirstJourney(journeys.first()) method call would not send the final response, since connector would be null .","title":"HandlerDef"},{"location":"dev/integrated-bot/#connectordef","text":"Here is a simplified version of SearchConnector : sealed class SearchConnector ( context : SearchDef ) : ConnectorDef < SearchDef >( context ) { fun Section . title (): CharSequence = i18n ( \"{0} - {1}\" , from , to ) fun sendFirstJourney ( journey : Journey ) = withMessage ( sendFirstJourney ( journey . publicTransportSections ())) abstract fun sendFirstJourney ( sections : List < Section >): ConnectorMessage } And its Messenger implementation: class MessengerSearchConnector ( context : SearchDef ) : SearchConnector ( context ) { override fun sendFirstJourney ( sections : List < Section >): ConnectorMessage = flexibleListTemplate ( sections . map { section -> with ( section ) { listElement ( title (), content (), trainImage ) } }, compact ) } The code specific to each connector is thus decoupled correctly. The code common to each connector is present in SearchConnector and the behavior specific to each connector is specified in the dedicated classes.","title":"ConnectorDef"},{"location":"dev/integrated-bot/#storystep","text":"Sometimes you need to remember the stage at which the user is in the current story. For this, Tock provides the concept of StoryStep . There are two types of StoryStep.","title":"StoryStep"},{"location":"dev/integrated-bot/#simplestorystep","text":"enum class MyStep : SimpleStoryStep { a , b } val story = storyWithSteps < MyStep >( \"intent\" ) { if ( step == a ) { // ... } else if ( step == b ) { // ... } else { //default case } } To modify the current step, two methods are available: Manually change the step val story = storyWithSteps < MyStep >( \"intent\" ) { //(...) step = MyStep . a // the step will be persisted as long as we stay in this story } Use buttons or quick replies More details on this topic here .","title":"SimpleStoryStep"},{"location":"dev/integrated-bot/#storysteps-with-complex-behavior","text":"In more complex cases, we want to be able to define a behavior for each step. enum class MySteps : StoryStep < MyHandlerDef > { //no specific behaviour display , select { // \"select\" step will be automatically selected if the select sub-intention is detected override val intent : IntentAware ? = SecondaryIntent . select override fun answer (): MyHandlerDef .() -> Any ? = { end ( \"I don't know yet how to select something\" ) } }, disruption { override fun answer (): ScoreboardDef .() -> Any ? = { end ( \"some perturbation\" ) } }; } More configuration options are available. Check out the description of StoryStep .","title":"StorySteps with complex behavior"},{"location":"dev/integrated-bot/#postback-buttons-quick-replies","text":"Messenger provides this type of button, as most connectors with GUI. With Tock, you can easily define the action performed after clicking on these buttons. In the following example, the button will redirect to the \"search\" intent: buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , search ) ) It is also possible to define a * StoryStep * and dedicated parameters: //to define parameters, just extend the ParameterKey interface enum class ChoiceParameter : ParameterKey { nextResultDate , nextResultOrigin } buttonsTemplate ( \"The bot is very limited! Only itineraries are supported :)\" , postbackButton ( \"Itineraries\" , intent = search , //if no step is specified, the current step is used step = MyStep . a , parameters = //this parameter is stored as a string (hooks are used) nextResultDate [ nextDate ] + //this parameter is stored in json (parentheses are used) nextResultOrigin ( origin ) ) ) To retrieve the parameters of the button that was clicked: val isClick = isChoiceAction () val nextDate = choice ( nextResultDate ) val nextOrigin : Locality = action . jsonChoice ( nextResultOrigin )","title":"Postback buttons &amp; quick replies"},{"location":"dev/modes/","text":"Bot development with Tock \u00b6 In order to go beyond the possibilities offered by Tock Studio to build bots & conversational assistants, you can program your conversation flow using one of the following modes: The Bot API Mode \u00b6 The Tock Bot API mode allows the development using any programming language of your choosing by integrating Tock's conversational REST API : This mode is only available on the Tock's demo platform . If you want to know more, read further here . The Integrated Bot Mode \u00b6 In this mode, you have access to all the possible functionalities that the Tock framework offers for developing a bot. Historically, most of the bots published by Tock's creators have an integrated bot. The implementation of this solution is more complex than using the REST API and the integrated bot will need direct access to a MongoDB instance. In consequence, you will need to : Install and configure your bot platform (using Docker ) on your poste or on a given server Share access to your MongoDB instance Develop your bot by using Kotlin If you want to know more, read further here .","title":"Bot development with Tock"},{"location":"dev/modes/#bot-development-with-tock","text":"In order to go beyond the possibilities offered by Tock Studio to build bots & conversational assistants, you can program your conversation flow using one of the following modes:","title":"Bot development with Tock"},{"location":"dev/modes/#the-bot-api-mode","text":"The Tock Bot API mode allows the development using any programming language of your choosing by integrating Tock's conversational REST API : This mode is only available on the Tock's demo platform . If you want to know more, read further here .","title":"The Bot API Mode"},{"location":"dev/modes/#the-integrated-bot-mode","text":"In this mode, you have access to all the possible functionalities that the Tock framework offers for developing a bot. Historically, most of the bots published by Tock's creators have an integrated bot. The implementation of this solution is more complex than using the REST API and the integrated bot will need direct access to a MongoDB instance. In consequence, you will need to : Install and configure your bot platform (using Docker ) on your poste or on a given server Share access to your MongoDB instance Develop your bot by using Kotlin If you want to know more, read further here .","title":"The Integrated Bot Mode"},{"location":"guide/studio/","text":"Create your first bot with Tock Studio \u00b6 The best way to try Tock is probably to create a first conversational bot using Tock Studio (the graphical user interface provided with the platform). By connecting to the Tock demonstration platform , it is possible to both design and test a conversational assistant in a few minutes, without having to write code. What you will build \u00b6 An application and a connector on the Tock demo platform A story : user sentence / bot answer, testable through the Tock Studio interface An assistant who answers, when you say \"hello\"! \ud83d\ude42 What you need \u00b6 About 5 to 15 minutes (reading the additional notes) A GitHub account, to connect to the demo platform Connect to the demo platform \u00b6 Open https://demo.tock.ai/ to access the Tock demonstration platform. Important : this platform is not supposed to host bots in production. This is merely a sandbox instance, in order to try the Tock solution without installing it. A login dialog invites you to connect with GitHub. Only your account ID will be read from GitHub. Create a Tock application \u00b6 When accessing the demo platform for the first time, a wizard helps to create the first application : Enter a name for the application Select a language - other languages can be added later Validate to create the application The just-created application is now visible from the menu: Settings > Language Understanding . Once the first application has been created, you can create others using Create New Application . Add a connector \u00b6 To interact with the bot (through a communication channel), a connector must be used. Numerous connectors are provided with Tock: Messenger , WhatsApp , Google Assistant and Google Home , Twitter , Alexa , Business Chat , Teams , Slack , Rocket.Chat ... It is even possible to implement your own connectors to integrate with more channels. In this tutorial, you will configure a connector for Slack - the collaborative and instant messaging platform. It will be possible to try the bot using the Tock Studio interface - no need to use Slack or get an account. Create the first connector for your application: Go to Settings > Configurations Create a new Configuration Select the connector type Slack Enter anything e.g. token in Token fields (for the moment) Create Note that an API Key is automatically generated for the application, once the first connector is created. This key is required to connect to the bot API, in order to leverage the WebHook or WebSocket modes. Clicking on Display test configurations , you can see another Test configuration has been created. This connector is used when the bot is tested directly through the Tock Studio interface. It allows to try the bot without having Slack, for instance. Create a story \u00b6 A conversational bot receives and understands user sentences, using natural-language techniques to identify an intent and possibly entities . Example: from the sentence \"What will the weather be like tomorrow?\", the Tock NLU (Natural Language Understanding) engine should detect a \"weather\" intent and a \"tomorrow\" date/time entity precising the question (like a kind of intent variable/parameter). In order to detect intents and entities, sentences must first be added and qualifieds. The Tock NLU menu allows to manage intents and entities, qualify sentences and supervise the bot training: the more qualified sentences, the more relevant is the bot . Nevertheless, let's leave intents and entities for now... The Tock Stories mode allows to create intents automatically in a few minutes, as well as the expected answers. You will now create a first template of a conversation, using the Tock Studio graphical tools: Go to Stories & Answers > New Story Enter a new user sentence - for instance \"hello\" A form now opens to configure the new story creation, the intent, the type of response, etc. In the Add new Answer field, enter the answer - for instance \"what a nice day!\" End with Create Story Test the bot \u00b6 It is time to try the bot and its first story! Go to Test > Test the Bot Say \"hello\", the bot answers Please check that the correct application and language are selected (in case there are more than one) when testing: they are visible in the top-right corner of the interface. Improve the understanding \u00b6 By entering various sentences through the Test the bot interface, you can see it does not understand much your phrases - even with sentences very similar to the one at story creation. The conversational model and the Tock NLU engine must be trained and improved by progressively adding user qualified sentences to feed underlying algorithms and give more and more relevant results. Although first tries can be deceiving, several qualified sentences (one or two dozens if necessary) usually make a difference and the bot gets more relevant. Go to Language Understanding > Inbox Here you can see the previously entered sentences, and more interestingly how the bot qualified them. For each sentence, Tock shows the detected intent, the language, as well as the scores (given by the algorithms according to their level of confidence for the sentence). Choose several sentences, for each one: select the correct intent then Validate Return to Test > Test the Bot Check the bot now understands these sentences correctly, as well as slightly-different ones you have never entered! Create more stories (optional) \u00b6 To go a little further with Tock stories , you could create more stories and test them directly from Tock Studio . Each bot response comes from the intent detected/triggered, without another form of navigation than the thread of YOUR sentences. Conversational is magic: natural language is the navigation, users are not forced to use traditional links and menus anymore (contrary to Websites and mobile apps). For curious users, let's have a word about managing numerous stories and the possible impact on understanding. If you take time and create many stories , you may experience unintended effects with how work NLU models and algorithms. As an example, numerous intents and entities can make detection difficult (or more random). A general recommendation is to create bots, dedicated to a limited functional perimeter. It makes it easier to train each bot and focus on the model for its own domain. Qualifying a lot of sentences generally improves the bot understanding, however too many sentences (or too similar) can over-train the model for an intent, resulting in degraded performance. As a conclusion, remember the design and maintenance of conversational models is complex, it requires training (the bot, as well as people building it), qualifying and adapting the models on a regular basis to user needs and language. Congratulations! \u00b6 You have just created your first conversational application with Tock. With a few minutes and no particular knowledge or skill, more importantly without writing or deploying code, you have been able to create a simple conversational workflow and test it online.","title":"Create your 1st bot"},{"location":"guide/studio/#create-your-first-bot-with-tock-studio","text":"The best way to try Tock is probably to create a first conversational bot using Tock Studio (the graphical user interface provided with the platform). By connecting to the Tock demonstration platform , it is possible to both design and test a conversational assistant in a few minutes, without having to write code.","title":"Create your first bot with Tock Studio"},{"location":"guide/studio/#what-you-will-build","text":"An application and a connector on the Tock demo platform A story : user sentence / bot answer, testable through the Tock Studio interface An assistant who answers, when you say \"hello\"! \ud83d\ude42","title":"What you will build"},{"location":"guide/studio/#what-you-need","text":"About 5 to 15 minutes (reading the additional notes) A GitHub account, to connect to the demo platform","title":"What you need"},{"location":"guide/studio/#connect-to-the-demo-platform","text":"Open https://demo.tock.ai/ to access the Tock demonstration platform. Important : this platform is not supposed to host bots in production. This is merely a sandbox instance, in order to try the Tock solution without installing it. A login dialog invites you to connect with GitHub. Only your account ID will be read from GitHub.","title":"Connect to the demo platform"},{"location":"guide/studio/#create-a-tock-application","text":"When accessing the demo platform for the first time, a wizard helps to create the first application : Enter a name for the application Select a language - other languages can be added later Validate to create the application The just-created application is now visible from the menu: Settings > Language Understanding . Once the first application has been created, you can create others using Create New Application .","title":"Create a Tock application"},{"location":"guide/studio/#add-a-connector","text":"To interact with the bot (through a communication channel), a connector must be used. Numerous connectors are provided with Tock: Messenger , WhatsApp , Google Assistant and Google Home , Twitter , Alexa , Business Chat , Teams , Slack , Rocket.Chat ... It is even possible to implement your own connectors to integrate with more channels. In this tutorial, you will configure a connector for Slack - the collaborative and instant messaging platform. It will be possible to try the bot using the Tock Studio interface - no need to use Slack or get an account. Create the first connector for your application: Go to Settings > Configurations Create a new Configuration Select the connector type Slack Enter anything e.g. token in Token fields (for the moment) Create Note that an API Key is automatically generated for the application, once the first connector is created. This key is required to connect to the bot API, in order to leverage the WebHook or WebSocket modes. Clicking on Display test configurations , you can see another Test configuration has been created. This connector is used when the bot is tested directly through the Tock Studio interface. It allows to try the bot without having Slack, for instance.","title":"Add a connector"},{"location":"guide/studio/#create-a-story","text":"A conversational bot receives and understands user sentences, using natural-language techniques to identify an intent and possibly entities . Example: from the sentence \"What will the weather be like tomorrow?\", the Tock NLU (Natural Language Understanding) engine should detect a \"weather\" intent and a \"tomorrow\" date/time entity precising the question (like a kind of intent variable/parameter). In order to detect intents and entities, sentences must first be added and qualifieds. The Tock NLU menu allows to manage intents and entities, qualify sentences and supervise the bot training: the more qualified sentences, the more relevant is the bot . Nevertheless, let's leave intents and entities for now... The Tock Stories mode allows to create intents automatically in a few minutes, as well as the expected answers. You will now create a first template of a conversation, using the Tock Studio graphical tools: Go to Stories & Answers > New Story Enter a new user sentence - for instance \"hello\" A form now opens to configure the new story creation, the intent, the type of response, etc. In the Add new Answer field, enter the answer - for instance \"what a nice day!\" End with Create Story","title":"Create a story"},{"location":"guide/studio/#test-the-bot","text":"It is time to try the bot and its first story! Go to Test > Test the Bot Say \"hello\", the bot answers Please check that the correct application and language are selected (in case there are more than one) when testing: they are visible in the top-right corner of the interface.","title":"Test the bot"},{"location":"guide/studio/#improve-the-understanding","text":"By entering various sentences through the Test the bot interface, you can see it does not understand much your phrases - even with sentences very similar to the one at story creation. The conversational model and the Tock NLU engine must be trained and improved by progressively adding user qualified sentences to feed underlying algorithms and give more and more relevant results. Although first tries can be deceiving, several qualified sentences (one or two dozens if necessary) usually make a difference and the bot gets more relevant. Go to Language Understanding > Inbox Here you can see the previously entered sentences, and more interestingly how the bot qualified them. For each sentence, Tock shows the detected intent, the language, as well as the scores (given by the algorithms according to their level of confidence for the sentence). Choose several sentences, for each one: select the correct intent then Validate Return to Test > Test the Bot Check the bot now understands these sentences correctly, as well as slightly-different ones you have never entered!","title":"Improve the understanding"},{"location":"guide/studio/#create-more-stories-optional","text":"To go a little further with Tock stories , you could create more stories and test them directly from Tock Studio . Each bot response comes from the intent detected/triggered, without another form of navigation than the thread of YOUR sentences. Conversational is magic: natural language is the navigation, users are not forced to use traditional links and menus anymore (contrary to Websites and mobile apps). For curious users, let's have a word about managing numerous stories and the possible impact on understanding. If you take time and create many stories , you may experience unintended effects with how work NLU models and algorithms. As an example, numerous intents and entities can make detection difficult (or more random). A general recommendation is to create bots, dedicated to a limited functional perimeter. It makes it easier to train each bot and focus on the model for its own domain. Qualifying a lot of sentences generally improves the bot understanding, however too many sentences (or too similar) can over-train the model for an intent, resulting in degraded performance. As a conclusion, remember the design and maintenance of conversational models is complex, it requires training (the bot, as well as people building it), qualifying and adapting the models on a regular basis to user needs and language.","title":"Create more stories (optional)"},{"location":"guide/studio/#congratulations","text":"You have just created your first conversational application with Tock. With a few minutes and no particular knowledge or skill, more importantly without writing or deploying code, you have been able to create a simple conversational workflow and test it online.","title":"Congratulations!"}]}